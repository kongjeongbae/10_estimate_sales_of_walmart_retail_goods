{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, time, warnings, pickle, psutil, random\n",
    "\n",
    "# custom imports\n",
    "from multiprocessing import Pool        # Multiprocess Runs\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Helpers\n",
    "#################################################################################\n",
    "## Seeder\n",
    "# :seed to make all processes deterministic     # type: int\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    \n",
    "## Multiprocess Runs\n",
    "def df_parallelize_run(func, t_split):\n",
    "    num_cores = np.min([N_CORES,len(t_split)])\n",
    "    pool = Pool(num_cores)\n",
    "    df = pd.concat(pool.map(func, t_split), axis=1)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Helper to load data by store ID\n",
    "#################################################################################\n",
    "# Read data\n",
    "def get_data_by_store(store):\n",
    "    \n",
    "    # Read and contact basic feature\n",
    "    df = pd.concat([pd.read_pickle(BASE),\n",
    "                    pd.read_pickle(PRICE).iloc[:,2:],\n",
    "                    pd.read_pickle(CALENDAR).iloc[:,2:]],\n",
    "                    axis=1)\n",
    "    \n",
    "    # Leave only relevant store\n",
    "    df = df[df['store_id']==store]\n",
    "\n",
    "    # With memory limits we have to read \n",
    "    # lags and mean encoding features\n",
    "    # separately and drop items that we don't need.\n",
    "    # As our Features Grids are aligned \n",
    "    # we can use index to keep only necessary rows\n",
    "    # Alignment is good for us as concat uses less memory than merge.\n",
    "    df2 = pd.read_pickle(MEAN_ENC)[mean_features]\n",
    "    df2 = df2[df2.index.isin(df.index)]\n",
    "    \n",
    "    df3 = pd.read_pickle(LAGS).iloc[:,3:]\n",
    "    df3 = df3[df3.index.isin(df.index)]\n",
    "    \n",
    "    df = pd.concat([df, df2], axis=1)\n",
    "    del df2 # to not reach memory limit \n",
    "    \n",
    "    df = pd.concat([df, df3], axis=1)\n",
    "    del df3 # to not reach memory limit \n",
    "    \n",
    "    # Create features list\n",
    "    features = [col for col in list(df) if col not in remove_features]\n",
    "    df = df[['id','d',TARGET]+features]\n",
    "    \n",
    "    # Skipping first n rows\n",
    "    df = df[df['d']>=START_TRAIN].reset_index(drop=True)\n",
    "    \n",
    "    return df, features\n",
    "\n",
    "# Recombine Test set after training\n",
    "def get_base_test():\n",
    "    base_test = pd.DataFrame()\n",
    "\n",
    "    for store_id in STORES_IDS:\n",
    "        temp_df = pd.read_pickle('test_'+store_id+'.pkl')\n",
    "        temp_df['store_id'] = store_id\n",
    "        base_test = pd.concat([base_test, temp_df]).reset_index(drop=True)\n",
    "    \n",
    "    return base_test\n",
    "\n",
    "\n",
    "########################### Helper to make dynamic rolling lags\n",
    "#################################################################################\n",
    "def make_lag(LAG_DAY):\n",
    "    lag_df = base_test[['id','d',TARGET]]\n",
    "    col_name = 'sales_lag_'+str(LAG_DAY)\n",
    "    lag_df[col_name] = lag_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(LAG_DAY)).astype(np.float16)\n",
    "    return lag_df[[col_name]]\n",
    "\n",
    "\n",
    "def make_lag_roll(LAG_DAY):\n",
    "    shift_day = LAG_DAY[0]\n",
    "    roll_wind = LAG_DAY[1]\n",
    "    lag_df = base_test[['id','d',TARGET]]\n",
    "    col_name = 'rolling_mean_tmp_'+str(shift_day)+'_'+str(roll_wind)\n",
    "    lag_df[col_name] = lag_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(shift_day).rolling(roll_wind).mean())\n",
    "    return lag_df[[col_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Model params\n",
    "#################################################################################\n",
    "import lightgbm as lgb\n",
    "lgb_params = {\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'tweedie',\n",
    "                    'tweedie_variance_power': 1.1,\n",
    "                    'metric': 'rmse',\n",
    "                    'subsample': 0.5,\n",
    "                    'subsample_freq': 1,\n",
    "                    'learning_rate': 0.03,\n",
    "                    'num_leaves': 2**11-1,\n",
    "                    'min_data_in_leaf': 2**12-1,\n",
    "                    'feature_fraction': 0.5,\n",
    "                    'max_bin': 100,\n",
    "                    'n_estimators': 1400,\n",
    "                    'boost_from_average': False,\n",
    "                    'verbose': -1,\n",
    "                } \n",
    "\n",
    "# Let's look closer on params\n",
    "\n",
    "## 'boosting_type': 'gbdt'\n",
    "# we have 'goss' option for faster training\n",
    "# but it normally leads to underfit.\n",
    "# Also there is good 'dart' mode\n",
    "# but it takes forever to train\n",
    "# and model performance depends \n",
    "# a lot on random factor \n",
    "# https://www.kaggle.com/c/home-credit-default-risk/discussion/60921\n",
    "\n",
    "## 'objective': 'tweedie'\n",
    "# Tweedie Gradient Boosting for Extremely\n",
    "# Unbalanced Zero-inflated Data\n",
    "# https://arxiv.org/pdf/1811.10192.pdf\n",
    "# and many more articles about tweediie\n",
    "#\n",
    "# Strange (for me) but Tweedie is close in results\n",
    "# to my own ugly loss.\n",
    "# My advice here - make OWN LOSS function\n",
    "# https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/140564\n",
    "# https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/143070\n",
    "# I think many of you already using it (after poisson kernel appeared) \n",
    "# (kagglers are very good with \"params\" testing and tuning).\n",
    "# Try to figure out why Tweedie works.\n",
    "# probably it will show you new features options\n",
    "# or data transformation (Target transformation?).\n",
    "\n",
    "## 'tweedie_variance_power': 1.1\n",
    "# default = 1.5\n",
    "# set this closer to 2 to shift towards a Gamma distribution\n",
    "# set this closer to 1 to shift towards a Poisson distribution\n",
    "# my CV shows 1.1 is optimal \n",
    "# but you can make your own choice\n",
    "\n",
    "## 'metric': 'rmse'\n",
    "# Doesn't mean anything to us\n",
    "# as competition metric is different\n",
    "# and we don't use early stoppings here.\n",
    "# So rmse serves just for general \n",
    "# model performance overview.\n",
    "# Also we use \"fake\" validation set\n",
    "# (as it makes part of the training set)\n",
    "# so even general rmse score doesn't mean anything))\n",
    "# https://www.kaggle.com/c/m5-forecasting-accuracy/discussion/133834\n",
    "\n",
    "## 'subsample': 0.5\n",
    "# Serves to fight with overfit\n",
    "# this will randomly select part of data without resampling\n",
    "# Chosen by CV (my CV can be wrong!)\n",
    "# Next kernel will be about CV\n",
    "\n",
    "##'subsample_freq': 1\n",
    "# frequency for bagging\n",
    "# default value - seems ok\n",
    "\n",
    "## 'learning_rate': 0.03\n",
    "# Chosen by CV\n",
    "# Smaller - longer training\n",
    "# but there is an option to stop \n",
    "# in \"local minimum\"\n",
    "# Bigger - faster training\n",
    "# but there is a chance to\n",
    "# not find \"global minimum\" minimum\n",
    "\n",
    "## 'num_leaves': 2**11-1\n",
    "## 'min_data_in_leaf': 2**12-1\n",
    "# Force model to use more features\n",
    "# We need it to reduce \"recursive\"\n",
    "# error impact.\n",
    "# Also it leads to overfit\n",
    "# that's why we use small \n",
    "# 'max_bin': 100\n",
    "\n",
    "## l1, l2 regularizations\n",
    "# https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c\n",
    "# Good tiny explanation\n",
    "# l2 can work with bigger num_leaves\n",
    "# but my CV doesn't show boost\n",
    "                    \n",
    "## 'n_estimators': 1400\n",
    "# CV shows that there should be\n",
    "# different values for each state/store.\n",
    "# Current value was chosen \n",
    "# for general purpose.\n",
    "# As we don't use any early stopings\n",
    "# careful to not overfit Public LB.\n",
    "\n",
    "##'feature_fraction': 0.5\n",
    "# LightGBM will randomly select \n",
    "# part of features on each iteration (tree).\n",
    "# We have maaaany features\n",
    "# and many of them are \"duplicates\"\n",
    "# and many just \"noise\"\n",
    "# good values here - 0.5-0.7 (by CV)\n",
    "\n",
    "## 'boost_from_average': False\n",
    "# There is some \"problem\"\n",
    "# to code boost_from_average for \n",
    "# custom loss\n",
    "# 'True' makes training faster\n",
    "# BUT carefull use it\n",
    "# https://github.com/microsoft/LightGBM/issues/1514\n",
    "# not our case but good to know cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Vars\n",
    "#################################################################################\n",
    "VER = 1                          # Our model version\n",
    "SEED = 42                        # We want all things\n",
    "seed_everything(SEED)            # to be as deterministic \n",
    "lgb_params['seed'] = SEED        # as possible\n",
    "N_CORES = psutil.cpu_count()     # Available CPU cores\n",
    "\n",
    "\n",
    "#LIMITS and const\n",
    "TARGET      = 'sales'            # Our target\n",
    "START_TRAIN = 0                  # We can skip some rows (Nans/faster training)\n",
    "END_TRAIN   = 1941               # End day of our train set\n",
    "P_HORIZON   = 28                 # Prediction horizon\n",
    "USE_AUX     = True               # Use or not pretrained models\n",
    "\n",
    "#FEATURES to remove\n",
    "## These features lead to overfit\n",
    "## or values not present in test set\n",
    "remove_features = ['id','state_id','store_id',\n",
    "                   'date','wm_yr_wk','d',TARGET]\n",
    "mean_features   = ['enc_cat_id_mean','enc_cat_id_std',\n",
    "                   'enc_dept_id_mean','enc_dept_id_std',\n",
    "                   'enc_item_id_mean','enc_item_id_std'] \n",
    "\n",
    "#PATHS for Features\n",
    "ORIGINAL = ''\n",
    "BASE     = 'grid_part_1.pkl'\n",
    "PRICE    = 'grid_part_2.pkl'\n",
    "CALENDAR = 'grid_part_3.pkl'\n",
    "LAGS     = 'lags_df_28.pkl'\n",
    "MEAN_ENC = 'mean_encoding_df.pkl'\n",
    "\n",
    "\n",
    "# AUX(pretrained) Models paths\n",
    "AUX_MODELS = 'bin/'\n",
    "\n",
    "\n",
    "#STORES ids\n",
    "STORES_IDS = pd.read_csv('../inputs/sales_train_evaluation.csv')['store_id']\n",
    "STORES_IDS = list(STORES_IDS.unique())\n",
    "\n",
    "\n",
    "#SPLITS for lags creation\n",
    "SHIFT_DAY  = 28\n",
    "N_LAGS     = 15\n",
    "LAGS_SPLIT = [col for col in range(SHIFT_DAY,SHIFT_DAY+N_LAGS)]\n",
    "ROLS_SPLIT = []\n",
    "for i in [1,7,14]:\n",
    "    for j in [7,14,30,60]:\n",
    "        ROLS_SPLIT.append([i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Aux Models\n",
    "# If you don't want to wait hours and hours\n",
    "# to have result you can train each store \n",
    "# in separate kernel and then just join result.\n",
    "\n",
    "# If we want to use pretrained models we can \n",
    "## skip training \n",
    "## (in our case do dummy training\n",
    "##  to show that we are good with memory\n",
    "##  and you can safely use this (all kernel) code)\n",
    "if USE_AUX:\n",
    "    lgb_params['n_estimators'] = 2\n",
    "    \n",
    "# Here is some 'logs' that can compare\n",
    "#Train CA_1\n",
    "#[100]\tvalid_0's rmse: 2.02289\n",
    "#[200]\tvalid_0's rmse: 2.0017\n",
    "#[300]\tvalid_0's rmse: 1.99239\n",
    "#[400]\tvalid_0's rmse: 1.98471\n",
    "#[500]\tvalid_0's rmse: 1.97923\n",
    "#[600]\tvalid_0's rmse: 1.97284\n",
    "#[700]\tvalid_0's rmse: 1.96763\n",
    "#[800]\tvalid_0's rmse: 1.9624\n",
    "#[900]\tvalid_0's rmse: 1.95673\n",
    "#[1000]\tvalid_0's rmse: 1.95201\n",
    "#[1100]\tvalid_0's rmse: 1.9476\n",
    "#[1200]\tvalid_0's rmse: 1.9434\n",
    "#[1300]\tvalid_0's rmse: 1.9392\n",
    "#[1400]\tvalid_0's rmse: 1.93446\n",
    "\n",
    "#Train CA_2\n",
    "#[100]\tvalid_0's rmse: 1.88949\n",
    "#[200]\tvalid_0's rmse: 1.84767\n",
    "#[300]\tvalid_0's rmse: 1.83653\n",
    "#[400]\tvalid_0's rmse: 1.82909\n",
    "#[500]\tvalid_0's rmse: 1.82265\n",
    "#[600]\tvalid_0's rmse: 1.81725\n",
    "#[700]\tvalid_0's rmse: 1.81252\n",
    "#[800]\tvalid_0's rmse: 1.80736\n",
    "#[900]\tvalid_0's rmse: 1.80242\n",
    "#[1000]\tvalid_0's rmse: 1.79821\n",
    "#[1100]\tvalid_0's rmse: 1.794\n",
    "#[1200]\tvalid_0's rmse: 1.78973\n",
    "#[1300]\tvalid_0's rmse: 1.78552\n",
    "#[1400]\tvalid_0's rmse: 1.78158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train CA_1\n",
      "                                  id     d  sales      item_id  dept_id  \\\n",
      "4873634  FOODS_3_823_CA_1_evaluation  1969    NaN  FOODS_3_823  FOODS_3   \n",
      "4873635  FOODS_3_824_CA_1_evaluation  1969    NaN  FOODS_3_824  FOODS_3   \n",
      "4873636  FOODS_3_825_CA_1_evaluation  1969    NaN  FOODS_3_825  FOODS_3   \n",
      "4873637  FOODS_3_826_CA_1_evaluation  1969    NaN  FOODS_3_826  FOODS_3   \n",
      "4873638  FOODS_3_827_CA_1_evaluation  1969    NaN  FOODS_3_827  FOODS_3   \n",
      "\n",
      "        cat_id  release  sell_price  price_max  price_min  ...  \\\n",
      "4873634  FOODS      127    2.980469   2.980469   2.480469  ...   \n",
      "4873635  FOODS        0    2.480469   2.679688   2.470703  ...   \n",
      "4873636  FOODS        1    3.980469   4.378906   3.980469  ...   \n",
      "4873637  FOODS      211    1.280273   1.280273   1.280273  ...   \n",
      "4873638  FOODS      403    1.000000   1.000000   1.000000  ...   \n",
      "\n",
      "         rolling_mean_tmp_1_30  rolling_mean_tmp_1_60  rolling_mean_tmp_7_7  \\\n",
      "4873634                    NaN                    NaN                   NaN   \n",
      "4873635                    NaN                    NaN                   NaN   \n",
      "4873636                    NaN                    NaN                   NaN   \n",
      "4873637                    NaN                    NaN                   NaN   \n",
      "4873638                    NaN                    NaN                   NaN   \n",
      "\n",
      "         rolling_mean_tmp_7_14  rolling_mean_tmp_7_30  rolling_mean_tmp_7_60  \\\n",
      "4873634                    NaN                    NaN                    NaN   \n",
      "4873635                    NaN                    NaN                    NaN   \n",
      "4873636                    NaN                    NaN                    NaN   \n",
      "4873637                    NaN                    NaN                    NaN   \n",
      "4873638                    NaN                    NaN                    NaN   \n",
      "\n",
      "         rolling_mean_tmp_14_7  rolling_mean_tmp_14_14 rolling_mean_tmp_14_30  \\\n",
      "4873634                    NaN                     NaN                    NaN   \n",
      "4873635                    NaN                     NaN                    NaN   \n",
      "4873636                    NaN                     NaN                    NaN   \n",
      "4873637                    NaN                     NaN                    NaN   \n",
      "4873638                    NaN                     NaN                    NaN   \n",
      "\n",
      "        rolling_mean_tmp_14_60  \n",
      "4873634                    NaN  \n",
      "4873635                    NaN  \n",
      "4873636                    NaN  \n",
      "4873637                    NaN  \n",
      "4873638                    NaN  \n",
      "\n",
      "[5 rows x 75 columns]\n",
      "Train CA_2\n",
      "                                  id     d  sales      item_id  dept_id  \\\n",
      "4446515  FOODS_3_823_CA_2_evaluation  1969    NaN  FOODS_3_823  FOODS_3   \n",
      "4446516  FOODS_3_824_CA_2_evaluation  1969    NaN  FOODS_3_824  FOODS_3   \n",
      "4446517  FOODS_3_825_CA_2_evaluation  1969    NaN  FOODS_3_825  FOODS_3   \n",
      "4446518  FOODS_3_826_CA_2_evaluation  1969    NaN  FOODS_3_826  FOODS_3   \n",
      "4446519  FOODS_3_827_CA_2_evaluation  1969    NaN  FOODS_3_827  FOODS_3   \n",
      "\n",
      "        cat_id  release  sell_price  price_max  price_min  ...  \\\n",
      "4446515  FOODS       13    2.980469   2.980469   2.480469  ...   \n",
      "4446516  FOODS        0    2.480469   2.679688   2.470703  ...   \n",
      "4446517  FOODS        0    3.980469   4.378906   3.980469  ...   \n",
      "4446518  FOODS      209    1.280273   1.280273   1.280273  ...   \n",
      "4446519  FOODS      338    1.000000   1.000000   1.000000  ...   \n",
      "\n",
      "         rolling_mean_tmp_1_30  rolling_mean_tmp_1_60  rolling_mean_tmp_7_7  \\\n",
      "4446515                    NaN                    NaN                   NaN   \n",
      "4446516                    NaN                    NaN                   NaN   \n",
      "4446517                    NaN                    NaN                   NaN   \n",
      "4446518                    NaN                    NaN                   NaN   \n",
      "4446519                    NaN                    NaN                   NaN   \n",
      "\n",
      "         rolling_mean_tmp_7_14  rolling_mean_tmp_7_30  rolling_mean_tmp_7_60  \\\n",
      "4446515                    NaN                    NaN                    NaN   \n",
      "4446516                    NaN                    NaN                    NaN   \n",
      "4446517                    NaN                    NaN                    NaN   \n",
      "4446518                    NaN                    NaN                    NaN   \n",
      "4446519                    NaN                    NaN                    NaN   \n",
      "\n",
      "         rolling_mean_tmp_14_7  rolling_mean_tmp_14_14 rolling_mean_tmp_14_30  \\\n",
      "4446515                    NaN                     NaN                    NaN   \n",
      "4446516                    NaN                     NaN                    NaN   \n",
      "4446517                    NaN                     NaN                    NaN   \n",
      "4446518                    NaN                     NaN                    NaN   \n",
      "4446519                    NaN                     NaN                    NaN   \n",
      "\n",
      "        rolling_mean_tmp_14_60  \n",
      "4446515                    NaN  \n",
      "4446516                    NaN  \n",
      "4446517                    NaN  \n",
      "4446518                    NaN  \n",
      "4446519                    NaN  \n",
      "\n",
      "[5 rows x 75 columns]\n",
      "Train CA_3\n",
      "                                  id     d  sales      item_id  dept_id  \\\n",
      "4842680  FOODS_3_823_CA_3_evaluation  1969    NaN  FOODS_3_823  FOODS_3   \n",
      "4842681  FOODS_3_824_CA_3_evaluation  1969    NaN  FOODS_3_824  FOODS_3   \n",
      "4842682  FOODS_3_825_CA_3_evaluation  1969    NaN  FOODS_3_825  FOODS_3   \n",
      "4842683  FOODS_3_826_CA_3_evaluation  1969    NaN  FOODS_3_826  FOODS_3   \n",
      "4842684  FOODS_3_827_CA_3_evaluation  1969    NaN  FOODS_3_827  FOODS_3   \n",
      "\n",
      "        cat_id  release  sell_price  price_max  price_min  ...  \\\n",
      "4842680  FOODS        0    2.980469   2.980469   2.480469  ...   \n",
      "4842681  FOODS        0    2.480469   2.679688   2.000000  ...   \n",
      "4842682  FOODS        2    3.980469   4.378906   2.000000  ...   \n",
      "4842683  FOODS      211    1.280273   1.280273   1.280273  ...   \n",
      "4842684  FOODS      308    1.000000   1.000000   1.000000  ...   \n",
      "\n",
      "         rolling_mean_tmp_1_30  rolling_mean_tmp_1_60  rolling_mean_tmp_7_7  \\\n",
      "4842680                    NaN                    NaN                   NaN   \n",
      "4842681                    NaN                    NaN                   NaN   \n",
      "4842682                    NaN                    NaN                   NaN   \n",
      "4842683                    NaN                    NaN                   NaN   \n",
      "4842684                    NaN                    NaN                   NaN   \n",
      "\n",
      "         rolling_mean_tmp_7_14  rolling_mean_tmp_7_30  rolling_mean_tmp_7_60  \\\n",
      "4842680                    NaN                    NaN                    NaN   \n",
      "4842681                    NaN                    NaN                    NaN   \n",
      "4842682                    NaN                    NaN                    NaN   \n",
      "4842683                    NaN                    NaN                    NaN   \n",
      "4842684                    NaN                    NaN                    NaN   \n",
      "\n",
      "         rolling_mean_tmp_14_7  rolling_mean_tmp_14_14 rolling_mean_tmp_14_30  \\\n",
      "4842680                    NaN                     NaN                    NaN   \n",
      "4842681                    NaN                     NaN                    NaN   \n",
      "4842682                    NaN                     NaN                    NaN   \n",
      "4842683                    NaN                     NaN                    NaN   \n",
      "4842684                    NaN                     NaN                    NaN   \n",
      "\n",
      "        rolling_mean_tmp_14_60  \n",
      "4842680                    NaN  \n",
      "4842681                    NaN  \n",
      "4842682                    NaN  \n",
      "4842683                    NaN  \n",
      "4842684                    NaN  \n",
      "\n",
      "[5 rows x 75 columns]\n",
      "Train CA_4\n",
      "                                  id     d  sales      item_id  dept_id  \\\n",
      "4737925  FOODS_3_823_CA_4_evaluation  1969    NaN  FOODS_3_823  FOODS_3   \n",
      "4737926  FOODS_3_824_CA_4_evaluation  1969    NaN  FOODS_3_824  FOODS_3   \n",
      "4737927  FOODS_3_825_CA_4_evaluation  1969    NaN  FOODS_3_825  FOODS_3   \n",
      "4737928  FOODS_3_826_CA_4_evaluation  1969    NaN  FOODS_3_826  FOODS_3   \n",
      "4737929  FOODS_3_827_CA_4_evaluation  1969    NaN  FOODS_3_827  FOODS_3   \n",
      "\n",
      "        cat_id  release  sell_price  price_max  price_min  ...  \\\n",
      "4737925  FOODS        0    2.980469   2.980469   2.480469  ...   \n",
      "4737926  FOODS        0    2.480469   2.679688   2.470703  ...   \n",
      "4737927  FOODS        0    3.939453   4.378906   3.939453  ...   \n",
      "4737928  FOODS      212    1.280273   1.280273   1.280273  ...   \n",
      "4737929  FOODS      320    1.000000   1.000000   1.000000  ...   \n",
      "\n",
      "         rolling_mean_tmp_1_30  rolling_mean_tmp_1_60  rolling_mean_tmp_7_7  \\\n",
      "4737925                    NaN                    NaN                   NaN   \n",
      "4737926                    NaN                    NaN                   NaN   \n",
      "4737927                    NaN                    NaN                   NaN   \n",
      "4737928                    NaN                    NaN                   NaN   \n",
      "4737929                    NaN                    NaN                   NaN   \n",
      "\n",
      "         rolling_mean_tmp_7_14  rolling_mean_tmp_7_30  rolling_mean_tmp_7_60  \\\n",
      "4737925                    NaN                    NaN                    NaN   \n",
      "4737926                    NaN                    NaN                    NaN   \n",
      "4737927                    NaN                    NaN                    NaN   \n",
      "4737928                    NaN                    NaN                    NaN   \n",
      "4737929                    NaN                    NaN                    NaN   \n",
      "\n",
      "         rolling_mean_tmp_14_7  rolling_mean_tmp_14_14 rolling_mean_tmp_14_30  \\\n",
      "4737925                    NaN                     NaN                    NaN   \n",
      "4737926                    NaN                     NaN                    NaN   \n",
      "4737927                    NaN                     NaN                    NaN   \n",
      "4737928                    NaN                     NaN                    NaN   \n",
      "4737929                    NaN                     NaN                    NaN   \n",
      "\n",
      "        rolling_mean_tmp_14_60  \n",
      "4737925                    NaN  \n",
      "4737926                    NaN  \n",
      "4737927                    NaN  \n",
      "4737928                    NaN  \n",
      "4737929                    NaN  \n",
      "\n",
      "[5 rows x 75 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TX_1\n",
      "                                  id     d  sales      item_id  dept_id  \\\n",
      "4883322  FOODS_3_823_TX_1_evaluation  1969    NaN  FOODS_3_823  FOODS_3   \n",
      "4883323  FOODS_3_824_TX_1_evaluation  1969    NaN  FOODS_3_824  FOODS_3   \n",
      "4883324  FOODS_3_825_TX_1_evaluation  1969    NaN  FOODS_3_825  FOODS_3   \n",
      "4883325  FOODS_3_826_TX_1_evaluation  1969    NaN  FOODS_3_826  FOODS_3   \n",
      "4883326  FOODS_3_827_TX_1_evaluation  1969    NaN  FOODS_3_827  FOODS_3   \n",
      "\n",
      "        cat_id  release  sell_price  price_max  price_min  ...  \\\n",
      "4883322  FOODS        0    2.980469   2.980469   0.990234  ...   \n",
      "4883323  FOODS        0    2.480469   2.480469   2.179688  ...   \n",
      "4883324  FOODS        0    3.980469   4.378906   1.990234  ...   \n",
      "4883325  FOODS      211    1.280273   1.280273   1.000000  ...   \n",
      "4883326  FOODS      306    1.000000   1.000000   1.000000  ...   \n",
      "\n",
      "         rolling_mean_tmp_1_30  rolling_mean_tmp_1_60  rolling_mean_tmp_7_7  \\\n",
      "4883322                    NaN                    NaN                   NaN   \n",
      "4883323                    NaN                    NaN                   NaN   \n",
      "4883324                    NaN                    NaN                   NaN   \n",
      "4883325                    NaN                    NaN                   NaN   \n",
      "4883326                    NaN                    NaN                   NaN   \n",
      "\n",
      "         rolling_mean_tmp_7_14  rolling_mean_tmp_7_30  rolling_mean_tmp_7_60  \\\n",
      "4883322                    NaN                    NaN                    NaN   \n",
      "4883323                    NaN                    NaN                    NaN   \n",
      "4883324                    NaN                    NaN                    NaN   \n",
      "4883325                    NaN                    NaN                    NaN   \n",
      "4883326                    NaN                    NaN                    NaN   \n",
      "\n",
      "         rolling_mean_tmp_14_7  rolling_mean_tmp_14_14 rolling_mean_tmp_14_30  \\\n",
      "4883322                    NaN                     NaN                    NaN   \n",
      "4883323                    NaN                     NaN                    NaN   \n",
      "4883324                    NaN                     NaN                    NaN   \n",
      "4883325                    NaN                     NaN                    NaN   \n",
      "4883326                    NaN                     NaN                    NaN   \n",
      "\n",
      "        rolling_mean_tmp_14_60  \n",
      "4883322                    NaN  \n",
      "4883323                    NaN  \n",
      "4883324                    NaN  \n",
      "4883325                    NaN  \n",
      "4883326                    NaN  \n",
      "\n",
      "[5 rows x 75 columns]\n",
      "Train TX_2\n",
      "                                  id     d  sales      item_id  dept_id  \\\n",
      "4893248  FOODS_3_823_TX_2_evaluation  1969    NaN  FOODS_3_823  FOODS_3   \n",
      "4893249  FOODS_3_824_TX_2_evaluation  1969    NaN  FOODS_3_824  FOODS_3   \n",
      "4893250  FOODS_3_825_TX_2_evaluation  1969    NaN  FOODS_3_825  FOODS_3   \n",
      "4893251  FOODS_3_826_TX_2_evaluation  1969    NaN  FOODS_3_826  FOODS_3   \n",
      "4893252  FOODS_3_827_TX_2_evaluation  1969    NaN  FOODS_3_827  FOODS_3   \n",
      "\n",
      "        cat_id  release  sell_price  price_max  price_min  ...  \\\n",
      "4893248  FOODS        0    2.980469   2.980469   1.990234  ...   \n",
      "4893249  FOODS        0    2.480469   2.480469   2.179688  ...   \n",
      "4893250  FOODS        0    3.980469   4.378906   3.980469  ...   \n",
      "4893251  FOODS      211    1.280273   1.280273   1.280273  ...   \n",
      "4893252  FOODS      312    1.000000   1.000000   1.000000  ...   \n",
      "\n",
      "         rolling_mean_tmp_1_30  rolling_mean_tmp_1_60  rolling_mean_tmp_7_7  \\\n",
      "4893248                    NaN                    NaN                   NaN   \n",
      "4893249                    NaN                    NaN                   NaN   \n",
      "4893250                    NaN                    NaN                   NaN   \n",
      "4893251                    NaN                    NaN                   NaN   \n",
      "4893252                    NaN                    NaN                   NaN   \n",
      "\n",
      "         rolling_mean_tmp_7_14  rolling_mean_tmp_7_30  rolling_mean_tmp_7_60  \\\n",
      "4893248                    NaN                    NaN                    NaN   \n",
      "4893249                    NaN                    NaN                    NaN   \n",
      "4893250                    NaN                    NaN                    NaN   \n",
      "4893251                    NaN                    NaN                    NaN   \n",
      "4893252                    NaN                    NaN                    NaN   \n",
      "\n",
      "         rolling_mean_tmp_14_7  rolling_mean_tmp_14_14 rolling_mean_tmp_14_30  \\\n",
      "4893248                    NaN                     NaN                    NaN   \n",
      "4893249                    NaN                     NaN                    NaN   \n",
      "4893250                    NaN                     NaN                    NaN   \n",
      "4893251                    NaN                     NaN                    NaN   \n",
      "4893252                    NaN                     NaN                    NaN   \n",
      "\n",
      "        rolling_mean_tmp_14_60  \n",
      "4893248                    NaN  \n",
      "4893249                    NaN  \n",
      "4893250                    NaN  \n",
      "4893251                    NaN  \n",
      "4893252                    NaN  \n",
      "\n",
      "[5 rows x 75 columns]\n",
      "Train TX_3\n",
      "                                  id     d  sales      item_id  dept_id  \\\n",
      "4822534  FOODS_3_823_TX_3_evaluation  1969    NaN  FOODS_3_823  FOODS_3   \n",
      "4822535  FOODS_3_824_TX_3_evaluation  1969    NaN  FOODS_3_824  FOODS_3   \n",
      "4822536  FOODS_3_825_TX_3_evaluation  1969    NaN  FOODS_3_825  FOODS_3   \n",
      "4822537  FOODS_3_826_TX_3_evaluation  1969    NaN  FOODS_3_826  FOODS_3   \n",
      "4822538  FOODS_3_827_TX_3_evaluation  1969    NaN  FOODS_3_827  FOODS_3   \n",
      "\n",
      "        cat_id  release  sell_price  price_max  price_min  ...  \\\n",
      "4822534  FOODS        3    2.980469   2.980469   2.000000  ...   \n",
      "4822535  FOODS        0    2.480469   2.679688   2.470703  ...   \n",
      "4822536  FOODS        0    3.980469   4.378906   3.980469  ...   \n",
      "4822537  FOODS      211    1.280273   1.280273   1.280273  ...   \n",
      "4822538  FOODS      312    1.000000   1.000000   0.500000  ...   \n",
      "\n",
      "         rolling_mean_tmp_1_30  rolling_mean_tmp_1_60  rolling_mean_tmp_7_7  \\\n",
      "4822534                    NaN                    NaN                   NaN   \n",
      "4822535                    NaN                    NaN                   NaN   \n",
      "4822536                    NaN                    NaN                   NaN   \n",
      "4822537                    NaN                    NaN                   NaN   \n",
      "4822538                    NaN                    NaN                   NaN   \n",
      "\n",
      "         rolling_mean_tmp_7_14  rolling_mean_tmp_7_30  rolling_mean_tmp_7_60  \\\n",
      "4822534                    NaN                    NaN                    NaN   \n",
      "4822535                    NaN                    NaN                    NaN   \n",
      "4822536                    NaN                    NaN                    NaN   \n",
      "4822537                    NaN                    NaN                    NaN   \n",
      "4822538                    NaN                    NaN                    NaN   \n",
      "\n",
      "         rolling_mean_tmp_14_7  rolling_mean_tmp_14_14 rolling_mean_tmp_14_30  \\\n",
      "4822534                    NaN                     NaN                    NaN   \n",
      "4822535                    NaN                     NaN                    NaN   \n",
      "4822536                    NaN                     NaN                    NaN   \n",
      "4822537                    NaN                     NaN                    NaN   \n",
      "4822538                    NaN                     NaN                    NaN   \n",
      "\n",
      "        rolling_mean_tmp_14_60  \n",
      "4822534                    NaN  \n",
      "4822535                    NaN  \n",
      "4822536                    NaN  \n",
      "4822537                    NaN  \n",
      "4822538                    NaN  \n",
      "\n",
      "[5 rows x 75 columns]\n",
      "Train WI_1\n",
      "                                  id     d  sales      item_id  dept_id  \\\n",
      "4646134  FOODS_3_823_WI_1_evaluation  1969    NaN  FOODS_3_823  FOODS_3   \n",
      "4646135  FOODS_3_824_WI_1_evaluation  1969    NaN  FOODS_3_824  FOODS_3   \n",
      "4646136  FOODS_3_825_WI_1_evaluation  1969    NaN  FOODS_3_825  FOODS_3   \n",
      "4646137  FOODS_3_826_WI_1_evaluation  1969    NaN  FOODS_3_826  FOODS_3   \n",
      "4646138  FOODS_3_827_WI_1_evaluation  1969    NaN  FOODS_3_827  FOODS_3   \n",
      "\n",
      "        cat_id  release  sell_price  price_max  price_min  ...  \\\n",
      "4646134  FOODS       13    2.980469   2.980469   2.480469  ...   \n",
      "4646135  FOODS        0    2.480469   2.679688   2.470703  ...   \n",
      "4646136  FOODS        0    3.939453   4.378906   3.939453  ...   \n",
      "4646137  FOODS      211    1.280273   1.280273   1.280273  ...   \n",
      "4646138  FOODS      304    1.000000   1.000000   1.000000  ...   \n",
      "\n",
      "         rolling_mean_tmp_1_30  rolling_mean_tmp_1_60  rolling_mean_tmp_7_7  \\\n",
      "4646134                    NaN                    NaN                   NaN   \n",
      "4646135                    NaN                    NaN                   NaN   \n",
      "4646136                    NaN                    NaN                   NaN   \n",
      "4646137                    NaN                    NaN                   NaN   \n",
      "4646138                    NaN                    NaN                   NaN   \n",
      "\n",
      "         rolling_mean_tmp_7_14  rolling_mean_tmp_7_30  rolling_mean_tmp_7_60  \\\n",
      "4646134                    NaN                    NaN                    NaN   \n",
      "4646135                    NaN                    NaN                    NaN   \n",
      "4646136                    NaN                    NaN                    NaN   \n",
      "4646137                    NaN                    NaN                    NaN   \n",
      "4646138                    NaN                    NaN                    NaN   \n",
      "\n",
      "         rolling_mean_tmp_14_7  rolling_mean_tmp_14_14 rolling_mean_tmp_14_30  \\\n",
      "4646134                    NaN                     NaN                    NaN   \n",
      "4646135                    NaN                     NaN                    NaN   \n",
      "4646136                    NaN                     NaN                    NaN   \n",
      "4646137                    NaN                     NaN                    NaN   \n",
      "4646138                    NaN                     NaN                    NaN   \n",
      "\n",
      "        rolling_mean_tmp_14_60  \n",
      "4646134                    NaN  \n",
      "4646135                    NaN  \n",
      "4646136                    NaN  \n",
      "4646137                    NaN  \n",
      "4646138                    NaN  \n",
      "\n",
      "[5 rows x 75 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train WI_2\n",
      "                                  id     d  sales      item_id  dept_id  \\\n",
      "4731947  FOODS_3_823_WI_2_evaluation  1969    NaN  FOODS_3_823  FOODS_3   \n",
      "4731948  FOODS_3_824_WI_2_evaluation  1969    NaN  FOODS_3_824  FOODS_3   \n",
      "4731949  FOODS_3_825_WI_2_evaluation  1969    NaN  FOODS_3_825  FOODS_3   \n",
      "4731950  FOODS_3_826_WI_2_evaluation  1969    NaN  FOODS_3_826  FOODS_3   \n",
      "4731951  FOODS_3_827_WI_2_evaluation  1969    NaN  FOODS_3_827  FOODS_3   \n",
      "\n",
      "        cat_id  release  sell_price  price_max  price_min  ...  \\\n",
      "4731947  FOODS       13    2.980469   2.980469   2.480469  ...   \n",
      "4731948  FOODS        0    2.480469   2.679688   2.470703  ...   \n",
      "4731949  FOODS        0    3.980469   4.378906   3.980469  ...   \n",
      "4731950  FOODS      212    1.280273   1.280273   1.280273  ...   \n",
      "4731951  FOODS      339    1.000000   1.000000   1.000000  ...   \n",
      "\n",
      "         rolling_mean_tmp_1_30  rolling_mean_tmp_1_60  rolling_mean_tmp_7_7  \\\n",
      "4731947                    NaN                    NaN                   NaN   \n",
      "4731948                    NaN                    NaN                   NaN   \n",
      "4731949                    NaN                    NaN                   NaN   \n",
      "4731950                    NaN                    NaN                   NaN   \n",
      "4731951                    NaN                    NaN                   NaN   \n",
      "\n",
      "         rolling_mean_tmp_7_14  rolling_mean_tmp_7_30  rolling_mean_tmp_7_60  \\\n",
      "4731947                    NaN                    NaN                    NaN   \n",
      "4731948                    NaN                    NaN                    NaN   \n",
      "4731949                    NaN                    NaN                    NaN   \n",
      "4731950                    NaN                    NaN                    NaN   \n",
      "4731951                    NaN                    NaN                    NaN   \n",
      "\n",
      "         rolling_mean_tmp_14_7  rolling_mean_tmp_14_14 rolling_mean_tmp_14_30  \\\n",
      "4731947                    NaN                     NaN                    NaN   \n",
      "4731948                    NaN                     NaN                    NaN   \n",
      "4731949                    NaN                     NaN                    NaN   \n",
      "4731950                    NaN                     NaN                    NaN   \n",
      "4731951                    NaN                     NaN                    NaN   \n",
      "\n",
      "        rolling_mean_tmp_14_60  \n",
      "4731947                    NaN  \n",
      "4731948                    NaN  \n",
      "4731949                    NaN  \n",
      "4731950                    NaN  \n",
      "4731951                    NaN  \n",
      "\n",
      "[5 rows x 75 columns]\n",
      "Train WI_3\n",
      "                                  id     d  sales      item_id  dept_id  \\\n",
      "4857408  FOODS_3_823_WI_3_evaluation  1969    NaN  FOODS_3_823  FOODS_3   \n",
      "4857409  FOODS_3_824_WI_3_evaluation  1969    NaN  FOODS_3_824  FOODS_3   \n",
      "4857410  FOODS_3_825_WI_3_evaluation  1969    NaN  FOODS_3_825  FOODS_3   \n",
      "4857411  FOODS_3_826_WI_3_evaluation  1969    NaN  FOODS_3_826  FOODS_3   \n",
      "4857412  FOODS_3_827_WI_3_evaluation  1969    NaN  FOODS_3_827  FOODS_3   \n",
      "\n",
      "        cat_id  release  sell_price  price_max  price_min  ...  \\\n",
      "4857408  FOODS        0    2.980469   2.980469   2.480469  ...   \n",
      "4857409  FOODS        0    2.480469   2.679688   2.000000  ...   \n",
      "4857410  FOODS        0    3.980469   4.378906   3.980469  ...   \n",
      "4857411  FOODS      230    1.280273   1.280273   1.280273  ...   \n",
      "4857412  FOODS      304    1.000000   1.000000   1.000000  ...   \n",
      "\n",
      "         rolling_mean_tmp_1_30  rolling_mean_tmp_1_60  rolling_mean_tmp_7_7  \\\n",
      "4857408                    NaN                    NaN                   NaN   \n",
      "4857409                    NaN                    NaN                   NaN   \n",
      "4857410                    NaN                    NaN                   NaN   \n",
      "4857411                    NaN                    NaN                   NaN   \n",
      "4857412                    NaN                    NaN                   NaN   \n",
      "\n",
      "         rolling_mean_tmp_7_14  rolling_mean_tmp_7_30  rolling_mean_tmp_7_60  \\\n",
      "4857408                    NaN                    NaN                    NaN   \n",
      "4857409                    NaN                    NaN                    NaN   \n",
      "4857410                    NaN                    NaN                    NaN   \n",
      "4857411                    NaN                    NaN                    NaN   \n",
      "4857412                    NaN                    NaN                    NaN   \n",
      "\n",
      "         rolling_mean_tmp_14_7  rolling_mean_tmp_14_14 rolling_mean_tmp_14_30  \\\n",
      "4857408                    NaN                     NaN                    NaN   \n",
      "4857409                    NaN                     NaN                    NaN   \n",
      "4857410                    NaN                     NaN                    NaN   \n",
      "4857411                    NaN                     NaN                    NaN   \n",
      "4857412                    NaN                     NaN                    NaN   \n",
      "\n",
      "        rolling_mean_tmp_14_60  \n",
      "4857408                    NaN  \n",
      "4857409                    NaN  \n",
      "4857410                    NaN  \n",
      "4857411                    NaN  \n",
      "4857412                    NaN  \n",
      "\n",
      "[5 rows x 75 columns]\n"
     ]
    }
   ],
   "source": [
    "########################### Train Models\n",
    "#################################################################################\n",
    "for store_id in STORES_IDS:\n",
    "    print('Train', store_id)\n",
    "    \n",
    "    # Get grid for current store\n",
    "    grid_df, features_columns = get_data_by_store(store_id)\n",
    "    print(grid_df.tail())\n",
    "    # Masks for \n",
    "    # Train (All data less than 1913)\n",
    "    # \"Validation\" (Last 28 days - not real validatio set)\n",
    "    # Test (All data greater than 1913 day, \n",
    "    #       with some gap for recursive features)\n",
    "    train_mask = grid_df['d']<=END_TRAIN\n",
    "    valid_mask = train_mask&(grid_df['d']>(END_TRAIN-P_HORIZON))\n",
    "    preds_mask = grid_df['d']>(END_TRAIN-100)\n",
    "    \n",
    "    # Apply masks and save lgb dataset as bin\n",
    "    # to reduce memory spikes during dtype convertations\n",
    "    # https://github.com/Microsoft/LightGBM/issues/1032\n",
    "    # \"To avoid any conversions, you should always use np.float32\"\n",
    "    # or save to bin before start training\n",
    "    # https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/discussion/53773\n",
    "    train_data = lgb.Dataset(grid_df[train_mask][features_columns], \n",
    "                       label=grid_df[train_mask][TARGET])\n",
    "    train_data.save_binary('train_data.bin')\n",
    "    train_data = lgb.Dataset('train_data.bin')\n",
    "    \n",
    "    valid_data = lgb.Dataset(grid_df[valid_mask][features_columns], \n",
    "                       label=grid_df[valid_mask][TARGET])\n",
    "    \n",
    "    # Saving part of the dataset for later predictions\n",
    "    # Removing features that we need to calculate recursively \n",
    "    grid_df = grid_df[preds_mask].reset_index(drop=True)\n",
    "    keep_cols = [col for col in list(grid_df) if '_tmp_' not in col]\n",
    "    grid_df = grid_df[keep_cols]\n",
    "    grid_df.to_pickle('test_'+store_id+'.pkl')\n",
    "    del grid_df\n",
    "    \n",
    "    # Launch seeder again to make lgb training 100% deterministic\n",
    "    # with each \"code line\" np.random \"evolves\" \n",
    "    # so we need (may want) to \"reset\" it\n",
    "    seed_everything(SEED)\n",
    "    estimator = lgb.train(lgb_params,\n",
    "                          train_data,\n",
    "                          valid_sets = [valid_data],\n",
    "                          verbose_eval = 100,\n",
    "                          )\n",
    "    \n",
    "    # Save model - it's not real '.bin' but a pickle file\n",
    "    # estimator = lgb.Booster(model_file='model.txt')\n",
    "    # can only predict with the best iteration (or the saving iteration)\n",
    "    # pickle.dump gives us more flexibility\n",
    "    # like estimator.predict(TEST, num_iteration=100)\n",
    "    # num_iteration - number of iteration want to predict with, \n",
    "    # NULL or <= 0 means use best iteration\n",
    "    model_name = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin'\n",
    "    pickle.dump(estimator, open(model_name, 'wb'))\n",
    "\n",
    "    # Remove temporary files and objects \n",
    "    # to free some hdd space and ram memory\n",
    "    !rm train_data.bin\n",
    "    del train_data, valid_data, estimator\n",
    "    gc.collect()\n",
    "    \n",
    "    # \"Keep\" models features for predictions\n",
    "    MODEL_FEATURES = features_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict | Day: 1\n",
      "##########  3.84 min round |  3.84 min total |  39950.97 day sales |\n",
      "Predict | Day: 2\n",
      "##########  3.75 min round |  7.59 min total |  37182.49 day sales |\n",
      "Predict | Day: 3\n",
      "##########  3.75 min round |  11.34 min total |  37035.73 day sales |\n",
      "Predict | Day: 4\n",
      "##########  3.75 min round |  15.09 min total |  37036.99 day sales |\n",
      "Predict | Day: 5\n",
      "##########  3.75 min round |  18.83 min total |  42061.23 day sales |\n",
      "Predict | Day: 6\n",
      "##########  3.75 min round |  22.58 min total |  50178.81 day sales |\n",
      "Predict | Day: 7\n",
      "##########  3.75 min round |  26.33 min total |  51105.64 day sales |\n",
      "Predict | Day: 8\n",
      "##########  3.74 min round |  30.07 min total |  45124.21 day sales |\n",
      "Predict | Day: 9\n",
      "##########  3.75 min round |  33.81 min total |  39074.22 day sales |\n",
      "Predict | Day: 10\n",
      "##########  3.74 min round |  37.56 min total |  44169.33 day sales |\n",
      "Predict | Day: 11\n",
      "##########  3.73 min round |  41.29 min total |  45348.97 day sales |\n",
      "Predict | Day: 12\n",
      "##########  3.75 min round |  45.04 min total |  53286.54 day sales |\n",
      "Predict | Day: 13\n",
      "##########  3.74 min round |  48.79 min total |  55908.36 day sales |\n",
      "Predict | Day: 14\n",
      "##########  3.75 min round |  52.53 min total |  58191.34 day sales |\n",
      "Predict | Day: 15\n",
      "##########  3.75 min round |  56.28 min total |  48039.42 day sales |\n",
      "Predict | Day: 16\n",
      "##########  3.75 min round |  60.03 min total |  43571.75 day sales |\n",
      "Predict | Day: 17\n",
      "##########  3.75 min round |  63.78 min total |  43007.92 day sales |\n",
      "Predict | Day: 18\n",
      "##########  3.77 min round |  67.54 min total |  44889.89 day sales |\n",
      "Predict | Day: 19\n",
      "##########  3.76 min round |  71.30 min total |  46840.47 day sales |\n",
      "Predict | Day: 20\n",
      "##########  3.76 min round |  75.06 min total |  57919.92 day sales |\n",
      "Predict | Day: 21\n",
      "##########  3.78 min round |  78.84 min total |  59290.87 day sales |\n",
      "Predict | Day: 22\n",
      "##########  3.78 min round |  82.62 min total |  46433.28 day sales |\n",
      "Predict | Day: 23\n",
      "##########  3.77 min round |  86.40 min total |  43519.22 day sales |\n",
      "Predict | Day: 24\n",
      "##########  3.77 min round |  90.17 min total |  45013.42 day sales |\n",
      "Predict | Day: 25\n",
      "##########  3.78 min round |  93.95 min total |  41536.07 day sales |\n",
      "Predict | Day: 26\n",
      "##########  3.77 min round |  97.72 min total |  45782.13 day sales |\n",
      "Predict | Day: 27\n",
      "##########  3.75 min round |  101.47 min total |  54385.40 day sales |\n",
      "Predict | Day: 28\n",
      "##########  3.75 min round |  105.21 min total |  49782.21 day sales |\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>0.958572</td>\n",
       "      <td>0.776854</td>\n",
       "      <td>0.795831</td>\n",
       "      <td>0.809182</td>\n",
       "      <td>1.126867</td>\n",
       "      <td>1.265218</td>\n",
       "      <td>1.174310</td>\n",
       "      <td>1.080325</td>\n",
       "      <td>0.883443</td>\n",
       "      <td>...</td>\n",
       "      <td>1.035435</td>\n",
       "      <td>1.276392</td>\n",
       "      <td>1.127642</td>\n",
       "      <td>0.971120</td>\n",
       "      <td>0.906212</td>\n",
       "      <td>0.860976</td>\n",
       "      <td>0.947063</td>\n",
       "      <td>1.228143</td>\n",
       "      <td>1.309055</td>\n",
       "      <td>1.101408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>0.238108</td>\n",
       "      <td>0.187746</td>\n",
       "      <td>0.202934</td>\n",
       "      <td>0.190623</td>\n",
       "      <td>0.229802</td>\n",
       "      <td>0.299991</td>\n",
       "      <td>0.313969</td>\n",
       "      <td>0.228468</td>\n",
       "      <td>0.208481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291811</td>\n",
       "      <td>0.364425</td>\n",
       "      <td>0.346255</td>\n",
       "      <td>0.227300</td>\n",
       "      <td>0.220785</td>\n",
       "      <td>0.208741</td>\n",
       "      <td>0.251313</td>\n",
       "      <td>0.271761</td>\n",
       "      <td>0.348970</td>\n",
       "      <td>0.380125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>0.539878</td>\n",
       "      <td>0.489011</td>\n",
       "      <td>0.523984</td>\n",
       "      <td>0.526887</td>\n",
       "      <td>0.674716</td>\n",
       "      <td>0.898484</td>\n",
       "      <td>0.788505</td>\n",
       "      <td>0.570668</td>\n",
       "      <td>0.608901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.721518</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.758040</td>\n",
       "      <td>0.581762</td>\n",
       "      <td>0.507301</td>\n",
       "      <td>0.552885</td>\n",
       "      <td>0.579897</td>\n",
       "      <td>0.763763</td>\n",
       "      <td>0.847152</td>\n",
       "      <td>0.763796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
       "      <td>1.559238</td>\n",
       "      <td>1.270549</td>\n",
       "      <td>1.252646</td>\n",
       "      <td>1.330892</td>\n",
       "      <td>1.898072</td>\n",
       "      <td>2.564652</td>\n",
       "      <td>3.052837</td>\n",
       "      <td>2.042812</td>\n",
       "      <td>1.363894</td>\n",
       "      <td>...</td>\n",
       "      <td>1.839892</td>\n",
       "      <td>2.361975</td>\n",
       "      <td>2.955681</td>\n",
       "      <td>1.676101</td>\n",
       "      <td>1.351872</td>\n",
       "      <td>1.334344</td>\n",
       "      <td>1.445189</td>\n",
       "      <td>1.930474</td>\n",
       "      <td>2.746842</td>\n",
       "      <td>2.685529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
       "      <td>0.994387</td>\n",
       "      <td>0.963645</td>\n",
       "      <td>0.905887</td>\n",
       "      <td>0.991271</td>\n",
       "      <td>1.120635</td>\n",
       "      <td>1.497103</td>\n",
       "      <td>1.559617</td>\n",
       "      <td>1.212098</td>\n",
       "      <td>0.995127</td>\n",
       "      <td>...</td>\n",
       "      <td>1.190287</td>\n",
       "      <td>1.565588</td>\n",
       "      <td>1.609874</td>\n",
       "      <td>1.069912</td>\n",
       "      <td>0.990129</td>\n",
       "      <td>1.008256</td>\n",
       "      <td>1.124766</td>\n",
       "      <td>1.342855</td>\n",
       "      <td>1.639730</td>\n",
       "      <td>1.402877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30485</th>\n",
       "      <td>FOODS_3_823_WI_3_evaluation</td>\n",
       "      <td>0.503894</td>\n",
       "      <td>0.499029</td>\n",
       "      <td>0.453799</td>\n",
       "      <td>0.500889</td>\n",
       "      <td>0.500926</td>\n",
       "      <td>0.552205</td>\n",
       "      <td>0.665215</td>\n",
       "      <td>0.556062</td>\n",
       "      <td>0.491702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594549</td>\n",
       "      <td>0.800446</td>\n",
       "      <td>0.949041</td>\n",
       "      <td>0.614799</td>\n",
       "      <td>0.633866</td>\n",
       "      <td>0.624532</td>\n",
       "      <td>0.530694</td>\n",
       "      <td>0.537334</td>\n",
       "      <td>0.604232</td>\n",
       "      <td>0.714240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30486</th>\n",
       "      <td>FOODS_3_824_WI_3_evaluation</td>\n",
       "      <td>0.281021</td>\n",
       "      <td>0.265647</td>\n",
       "      <td>0.247098</td>\n",
       "      <td>0.228808</td>\n",
       "      <td>0.221473</td>\n",
       "      <td>0.276727</td>\n",
       "      <td>0.310442</td>\n",
       "      <td>0.276439</td>\n",
       "      <td>0.245420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262813</td>\n",
       "      <td>0.378834</td>\n",
       "      <td>0.407067</td>\n",
       "      <td>0.332815</td>\n",
       "      <td>0.381947</td>\n",
       "      <td>0.369283</td>\n",
       "      <td>0.262434</td>\n",
       "      <td>0.215852</td>\n",
       "      <td>0.293710</td>\n",
       "      <td>0.298762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30487</th>\n",
       "      <td>FOODS_3_825_WI_3_evaluation</td>\n",
       "      <td>0.664720</td>\n",
       "      <td>0.520124</td>\n",
       "      <td>0.484450</td>\n",
       "      <td>0.446882</td>\n",
       "      <td>0.474385</td>\n",
       "      <td>0.611314</td>\n",
       "      <td>0.685943</td>\n",
       "      <td>0.658661</td>\n",
       "      <td>0.502950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783032</td>\n",
       "      <td>1.166711</td>\n",
       "      <td>1.326367</td>\n",
       "      <td>0.988811</td>\n",
       "      <td>1.131937</td>\n",
       "      <td>1.057419</td>\n",
       "      <td>0.726306</td>\n",
       "      <td>0.709003</td>\n",
       "      <td>0.782662</td>\n",
       "      <td>0.891226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30488</th>\n",
       "      <td>FOODS_3_826_WI_3_evaluation</td>\n",
       "      <td>1.107197</td>\n",
       "      <td>0.998989</td>\n",
       "      <td>1.037605</td>\n",
       "      <td>0.956622</td>\n",
       "      <td>1.093383</td>\n",
       "      <td>1.274922</td>\n",
       "      <td>1.206429</td>\n",
       "      <td>1.321641</td>\n",
       "      <td>1.104078</td>\n",
       "      <td>...</td>\n",
       "      <td>1.039109</td>\n",
       "      <td>1.459719</td>\n",
       "      <td>1.561319</td>\n",
       "      <td>1.199589</td>\n",
       "      <td>1.524164</td>\n",
       "      <td>1.366592</td>\n",
       "      <td>1.106344</td>\n",
       "      <td>1.253126</td>\n",
       "      <td>1.388892</td>\n",
       "      <td>1.411870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30489</th>\n",
       "      <td>FOODS_3_827_WI_3_evaluation</td>\n",
       "      <td>1.794366</td>\n",
       "      <td>1.666173</td>\n",
       "      <td>1.629208</td>\n",
       "      <td>1.722912</td>\n",
       "      <td>2.093909</td>\n",
       "      <td>2.321157</td>\n",
       "      <td>1.978429</td>\n",
       "      <td>1.972179</td>\n",
       "      <td>1.722263</td>\n",
       "      <td>...</td>\n",
       "      <td>1.747405</td>\n",
       "      <td>2.337763</td>\n",
       "      <td>2.248293</td>\n",
       "      <td>1.780179</td>\n",
       "      <td>2.241183</td>\n",
       "      <td>1.937571</td>\n",
       "      <td>1.581266</td>\n",
       "      <td>1.924365</td>\n",
       "      <td>2.062075</td>\n",
       "      <td>2.059188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30490 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id        F1        F2        F3        F4  \\\n",
       "0      HOBBIES_1_001_CA_1_evaluation  0.958572  0.776854  0.795831  0.809182   \n",
       "1      HOBBIES_1_002_CA_1_evaluation  0.238108  0.187746  0.202934  0.190623   \n",
       "2      HOBBIES_1_003_CA_1_evaluation  0.539878  0.489011  0.523984  0.526887   \n",
       "3      HOBBIES_1_004_CA_1_evaluation  1.559238  1.270549  1.252646  1.330892   \n",
       "4      HOBBIES_1_005_CA_1_evaluation  0.994387  0.963645  0.905887  0.991271   \n",
       "...                              ...       ...       ...       ...       ...   \n",
       "30485    FOODS_3_823_WI_3_evaluation  0.503894  0.499029  0.453799  0.500889   \n",
       "30486    FOODS_3_824_WI_3_evaluation  0.281021  0.265647  0.247098  0.228808   \n",
       "30487    FOODS_3_825_WI_3_evaluation  0.664720  0.520124  0.484450  0.446882   \n",
       "30488    FOODS_3_826_WI_3_evaluation  1.107197  0.998989  1.037605  0.956622   \n",
       "30489    FOODS_3_827_WI_3_evaluation  1.794366  1.666173  1.629208  1.722912   \n",
       "\n",
       "             F5        F6        F7        F8        F9  ...       F19  \\\n",
       "0      1.126867  1.265218  1.174310  1.080325  0.883443  ...  1.035435   \n",
       "1      0.229802  0.299991  0.313969  0.228468  0.208481  ...  0.291811   \n",
       "2      0.674716  0.898484  0.788505  0.570668  0.608901  ...  0.721518   \n",
       "3      1.898072  2.564652  3.052837  2.042812  1.363894  ...  1.839892   \n",
       "4      1.120635  1.497103  1.559617  1.212098  0.995127  ...  1.190287   \n",
       "...         ...       ...       ...       ...       ...  ...       ...   \n",
       "30485  0.500926  0.552205  0.665215  0.556062  0.491702  ...  0.594549   \n",
       "30486  0.221473  0.276727  0.310442  0.276439  0.245420  ...  0.262813   \n",
       "30487  0.474385  0.611314  0.685943  0.658661  0.502950  ...  0.783032   \n",
       "30488  1.093383  1.274922  1.206429  1.321641  1.104078  ...  1.039109   \n",
       "30489  2.093909  2.321157  1.978429  1.972179  1.722263  ...  1.747405   \n",
       "\n",
       "            F20       F21       F22       F23       F24       F25       F26  \\\n",
       "0      1.276392  1.127642  0.971120  0.906212  0.860976  0.947063  1.228143   \n",
       "1      0.364425  0.346255  0.227300  0.220785  0.208741  0.251313  0.271761   \n",
       "2      0.795368  0.758040  0.581762  0.507301  0.552885  0.579897  0.763763   \n",
       "3      2.361975  2.955681  1.676101  1.351872  1.334344  1.445189  1.930474   \n",
       "4      1.565588  1.609874  1.069912  0.990129  1.008256  1.124766  1.342855   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "30485  0.800446  0.949041  0.614799  0.633866  0.624532  0.530694  0.537334   \n",
       "30486  0.378834  0.407067  0.332815  0.381947  0.369283  0.262434  0.215852   \n",
       "30487  1.166711  1.326367  0.988811  1.131937  1.057419  0.726306  0.709003   \n",
       "30488  1.459719  1.561319  1.199589  1.524164  1.366592  1.106344  1.253126   \n",
       "30489  2.337763  2.248293  1.780179  2.241183  1.937571  1.581266  1.924365   \n",
       "\n",
       "            F27       F28  \n",
       "0      1.309055  1.101408  \n",
       "1      0.348970  0.380125  \n",
       "2      0.847152  0.763796  \n",
       "3      2.746842  2.685529  \n",
       "4      1.639730  1.402877  \n",
       "...         ...       ...  \n",
       "30485  0.604232  0.714240  \n",
       "30486  0.293710  0.298762  \n",
       "30487  0.782662  0.891226  \n",
       "30488  1.388892  1.411870  \n",
       "30489  2.062075  2.059188  \n",
       "\n",
       "[30490 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################### Predict\n",
    "#################################################################################\n",
    "# Create Dummy DataFrame to store predictions\n",
    "all_preds = pd.DataFrame()\n",
    "\n",
    "# Join back the Test dataset with \n",
    "# a small part of the training data \n",
    "# to make recursive features\n",
    "base_test = get_base_test()\n",
    "\n",
    "# Timer to measure predictions time \n",
    "main_time = time.time()\n",
    "\n",
    "# Loop over each prediction day\n",
    "# As rolling lags are the most timeconsuming\n",
    "# we will calculate it for whole day\n",
    "for PREDICT_DAY in range(1,29):    \n",
    "    print('Predict | Day:', PREDICT_DAY)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Make temporary grid to calculate rolling lags\n",
    "    grid_df = base_test.copy()\n",
    "#     grid_df = pd.concat([grid_df, df_parallelize_run(make_lag_roll, ROLS_SPLIT)], axis=1)\n",
    "    for i in ROLS_SPLIT:\n",
    "        grid_df = pd.concat([grid_df, make_lag_roll(i)], axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for store_id in STORES_IDS:\n",
    "        \n",
    "        # Read all our models and make predictions\n",
    "        # for each day/store pairs\n",
    "        model_path = 'lgb_model_'+store_id+'_v'+str(VER)+'.bin' \n",
    "        if USE_AUX:\n",
    "            model_path = AUX_MODELS + model_path\n",
    "        \n",
    "        estimator = pickle.load(open(model_path, 'rb'))\n",
    "        \n",
    "        day_mask = base_test['d']==(END_TRAIN+PREDICT_DAY)\n",
    "        store_mask = base_test['store_id']==store_id\n",
    "        \n",
    "        mask = (day_mask)&(store_mask)\n",
    "        base_test[TARGET][mask] = estimator.predict(grid_df[mask][MODEL_FEATURES])\n",
    "    \n",
    "    # Make good column naming and add \n",
    "    # to all_preds DataFrame\n",
    "    temp_df = base_test[day_mask][['id',TARGET]]\n",
    "    temp_df.columns = ['id','F'+str(PREDICT_DAY)]\n",
    "    if 'id' in list(all_preds):\n",
    "        all_preds = all_preds.merge(temp_df, on=['id'], how='left')\n",
    "    else:\n",
    "        all_preds = temp_df.copy()\n",
    "        \n",
    "    print('#'*10, ' %0.2f min round |' % ((time.time() - start_time) / 60),\n",
    "                  ' %0.2f min total |' % ((time.time() - main_time) / 60),\n",
    "                  ' %0.2f day sales |' % (temp_df['F'+str(PREDICT_DAY)].sum()))\n",
    "    del temp_df\n",
    "    \n",
    "all_preds = all_preds.reset_index(drop=True)\n",
    "all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>0.958572</td>\n",
       "      <td>0.776854</td>\n",
       "      <td>0.795831</td>\n",
       "      <td>0.809182</td>\n",
       "      <td>1.126867</td>\n",
       "      <td>1.265218</td>\n",
       "      <td>1.174310</td>\n",
       "      <td>1.080325</td>\n",
       "      <td>0.883443</td>\n",
       "      <td>...</td>\n",
       "      <td>1.035435</td>\n",
       "      <td>1.276392</td>\n",
       "      <td>1.127642</td>\n",
       "      <td>0.971120</td>\n",
       "      <td>0.906212</td>\n",
       "      <td>0.860976</td>\n",
       "      <td>0.947063</td>\n",
       "      <td>1.228143</td>\n",
       "      <td>1.309055</td>\n",
       "      <td>1.101408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>0.238108</td>\n",
       "      <td>0.187746</td>\n",
       "      <td>0.202934</td>\n",
       "      <td>0.190623</td>\n",
       "      <td>0.229802</td>\n",
       "      <td>0.299991</td>\n",
       "      <td>0.313969</td>\n",
       "      <td>0.228468</td>\n",
       "      <td>0.208481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291811</td>\n",
       "      <td>0.364425</td>\n",
       "      <td>0.346255</td>\n",
       "      <td>0.227300</td>\n",
       "      <td>0.220785</td>\n",
       "      <td>0.208741</td>\n",
       "      <td>0.251313</td>\n",
       "      <td>0.271761</td>\n",
       "      <td>0.348970</td>\n",
       "      <td>0.380125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>0.539878</td>\n",
       "      <td>0.489011</td>\n",
       "      <td>0.523984</td>\n",
       "      <td>0.526887</td>\n",
       "      <td>0.674716</td>\n",
       "      <td>0.898484</td>\n",
       "      <td>0.788505</td>\n",
       "      <td>0.570668</td>\n",
       "      <td>0.608901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.721518</td>\n",
       "      <td>0.795368</td>\n",
       "      <td>0.758040</td>\n",
       "      <td>0.581762</td>\n",
       "      <td>0.507301</td>\n",
       "      <td>0.552885</td>\n",
       "      <td>0.579897</td>\n",
       "      <td>0.763763</td>\n",
       "      <td>0.847152</td>\n",
       "      <td>0.763796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
       "      <td>1.559238</td>\n",
       "      <td>1.270549</td>\n",
       "      <td>1.252646</td>\n",
       "      <td>1.330892</td>\n",
       "      <td>1.898072</td>\n",
       "      <td>2.564652</td>\n",
       "      <td>3.052837</td>\n",
       "      <td>2.042812</td>\n",
       "      <td>1.363894</td>\n",
       "      <td>...</td>\n",
       "      <td>1.839892</td>\n",
       "      <td>2.361975</td>\n",
       "      <td>2.955681</td>\n",
       "      <td>1.676101</td>\n",
       "      <td>1.351872</td>\n",
       "      <td>1.334344</td>\n",
       "      <td>1.445189</td>\n",
       "      <td>1.930474</td>\n",
       "      <td>2.746842</td>\n",
       "      <td>2.685529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
       "      <td>0.994387</td>\n",
       "      <td>0.963645</td>\n",
       "      <td>0.905887</td>\n",
       "      <td>0.991271</td>\n",
       "      <td>1.120635</td>\n",
       "      <td>1.497103</td>\n",
       "      <td>1.559617</td>\n",
       "      <td>1.212098</td>\n",
       "      <td>0.995127</td>\n",
       "      <td>...</td>\n",
       "      <td>1.190287</td>\n",
       "      <td>1.565588</td>\n",
       "      <td>1.609874</td>\n",
       "      <td>1.069912</td>\n",
       "      <td>0.990129</td>\n",
       "      <td>1.008256</td>\n",
       "      <td>1.124766</td>\n",
       "      <td>1.342855</td>\n",
       "      <td>1.639730</td>\n",
       "      <td>1.402877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        F1        F2        F3        F4  \\\n",
       "0  HOBBIES_1_001_CA_1_evaluation  0.958572  0.776854  0.795831  0.809182   \n",
       "1  HOBBIES_1_002_CA_1_evaluation  0.238108  0.187746  0.202934  0.190623   \n",
       "2  HOBBIES_1_003_CA_1_evaluation  0.539878  0.489011  0.523984  0.526887   \n",
       "3  HOBBIES_1_004_CA_1_evaluation  1.559238  1.270549  1.252646  1.330892   \n",
       "4  HOBBIES_1_005_CA_1_evaluation  0.994387  0.963645  0.905887  0.991271   \n",
       "\n",
       "         F5        F6        F7        F8        F9  ...       F19       F20  \\\n",
       "0  1.126867  1.265218  1.174310  1.080325  0.883443  ...  1.035435  1.276392   \n",
       "1  0.229802  0.299991  0.313969  0.228468  0.208481  ...  0.291811  0.364425   \n",
       "2  0.674716  0.898484  0.788505  0.570668  0.608901  ...  0.721518  0.795368   \n",
       "3  1.898072  2.564652  3.052837  2.042812  1.363894  ...  1.839892  2.361975   \n",
       "4  1.120635  1.497103  1.559617  1.212098  0.995127  ...  1.190287  1.565588   \n",
       "\n",
       "        F21       F22       F23       F24       F25       F26       F27  \\\n",
       "0  1.127642  0.971120  0.906212  0.860976  0.947063  1.228143  1.309055   \n",
       "1  0.346255  0.227300  0.220785  0.208741  0.251313  0.271761  0.348970   \n",
       "2  0.758040  0.581762  0.507301  0.552885  0.579897  0.763763  0.847152   \n",
       "3  2.955681  1.676101  1.351872  1.334344  1.445189  1.930474  2.746842   \n",
       "4  1.609874  1.069912  0.990129  1.008256  1.124766  1.342855  1.639730   \n",
       "\n",
       "        F28  \n",
       "0  1.101408  \n",
       "1  0.380125  \n",
       "2  0.763796  \n",
       "3  2.685529  \n",
       "4  1.402877  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Export\n",
    "#################################################################################\n",
    "# Reading competition sample submission and\n",
    "# merging our predictions\n",
    "# As we have predictions only for \"_validation\" data\n",
    "# we need to do fillna() for \"_evaluation\" items\n",
    "submission = pd.read_csv('../inputs/sample_submission.csv')[['id']]\n",
    "submission = submission.merge(all_preds, on=['id'], how='left').fillna(0)\n",
    "submission.to_csv('submission_v'+str(VER)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "\n",
    "# Of course here is no magic at all.\n",
    "# No \"Novel\" features and no brilliant ideas.\n",
    "# We just carefully joined all\n",
    "# our previous fe work and created a model.\n",
    "\n",
    "# Also!\n",
    "# In my opinion this strategy is a \"dead end\".\n",
    "# Overfits a lot LB and with 1 final submission \n",
    "# you have no option to risk.\n",
    "\n",
    "\n",
    "# Improvement should come from:\n",
    "# Loss function\n",
    "# Data representation\n",
    "# Stable CV\n",
    "# Good features reduction strategy\n",
    "# Predictions stabilization with NN\n",
    "# Trend prediction\n",
    "# Real zero sales detection/classification\n",
    "\n",
    "\n",
    "# Good kernels references \n",
    "## (the order is random and the list is not complete):\n",
    "# https://www.kaggle.com/ragnar123/simple-lgbm-groupkfold-cv\n",
    "# https://www.kaggle.com/jpmiller/grouping-items-by-stockout-pattern\n",
    "# https://www.kaggle.com/headsortails/back-to-predict-the-future-interactive-m5-eda\n",
    "# https://www.kaggle.com/sibmike/m5-out-of-stock-feature\n",
    "# https://www.kaggle.com/mayer79/m5-forecast-attack-of-the-data-table\n",
    "# https://www.kaggle.com/yassinealouini/seq2seq\n",
    "# https://www.kaggle.com/kailex/m5-forecaster-v2\n",
    "# https://www.kaggle.com/aerdem4/m5-lofo-importance-on-gpu-via-rapids-xgboost\n",
    "\n",
    "\n",
    "# Features were created in these kernels:\n",
    "## \n",
    "# Mean encodings and PCA options\n",
    "# https://www.kaggle.com/kyakovlev/m5-custom-features\n",
    "##\n",
    "# Lags and rolling lags\n",
    "# https://www.kaggle.com/kyakovlev/m5-lags-features\n",
    "##\n",
    "# Base Grid and base features (calendar/price/etc)\n",
    "# https://www.kaggle.com/kyakovlev/m5-simple-fe\n",
    "\n",
    "\n",
    "# Personal request\n",
    "# Please don't upvote any ensemble and copypaste kernels\n",
    "## The worst case is ensemble without any analyse.\n",
    "## The best choice - just ignore it.\n",
    "## I would like to see more kernels with interesting and original approaches.\n",
    "## Don't feed copypasters with upvotes.\n",
    "\n",
    "## It doesn't mean that you should not fork and improve others kernels\n",
    "## but I would like to see params and code tuning based on some CV and analyse\n",
    "## and not only on LB probing.\n",
    "## Small changes could be shared in comments and authors can improve their kernel.\n",
    "\n",
    "## Feel free to criticize this kernel as my knowlege is very limited\n",
    "## and I can be wrong in code and descriptions. \n",
    "## Thank you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
