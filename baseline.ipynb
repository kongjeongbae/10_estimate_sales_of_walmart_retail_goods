{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시계열 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 라이브러리 로드 및 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 라이브러리 로드 및 메모리 감소 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "def write_record(features, params):\n",
    "    record = open(\"record model and features.txt\", 'a')\n",
    "    record.write(\"\\n\")\n",
    "    record.write(str(datetime.datetime.now())+\"\\n\")\n",
    "\n",
    "    check = 0\n",
    "    for _ in features:\n",
    "        check += 1\n",
    "        if check % 5 == 0:\n",
    "            record.write(\"\\n\")\n",
    "        record.write(_+\"  \")\n",
    "    record.write(\"\\n\")\n",
    "    for i  in params.items():\n",
    "        record.write(str(i) + \"\\n\")\n",
    "\n",
    "    record.write('--------------------------------\\n')\n",
    "    record.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 데이터 불러오기 및 pd.melt를 활용해 데이터 정렬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare training and test data.\n",
    "- 2011-01-29 ~ 2016-04-24 : d_1    ~ d_1913\n",
    "- 2016-04-25 ~ 2016-05-22 : d_1914 ~ d_1941 (public)\n",
    "- 2016-05-23 ~ 2016-06-19 : d_1942 ~ d_1969 (private)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('inputs/sales_train_validation.csv')\n",
    "train = pd.melt(train, id_vars=['id','item_id','dept_id','cat_id','store_id','state_id'], var_name='d', value_name='target')\n",
    "\n",
    "test = pd.read_csv('inputs/sample_submission.csv')\n",
    "test2 = test[30490:]\n",
    "\n",
    "test = test[:30490]\n",
    "test = pd.melt(test, id_vars=['id'], var_name='d', value_name='target')\n",
    "for i in range(1, 29):\n",
    "    test = test.replace({f'F{i}': f'd_{1913+i}'})\n",
    "\n",
    "test[['cat_id', 'dept_id', 'item_id', 'state_id', 'store_id', 'tmp']] = pd.DataFrame(test['id'].str.split('_').tolist())\n",
    "del test['tmp']\n",
    "test['store_id'] = test['state_id'] + '_' + test['store_id']\n",
    "test['dept_id'] = test['cat_id'] + '_' + test['dept_id']\n",
    "test['item_id'] = test['dept_id'] + '_' + test['item_id']\n",
    "\n",
    "test = test[train.columns]\n",
    "\n",
    "calendar = pd.read_csv('inputs/calendar.csv')\n",
    "\n",
    "sell_prices = pd.read_csv('inputs/sell_prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 탐색"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아웃라이어를 제거해서 boxplot 더 잘보이게끔\n",
    "train200 = train[train['target'] < 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 419)\n",
    "pd.DataFrame(train['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "display(\n",
    "    train[train['target'] == 763],\n",
    "    train[train['id'] == 'FOODS_3_090_CA_3_validation'],\n",
    "    sns.distplot(train[train['id'] == 'FOODS_3_090_CA_3_validation']['target'])    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "display(\n",
    "    train[train['target'] == 370],\n",
    "    train[train['id'] == 'FOODS_3_318_CA_3_validation'],\n",
    "    sns.distplot(train[train['id'] == 'FOODS_3_318_CA_3_validation']['target'])    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train[train['target'] == 763]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 시간 오래걸림\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "# sns.distplot(train['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.groupby('id')['target'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('item_id')['target'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['item_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 dept_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.groupby('dept_id')['target'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['dept_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.boxplot(train['dept_id'], train200['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 cat_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('cat_id')['target'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['cat_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.6 store_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.groupby('store_id')['target'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['store_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "store_id 를 기준으로 10가지 모델을 만들어봐도 좋을 듯 싶다.  \n",
    "우선 검증을 해야함. 각각이 많이 다른지부터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.7 state_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('state_id')['target'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['state_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.8 d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.groupby('d')['target'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대부분 date 데이터고, event 및 snap(정부보조금 적용되는 날)에 집중해보자.\n",
    "- event_name_2가 너무 적다. 우선을 빼고 모델 만들어 볼 것임.\n",
    "- 이벤트 유무(is_event) 컬럼 만들 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar = calendar.drop(['event_name_2', 'event_type_2'], axis=1)\n",
    "calendar['is_event'] = calendar['event_name_1'].notna().astype('int8')\n",
    "del calendar['wday']\n",
    "del calendar['wm_yr_wk'] # 모든 주차에 인덱스 붙여놓음. 282개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar['day'] = calendar['date'].astype('datetime64').dt.day\n",
    "calendar['week'] = calendar['date'].astype('datetime64').dt.week\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(calendar, how='left')\n",
    "test = test.merge(calendar, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['day'] = train['date'].astype('datetime64').dt.day\n",
    "test['day'] = test['date'].astype('datetime64').dt.day\n",
    "\n",
    "train['week'] = train['date'].astype('datetime64').dt.week\n",
    "test['week'] = test['date'].astype('datetime64').dt.week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 sell_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_prices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_prices.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sell_prices['wm_yr_wk'].unique():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_prices.groupby('wm_yr_wk')['sell_price'].mean().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.lineplot(range(len(sell_prices.groupby('wm_yr_wk')['sell_price'].mean())), list(sell_prices.groupby('wm_yr_wk')['sell_price'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 피쳐 엔지니어링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare training and test data.\n",
    "- 2011-01-29 ~ 2016-04-24 : d_1    ~ d_1913\n",
    "- 2016-04-25 ~ 2016-05-22 : d_1914 ~ d_1941 (public)\n",
    "- 2016-05-23 ~ 2016-06-19 : d_1942 ~ d_1969 (private)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     18,
     46
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import TimeSeriesSplit, KFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "def write_record(features, params):\n",
    "    record = open(\"record model and features.txt\", 'a')\n",
    "    record.write(\"\\n\")\n",
    "    record.write(str(datetime.datetime.now())+\"\\n\")\n",
    "\n",
    "    check = 0\n",
    "    for _ in features:\n",
    "        check += 1\n",
    "        if check % 5 == 0:\n",
    "            record.write(\"\\n\")\n",
    "        record.write(_+\"  \")\n",
    "    record.write(\"\\n\")\n",
    "    for i  in params.items():\n",
    "        record.write(str(i) + \"\\n\")\n",
    "\n",
    "    record.write('--------------------------------\\n')\n",
    "    record.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 3226.27 Mb (9.4% reduction)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('inputs/sales_train_validation.csv')\n",
    "train = pd.melt(train, id_vars=['id','item_id','dept_id','cat_id','store_id','state_id'], var_name='d', value_name='target')\n",
    "train = reduce_mem_usage(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 46.41 Mb (10.9% reduction)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('inputs/sample_submission.csv')\n",
    "test = test[:30490]\n",
    "test = pd.melt(test, id_vars=['id'], var_name='d', value_name='target')\n",
    "for i in range(1, 29):\n",
    "    test = test.replace({f'F{i}': f'd_{1913+i}'})\n",
    "\n",
    "test[['cat_id', 'dept_id', 'item_id', 'state_id', 'store_id', 'tmp']] = pd.DataFrame(test['id'].str.split('_').tolist())\n",
    "del test['tmp']\n",
    "test['store_id'] = test['state_id'] + '_' + test['store_id']\n",
    "test['dept_id'] = test['cat_id'] + '_' + test['dept_id']\n",
    "test['item_id'] = test['dept_id'] + '_' + test['item_id']\n",
    "\n",
    "test = test[train.columns]\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 calendar (date 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar = pd.read_csv('inputs/calendar.csv')\n",
    "\n",
    "calendar = calendar.drop(['event_name_2', 'event_type_2'], axis=1)\n",
    "calendar['is_event'] = calendar['event_name_1'].notna().astype('int8')\n",
    "del calendar['wday']  # weekday랑 똑같은 컬럼.\n",
    "calendar['day'] = calendar['date'].astype('datetime64').dt.day\n",
    "calendar['week'] = calendar['date'].astype('datetime64').dt.week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(calendar, how='left')\n",
    "test = test.merge(calendar, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 sell_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_prices = pd.read_csv('inputs/sell_prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(sell_prices, on = ['store_id', 'item_id', 'wm_yr_wk'], how = 'left')\n",
    "test = test.merge(sell_prices, on = ['store_id', 'item_id', 'wm_yr_wk'], how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 라벨인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_df = pd.concat([train, test])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "for i in all_df.columns[all_df.dtypes == 'object']:\n",
    "    if i == 'id' or i == 'date':\n",
    "        continue\n",
    "    all_df[i] = le.fit_transform(list(all_df[i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 lag 데이터 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 2821.97 Mb (70.8% reduction)\n"
     ]
    }
   ],
   "source": [
    "all_df = reduce_mem_usage(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 3612.13 Mb (39.6% reduction)\n",
      "Mem. usage decreased to 4740.92 Mb (41.7% reduction)\n",
      "Mem. usage decreased to 5869.71 Mb (36.6% reduction)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 29):\n",
    "    all_df[f'lag_t{i}'] = all_df.groupby(['id'])['target'].transform(lambda x: x.shift(i)).fillna(-i)\n",
    "    \n",
    "    if i % 10 == 7:\n",
    "        all_df = reduce_mem_usage(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# all_df['lag_t28'] = all_df.groupby(['id'])['target'].transform(lambda x: x.shift(28))\n",
    "# all_df['lag_t29'] = all_df.groupby(['id'])['target'].transform(lambda x: x.shift(29))\n",
    "# all_df['lag_t30'] = all_df.groupby(['id'])['target'].transform(lambda x: x.shift(30))\n",
    "\n",
    "# # 새롭게 만들 거\n",
    "# all_df['lag_t24'] = all_df.groupby(['id'])['target'].transform(lambda x: x.shift(24))\n",
    "# all_df['lag_t25'] = all_df.groupby(['id'])['target'].transform(lambda x: x.shift(25))\n",
    "# all_df['lag_t26'] = all_df.groupby(['id'])['target'].transform(lambda x: x.shift(26))\n",
    "# all_df['lag_t27'] = all_df.groupby(['id'])['target'].transform(lambda x: x.shift(27))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 이동평균 피처"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish!!\n"
     ]
    }
   ],
   "source": [
    "weeks = [7, 28, 56, 84, 112, 168]\n",
    "for i in weeks:\n",
    "    all_df[f'rolling_mean_t{i}'] = all_df.groupby(['id'])['target'].transform(lambda x: x.shift(28).rolling(i).mean())\n",
    "    all_df[f'rolling_std_t{i}'] = all_df.groupby(['id'])['target'].transform(lambda x: x.shift(28).rolling(i).std())\n",
    "#     all_df = reduce_mem_usage(all_df)\n",
    "print('finish!!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 price 통계량 피쳐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = reduce_mem_usage(all_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_df['lag_price_t1'] = all_df.groupby(['id'])['sell_price'].transform(lambda x: x.shift(1))\n",
    "\n",
    "# all_df['price_change_t1'] = (all_df['lag_price_t1'] - all_df['sell_price']) / (all_df['lag_price_t1'])\n",
    "\n",
    "# all_df['rolling_price_max_t365'] = all_df.groupby(['id'])['sell_price'].transform(lambda x: x.shift(1).rolling(365).max())\n",
    "\n",
    "# all_df['price_change_t365'] = (all_df['rolling_price_max_t365'] - all_df['sell_price']) / (all_df['rolling_price_max_t365'])\n",
    "\n",
    "# all_df['rolling_price_std_t7'] = all_df.groupby(['id'])['sell_price'].transform(lambda x: x.rolling(7).std())\n",
    "\n",
    "# 새롭게 만들거\n",
    "# all_df['rolling_price_std_t32'] = all_df.groupby(['id'])['sell_price'].transform(lambda x: x.rolling(32).std())\n",
    "\n",
    "all_df['rolling_price_std_t28'] = all_df.groupby(['id'])['sell_price'].transform(lambda x: x.rolling(28).std())\n",
    "# all_df = reduce_mem_usage(all_df)\n",
    "\n",
    "\n",
    "all_df2 = all_df.drop(['rolling_price_max_t365', 'lag_price_t1'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df2 = all_df.drop(['rolling_price_max_t365', 'lag_price_t1'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>target</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>is_event</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>lag_t1</th>\n",
       "      <th>lag_t2</th>\n",
       "      <th>lag_t3</th>\n",
       "      <th>lag_t4</th>\n",
       "      <th>lag_t5</th>\n",
       "      <th>lag_t6</th>\n",
       "      <th>lag_t7</th>\n",
       "      <th>lag_t8</th>\n",
       "      <th>lag_t9</th>\n",
       "      <th>lag_t10</th>\n",
       "      <th>lag_t11</th>\n",
       "      <th>lag_t12</th>\n",
       "      <th>lag_t13</th>\n",
       "      <th>lag_t14</th>\n",
       "      <th>lag_t15</th>\n",
       "      <th>lag_t16</th>\n",
       "      <th>lag_t17</th>\n",
       "      <th>lag_t18</th>\n",
       "      <th>lag_t19</th>\n",
       "      <th>lag_t20</th>\n",
       "      <th>lag_t21</th>\n",
       "      <th>lag_t22</th>\n",
       "      <th>lag_t23</th>\n",
       "      <th>lag_t24</th>\n",
       "      <th>lag_t25</th>\n",
       "      <th>lag_t26</th>\n",
       "      <th>lag_t27</th>\n",
       "      <th>lag_t28</th>\n",
       "      <th>rolling_mean_t7</th>\n",
       "      <th>rolling_std_t7</th>\n",
       "      <th>rolling_mean_t28</th>\n",
       "      <th>rolling_std_t28</th>\n",
       "      <th>rolling_mean_t56</th>\n",
       "      <th>rolling_std_t56</th>\n",
       "      <th>rolling_mean_t84</th>\n",
       "      <th>rolling_std_t84</th>\n",
       "      <th>rolling_mean_t112</th>\n",
       "      <th>rolling_std_t112</th>\n",
       "      <th>rolling_mean_t168</th>\n",
       "      <th>rolling_std_t168</th>\n",
       "      <th>price_change_t1</th>\n",
       "      <th>price_change_t365</th>\n",
       "      <th>rolling_price_std_t7</th>\n",
       "      <th>rolling_price_std_t28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>11101</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>-26.0</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  item_id  dept_id  cat_id  store_id  \\\n",
       "0  HOBBIES_1_001_CA_1_validation     1437        3       1         0   \n",
       "1  HOBBIES_1_002_CA_1_validation     1438        3       1         0   \n",
       "2  HOBBIES_1_003_CA_1_validation     1439        3       1         0   \n",
       "3  HOBBIES_1_004_CA_1_validation     1440        3       1         0   \n",
       "4  HOBBIES_1_005_CA_1_validation     1441        3       1         0   \n",
       "\n",
       "   state_id  d  target        date  wm_yr_wk  weekday  month  year  \\\n",
       "0         0  0       0  2011-01-29     11101        2      1  2011   \n",
       "1         0  0       0  2011-01-29     11101        2      1  2011   \n",
       "2         0  0       0  2011-01-29     11101        2      1  2011   \n",
       "3         0  0       0  2011-01-29     11101        2      1  2011   \n",
       "4         0  0       0  2011-01-29     11101        2      1  2011   \n",
       "\n",
       "   event_name_1  event_type_1  snap_CA  snap_TX  snap_WI  is_event  day  week  \\\n",
       "0            30             4        0        0        0         0   29     4   \n",
       "1            30             4        0        0        0         0   29     4   \n",
       "2            30             4        0        0        0         0   29     4   \n",
       "3            30             4        0        0        0         0   29     4   \n",
       "4            30             4        0        0        0         0   29     4   \n",
       "\n",
       "   sell_price  lag_t1  lag_t2  lag_t3  lag_t4  lag_t5  lag_t6  lag_t7  lag_t8  \\\n",
       "0         NaN    -1.0    -2.0    -3.0    -4.0    -5.0    -6.0    -7.0    -8.0   \n",
       "1         NaN    -1.0    -2.0    -3.0    -4.0    -5.0    -6.0    -7.0    -8.0   \n",
       "2         NaN    -1.0    -2.0    -3.0    -4.0    -5.0    -6.0    -7.0    -8.0   \n",
       "3         NaN    -1.0    -2.0    -3.0    -4.0    -5.0    -6.0    -7.0    -8.0   \n",
       "4         NaN    -1.0    -2.0    -3.0    -4.0    -5.0    -6.0    -7.0    -8.0   \n",
       "\n",
       "   lag_t9  lag_t10  lag_t11  lag_t12  lag_t13  lag_t14  lag_t15  lag_t16  \\\n",
       "0    -9.0    -10.0    -11.0    -12.0    -13.0    -14.0    -15.0    -16.0   \n",
       "1    -9.0    -10.0    -11.0    -12.0    -13.0    -14.0    -15.0    -16.0   \n",
       "2    -9.0    -10.0    -11.0    -12.0    -13.0    -14.0    -15.0    -16.0   \n",
       "3    -9.0    -10.0    -11.0    -12.0    -13.0    -14.0    -15.0    -16.0   \n",
       "4    -9.0    -10.0    -11.0    -12.0    -13.0    -14.0    -15.0    -16.0   \n",
       "\n",
       "   lag_t17  lag_t18  lag_t19  lag_t20  lag_t21  lag_t22  lag_t23  lag_t24  \\\n",
       "0    -17.0    -18.0    -19.0    -20.0    -21.0    -22.0    -23.0    -24.0   \n",
       "1    -17.0    -18.0    -19.0    -20.0    -21.0    -22.0    -23.0    -24.0   \n",
       "2    -17.0    -18.0    -19.0    -20.0    -21.0    -22.0    -23.0    -24.0   \n",
       "3    -17.0    -18.0    -19.0    -20.0    -21.0    -22.0    -23.0    -24.0   \n",
       "4    -17.0    -18.0    -19.0    -20.0    -21.0    -22.0    -23.0    -24.0   \n",
       "\n",
       "   lag_t25  lag_t26  lag_t27  lag_t28  rolling_mean_t7  rolling_std_t7  \\\n",
       "0    -25.0    -26.0    -27.0    -28.0              NaN             NaN   \n",
       "1    -25.0    -26.0    -27.0    -28.0              NaN             NaN   \n",
       "2    -25.0    -26.0    -27.0    -28.0              NaN             NaN   \n",
       "3    -25.0    -26.0    -27.0    -28.0              NaN             NaN   \n",
       "4    -25.0    -26.0    -27.0    -28.0              NaN             NaN   \n",
       "\n",
       "   rolling_mean_t28  rolling_std_t28  rolling_mean_t56  rolling_std_t56  \\\n",
       "0               NaN              NaN               NaN              NaN   \n",
       "1               NaN              NaN               NaN              NaN   \n",
       "2               NaN              NaN               NaN              NaN   \n",
       "3               NaN              NaN               NaN              NaN   \n",
       "4               NaN              NaN               NaN              NaN   \n",
       "\n",
       "   rolling_mean_t84  rolling_std_t84  rolling_mean_t112  rolling_std_t112  \\\n",
       "0               NaN              NaN                NaN               NaN   \n",
       "1               NaN              NaN                NaN               NaN   \n",
       "2               NaN              NaN                NaN               NaN   \n",
       "3               NaN              NaN                NaN               NaN   \n",
       "4               NaN              NaN                NaN               NaN   \n",
       "\n",
       "   rolling_mean_t168  rolling_std_t168  price_change_t1  price_change_t365  \\\n",
       "0                NaN               NaN              NaN                NaN   \n",
       "1                NaN               NaN              NaN                NaN   \n",
       "2                NaN               NaN              NaN                NaN   \n",
       "3                NaN               NaN              NaN                NaN   \n",
       "4                NaN               NaN              NaN                NaN   \n",
       "\n",
       "   rolling_price_std_t7  rolling_price_std_t28  \n",
       "0                   NaN                    NaN  \n",
       "1                   NaN                    NaN  \n",
       "2                   NaN                    NaN  \n",
       "3                   NaN                    NaN  \n",
       "4                   NaN                    NaN  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 8014.41 Mb (0.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "all_df = reduce_mem_usage(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('inputs/all_df4.pickle', 'wb') as f:\n",
    "    pickle.dump(all_df2, f, protocol=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open('inputs/all_df.pickle', 'rb') as f:\n",
    "    all_df = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 모델 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# rf = RandomForestRegressor(n_estimators=100, n_jobs=-1)\n",
    "# rf.fit(train2, np.log(train['target'] + 1))\n",
    "# result = rf.predict(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lightgbm import LGBMRegressor\n",
    "# # lgb = LGBMRegressor(num_leaves=2000, colsample_bytree=0.6, subsample=0.6, n_estimators=600, learning_rate=0.025, n_jobs=-1, device='gpu', max_bin = 63)\n",
    "# lgb = LGBMRegressor(num_leaves=20, colsample_bytree=0.6, subsample=0.6, n_estimators=60, learning_rate=0.02, n_jobs=-1, device='cpu')\n",
    "\n",
    "# lgb.fit(train, target)\n",
    "# result = lgb.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 KFold - LGBM 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import gc\n",
    "\n",
    "features = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'year', 'month', 'week', 'day', 'weekday', 'event_name_1', 'event_type_1',  \n",
    "            'snap_CA', 'snap_TX', 'snap_WI', 'sell_price', 'lag_t28', 'lag_t29', 'lag_t30', 'rolling_mean_t7', 'rolling_std_t7', 'rolling_mean_t30', 'rolling_mean_t90', \n",
    "            'rolling_mean_t180', 'rolling_std_t30', 'price_change_t1', 'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t30']\n",
    "\n",
    "# 나중에 합칠 때 필요해서 test에 선언\n",
    "test = all_df[len(train):]\n",
    "\n",
    "train_set_X = all_df[:len(train)]\n",
    "train_set_y = train_set_X['target']\n",
    "\n",
    "train_set_X = train_set_X[features]\n",
    "\n",
    "# 테스트 셋\n",
    "test_set = all_df[len(train):]\n",
    "test_set = test_set[features]\n",
    "\n",
    "del all_df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 2\n",
    "folds = KFold(n_splits=n_fold, shuffle=True)\n",
    "splits = folds.split(train_set_X, train_set_y)\n",
    "\n",
    "y_preds = np.zeros(test.shape[0])\n",
    "y_oof = np.zeros(train.shape[0])\n",
    "\n",
    "feature_importances = pd.DataFrame()\n",
    "feature_importances['feature'] = train_set_X.columns\n",
    "mean_score = []\n",
    "eval_results = []\n",
    "\n",
    "for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "    \n",
    "    print('Fold:',fold_n+1)\n",
    "    \n",
    "    X_train, X_valid = train_set_X.iloc[train_index], train_set_X.iloc[valid_index]\n",
    "    y_train, y_valid = train_set_y.iloc[train_index], train_set_y.iloc[valid_index]\n",
    "    \n",
    "    lgb = LGBMRegressor(\n",
    "        boosting_type = 'gbdt',\n",
    "        num_leaves = 400,\n",
    "        colsample_bytree = 0.8,\n",
    "        subsample = 0.8,\n",
    "        n_estimators = 20,\n",
    "        learning_rate = 0.01,\n",
    "        n_jobs = -1,\n",
    "        device = 'gpu'\n",
    "    )\n",
    "    lgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], early_stopping_rounds = 50, verbose = True)\n",
    "    eval_results.append(lgb.evals_result_)\n",
    "    # 피쳐중요도 작성\n",
    "    feature_importances[f'fold_{fold_n + 1}'] = lgb.feature_importances_\n",
    "    \n",
    "    # validation predict\n",
    "    y_pred_valid = lgb.predict(X_valid, num_iteration=lgb.best_iteration_)\n",
    "\n",
    "    y_oof[valid_index] = y_pred_valid\n",
    "    \n",
    "    val_score = np.sqrt(metrics.mean_squared_error(y_pred_valid, y_valid))\n",
    "    \n",
    "    print(f'val rmse score is {val_score}')\n",
    "    \n",
    "    mean_score.append(val_score)\n",
    "    \n",
    "    y_preds += lgb.predict(test_set, num_iteration=lgb.best_iteration_) / n_fold\n",
    "    \n",
    "    del X_train, X_valid, y_train, y_valid\n",
    "\n",
    "print('mean rmse score over folds is',np.mean(mean_score))\n",
    "test['target'] = y_preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = list(eval_results[0]['valid_0'].values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp = list(eval_results[1]['valid_0'].values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results[0].values().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_set_X.columns\n",
    "params = lgb.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 KFold - XGB 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = reduce_mem_usage(all_df)\n",
    "\n",
    "test = all_df[len(train):]\n",
    "\n",
    "features = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'year', 'month', 'week', 'day', 'weekday', 'event_name_1', 'event_type_1',  \n",
    "            'snap_CA', 'snap_TX', 'snap_WI', 'sell_price']\n",
    "\n",
    "\n",
    "\n",
    "train_set_X = all_df[:len(train)]\n",
    "train_set_y = train_set_X['target']\n",
    "\n",
    "train_set_X = train_set_X[features]\n",
    "\n",
    "# 테스트 셋\n",
    "test_set = all_df[len(train):]\n",
    "test_set = test_set[features]\n",
    "\n",
    "del all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_X['sell_price'] = train_set_X['sell_price'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "n_fold = 5\n",
    "folds = KFold(n_splits=5, shuffle=True)\n",
    "splits = folds.split(train_set_X, train_set_y)\n",
    "\n",
    "y_preds = np.zeros(test.shape[0])\n",
    "# y_oof = np.zeros(train.shape[0])\n",
    "\n",
    "feature_importances = pd.DataFrame()\n",
    "feature_importances['feature'] = train_set_X.columns\n",
    "mean_score = []\n",
    "\n",
    "# dtest = xgb.DMatrix(data=test_set)\n",
    "\n",
    "\n",
    "for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "    print('Fold:',fold_n+1)\n",
    "    \n",
    "    X_train, X_valid = train_set_X.iloc[train_index], train_set_X.iloc[valid_index]\n",
    "    y_train, y_valid = train_set_y.iloc[train_index], train_set_y.iloc[valid_index]\n",
    "    \n",
    "    \n",
    "    xgb_model = xgb.XGBRegressor(colsample_bytree = 0.8, learning_rate = 0.02,subsample=0.8,\n",
    "                max_depth = 12, n_estimators = 4000, tree_method='gpu_hist')\n",
    "    \n",
    "    xgb_model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], early_stopping_rounds=50)\n",
    "    \n",
    "    # 피쳐중요도 작성\n",
    "    feature_importances[f'fold_{fold_n + 1}'] = xgb_model.feature_importances_\n",
    "    \n",
    "    # validation predict\n",
    "    y_pred_valid = xgb_model.predict(X_valid)\n",
    "    # y_oof[valid_index] = y_pred_valid\n",
    "    val_score = np.sqrt(metrics.mean_squared_error(y_pred_valid, y_valid))\n",
    "    print(f'val rmse score is {val_score}')\n",
    "\n",
    "    # test 값 예측\n",
    "    y_preds += xgb_model.predict(test_set) / n_fold\n",
    "    del X_train, X_valid, y_train, y_valid, y_pred_valid, val_score\n",
    "\n",
    "print('mean rmse score over folds is',np.mean(mean_score))\n",
    "test['target'] = y_preds\n",
    "\n",
    "features = train_set_X.columns\n",
    "params = xgb_model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 TimeSeriesSplit - LGBM 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_fold = 10\n",
    "# folds = TimeSeriesSplit(n_splits=n_fold)\n",
    "# splits = folds.split(train_set_X, train_set_y)\n",
    "\n",
    "# y_preds = np.zeros(test.shape[0])\n",
    "# y_oof = np.zeros(train.shape[0])\n",
    "\n",
    "# feature_importances = pd.DataFrame()\n",
    "# feature_importances['feature'] = train_set_X.columns\n",
    "# mean_score = []\n",
    "\n",
    "# for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "#     print('Fold:',fold_n+1)\n",
    "    \n",
    "#     X_train, X_valid = train_set_X.iloc[train_index], train_set_X.iloc[valid_index]\n",
    "#     y_train, y_valid = train_set_y.iloc[train_index], train_set_y.iloc[valid_index]\n",
    "    \n",
    "#     lgb = LGBMRegressor(\n",
    "#         num_leaves = 1000,\n",
    "#         colsample_bytree = 0.8,\n",
    "#         subsample = 0.8,\n",
    "#         n_estimators = 2500,\n",
    "#         learning_rate = 0.01,\n",
    "#         n_jobs = -1,\n",
    "#         device = 'cpu'\n",
    "#     )\n",
    "    \n",
    "#     lgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], early_stopping_rounds = 50, verbose = False)\n",
    "\n",
    "#     feature_importances[f'fold_{fold_n + 1}'] = lgb.feature_importances_\n",
    "    \n",
    "#     y_pred_valid = lgb.predict(X_valid, num_iteration=lgb.best_iteration_)\n",
    "    \n",
    "#     y_oof[valid_index] = y_pred_valid\n",
    "    \n",
    "#     val_score = np.sqrt(metrics.mean_squared_error(y_pred_valid, y_valid))\n",
    "    \n",
    "#     print(f'val rmse score is {val_score}')\n",
    "    \n",
    "#     mean_score.append(val_score)\n",
    "    \n",
    "#     y_preds += lgb.predict(test_set, num_iteration=lgb.best_iteration_) / n_fold\n",
    "    \n",
    "#     del X_train, X_valid, y_train, y_valid\n",
    "\n",
    "# print('mean rmse score over folds is',np.mean(mean_score))\n",
    "\n",
    "# test['target'] = y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 feature_importance 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 예측 및 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('inputs/sample_submission.csv')\n",
    "\n",
    "predictions = test[['id', 'date', 'target']]\n",
    "predictions = pd.pivot(predictions, index = 'id', columns = 'date', values = 'target').reset_index()\n",
    "predictions.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "\n",
    "evaluation_rows = [row for row in sub['id'] if 'evaluation' in row] \n",
    "evaluation = sub[sub['id'].isin(evaluation_rows)]\n",
    "\n",
    "validation = sub[['id']].merge(predictions, on = 'id')\n",
    "final = pd.concat([validation, evaluation])\n",
    "final.to_csv('submissions/submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/m5-forecasting-accuracy/submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2)\n",
    "os.chdir(\"submissions\")\n",
    "!kaggle competitions submit -c m5-forecasting-accuracy -f submission.csv -m lgb\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 모델 파라미터, 피처 기록 및 모델 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_record(features, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# save model\n",
    "# joblib.dump(lgb, 'models/lgb1.pkl')\n",
    "# load model\n",
    "# lgb = joblib.load('models/lgb.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
