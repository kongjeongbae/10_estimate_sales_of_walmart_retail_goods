{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M5 Forecast: Poisson Loss\n",
    "\n",
    "This kernel serves as a Python translation of my [data.table](https://www.kaggle.com/mayer79/m5-forecast-attack-of-the-data-table) script, including the [dark magic](https://www.kaggle.com/kyakovlev/m5-dark-magic) calibration step. The results are not identical though.\n",
    "\n",
    "Feature construction and lightGBM parameters were influenced by the two excellent kernels [Very fst Model](https://www.kaggle.com/ragnar123/very-fst-model) and [M5 ForecasteR](https://www.kaggle.com/kailex/m5-forecaster-0-57330).\n",
    "\n",
    "One of the major performance boosts of the [data.table](https://www.kaggle.com/mayer79/m5-forecast-attack-of-the-data-table) script came from switching to Poisson loss. As far as I know, that kernel was the first public one to use this loss. Poisson loss is a typical way to model counts (e.g. number of sold items) and amounts to optimize the same objective function as a Poisson regression, i.e. the log likelihood derived from the Poisson distribution, or, (up to a constant) the Poisson deviance. The latter is defined as\n",
    "$$\n",
    "\\sum_{observations} \\left(y \\log\\frac{y}{predicted} - (y - predicted)\\right),\n",
    "$$\n",
    "where the second part cancels out for an unbiased model.\n",
    "\n",
    "Interestingly and in contrast to using MSE loss, it seems to work very well together with above mentioned [dark magic](https://www.kaggle.com/kyakovlev/m5-dark-magic) calibration step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"inputs/\"\n",
    "\n",
    "calendar = pd.read_csv(os.path.join(path, \"calendar.csv\"))\n",
    "selling_prices = pd.read_csv(os.path.join(path, \"sell_prices.csv\"))\n",
    "sample_submission = pd.read_csv(os.path.join(path, \"sample_submission.csv\"))\n",
    "sales = pd.read_csv(os.path.join(path, \"sales_train_validation.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe and prepare data\n",
    "\n",
    "We will now go through all data sets and prepare them for modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calendar data\n",
    "\n",
    "For each date (covering both training and test data), we have access to useful calendar information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "def prep_calendar(df):\n",
    "    df = df.drop([\"weekday\", \"event_name_2\", \"event_type_2\"], axis=1)\n",
    "    df = df.assign(d = df.d.str[2:].astype(int))\n",
    "    to_ordinal = [\"event_name_1\", \"event_type_1\"] \n",
    "    df[to_ordinal] = df[to_ordinal].fillna(\"1\")\n",
    "    df[to_ordinal] = OrdinalEncoder(dtype=\"int\").fit_transform(df[to_ordinal]) + 1\n",
    "    to_int8 = [\"wday\", \"month\", \"snap_CA\", \"snap_TX\", \"snap_WI\"] + to_ordinal\n",
    "    df[to_int8] = df[to_int8].astype(\"int8\")\n",
    "    return df\n",
    "\n",
    "calendar = prep_calendar(calendar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selling prices\n",
    "\n",
    "Contains selling prices for each store_id, item_id_wm_yr_wk combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selling_prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derive some time related features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_selling_prices(df):\n",
    "    gr = df.groupby([\"store_id\", \"item_id\"])[\"sell_price\"]\n",
    "    df[\"sell_price_rel_diff\"] = gr.pct_change()\n",
    "    df[\"sell_price_cumrel\"] = (gr.shift(0) - gr.cummin()) / (1 + gr.cummax() - gr.cummin())\n",
    "    df[\"sell_price_roll_sd7\"] = gr.transform(lambda x: x.rolling(7).std())\n",
    "    to_float32 = [\"sell_price\", \"sell_price_rel_diff\", \"sell_price_cumrel\", \"sell_price_roll_sd7\"]\n",
    "    df[to_float32] = df[to_float32].astype(\"float32\")\n",
    "         \n",
    "    return df\n",
    "\n",
    "selling_prices = prep_selling_prices(selling_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales data\n",
    "\n",
    "Contains the number of sold items (= our response) as well as some categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping\n",
    "\n",
    "We now reshape the data from wide to long, using \"id\" as fixed and swapping \"d_x\" columns. Along this process, we also add structure for submission data and reduce data size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_sales(df, drop_d = None):\n",
    "    if drop_d is not None:\n",
    "        df = df.drop([\"d_\" + str(i+1) for i in range(drop_d-1)], axis=1)\n",
    "    df = df.assign(id=df.id.str.replace(\"_validation\", \"\"))\n",
    "    df = df.reindex(columns=df.columns.tolist() + [\"d_\" + str(1913 + i + 1) for i in range(2 * 28)])\n",
    "    df = df.melt(id_vars=[\"id\", \"item_id\", \"dept_id\", \"cat_id\", \"store_id\", \"state_id\"],\n",
    "                 var_name='d', value_name='demand')\n",
    "    df = df.assign(d=df.d.str[2:].astype(\"int64\"))\n",
    "\n",
    "    return df\n",
    "\n",
    "sales = reshape_sales(sales, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add time-lagged features\n",
    "\n",
    "Add some of the derived features from kernel https://www.kaggle.com/ragnar123/very-fst-model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_sales(df):\n",
    "    df['lag_t28'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28))\n",
    "    df['lag_t29'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(29))\n",
    "    df['lag_t30'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(30))\n",
    "    df['lag_t31'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(31))\n",
    "\n",
    "    df['rolling_mean_t7'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(7).mean())\n",
    "    df['rolling_mean_t30'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(30).mean())\n",
    "    df['rolling_mean_t60'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(60).mean())\n",
    "    df['rolling_mean_t90'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(90).mean())\n",
    "    df['rolling_mean_t180'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(180).mean())\n",
    "    df['rolling_std_t7'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(7).std())\n",
    "    df['rolling_std_t30'] = df.groupby(['id'])['demand'].transform(lambda x: x.shift(28).rolling(30).std())\n",
    "  \n",
    "    to_float32 = ['lag_t28', 'rolling_mean_t7', 'rolling_mean_t30', 'rolling_mean_t60', \n",
    "                  'rolling_mean_t90', 'rolling_mean_t180', 'rolling_std_t7', 'rolling_std_t30']\n",
    "    df[to_float32] = df[to_float32].astype(\"float32\")\n",
    "    \n",
    "    # Remove rows with NAs except for submission rows. rolling_mean_t180 was selected as it produces most missings\n",
    "    df = df[(df.d >= 1914) | (pd.notna(df.rolling_mean_t180))]\n",
    " \n",
    "    return df\n",
    "\n",
    "sales = prep_sales(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = sales.merge(calendar, how=\"left\", on=\"d\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = sales.merge(selling_prices, how=\"left\", on=[\"store_id\", \"item_id\", \"wm_yr_wk\"])\n",
    "sales.drop([\"wm_yr_wk\"], axis=1, inplace=True)\n",
    "gc.collect()\n",
    "del selling_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sales['week'] = sales['date'].astype('datetime64').dt.week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['weekofmonth'] = np.ceil(sales['wday'] // 7).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['day'] = sales['date'].astype('datetime64').dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = sales['week'] == 13\n",
    "c2 = sales['week'] == 14\n",
    "c3 = sales['week'] == 15\n",
    "c4 = sales['week'] == 16\n",
    "\n",
    "c5 = sales['week'] == 17\n",
    "c6 = sales['week'] == 18\n",
    "c7 = sales['week'] == 19\n",
    "c8 = sales['week'] == 20\n",
    "\n",
    "sales = sales[c1 | c2 | c3 | c4 | c5 | c6 | c7 | c8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for LightGBM interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal encoding of remaining categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, v in tqdm(enumerate([\"item_id\", \"dept_id\", \"store_id\", \"cat_id\", \"state_id\"])):\n",
    "    sales[v] = OrdinalEncoder(dtype=\"int\").fit_transform(sales[[v]]).astype(\"int16\") + 1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariables used\n",
    "x = ['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id',\n",
    "       'lag_t28', 'lag_t29', 'lag_t30', 'lag_t31', 'rolling_mean_t7',\n",
    "       'rolling_mean_t30', 'rolling_mean_t60', 'rolling_mean_t90',\n",
    "       'rolling_mean_t180', 'rolling_std_t7', 'rolling_std_t30',\n",
    "       'wday', 'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA',\n",
    "       'snap_TX', 'snap_WI', 'sell_price', 'sell_price_rel_diff',\n",
    "       'sell_price_cumrel', 'sell_price_roll_sd7', 'week', 'weekofmonth',\n",
    "       'day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate submission data and reconstruct id columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sales[sales.d >= 1914]\n",
    "test = test.assign(id=test.id + \"_\" + np.where(test.d <= 1941, \"validation\", \"evaluation\"),\n",
    "                   F=\"F\" + (test.d - 1913 - 28 * (test.d > 1941)).astype(\"str\"))\n",
    "\n",
    "# Reduce sales\n",
    "sales1 = sales[sales.d < 1914]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One month of validation data\n",
    "flag = sales1.d >= 1914 - 28\n",
    "valid = lgb.Dataset(sales1[flag][x], label = sales1[[\"demand\"]][flag])\n",
    "gc.collect()\n",
    "\n",
    "# Rest is used for training\n",
    "sales1 = sales1[~flag].drop([\"d\", \"id\"], axis=1)\n",
    "del flag\n",
    "gc.collect()\n",
    "sales1 = lgb.Dataset(sales1[x], label = sales1[[\"demand\"]])\n",
    "\n",
    "# Trick to avoid memory spike when LightGBM converts everything to float32:\n",
    "#   See https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/discussion/53773\n",
    "sales1.save_binary('train.bin')\n",
    "sales1 = lgb.Dataset('train.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'metric': 'rmse',\n",
    "    'objective': 'poisson',\n",
    "    'seed': 20,\n",
    "    'learning_rate': 0.08,\n",
    "    'lambda': 0.1,\n",
    "    'num_leaves': 63,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 1, \n",
    "    'colsample_bytree': 0.7\n",
    "}\n",
    "\n",
    "fit = lgb.train(params, \n",
    "                sales1, \n",
    "                num_boost_round = 2100, \n",
    "                valid_sets = [valid], \n",
    "                early_stopping_rounds = 400,\n",
    "                verbose_eval = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import TimeSeriesSplit, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold, shuffle=True)\n",
    "splits = folds.split(sales[x], sales[[\"demand\"]])\n",
    "\n",
    "y_preds = np.zeros(test_set.shape[0])\n",
    "y_oof = np.zeros(train_set_X.shape[0])\n",
    "\n",
    "feature_importances = pd.DataFrame()\n",
    "feature_importances['feature'] = train_set_X.columns\n",
    "mean_score = []\n",
    "\n",
    "print(train_set_X.columns)\n",
    "\n",
    "for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "    print('Fold:',fold_n+1)\n",
    "    \n",
    "    X_train, X_valid = sales[x].iloc[train_index], sales[x].iloc[valid_index]\n",
    "    y_train, y_valid = sales[[\"demand\"]].iloc[train_index], sales[[\"demand\"]].iloc[valid_index]\n",
    "    \n",
    "    sales = lgb.Dataset(X_train, label = y_train)\n",
    "    sales.save_binary('train.bin')\n",
    "    sales = lgb.Dataset('train.bin')\n",
    "    \n",
    "    fit = lgb.train(params, \n",
    "                sales, \n",
    "                num_boost_round = 2100, \n",
    "                valid_sets = [valid], \n",
    "                early_stopping_rounds = 400,\n",
    "                verbose_eval = 100)\n",
    "\n",
    "    pred = fit.predict(test[x])\n",
    "    \n",
    "    # 예측\n",
    "    y_preds += pred / n_fold\n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(fit, importance_type=\"gain\", precision=0, height=0.5, figsize=(6, 10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"demand\"] = y_preds\n",
    "submission = test.pivot(index=\"id\", columns=\"F\", values=\"demand\").reset_index()[sample_submission.columns]\n",
    "\n",
    "for i in range(1,29):\n",
    "    submission['F'+str(i)] *= 1.0315\n",
    "    submission.to_csv('submissions/submission.csv', index = False)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "22887a747e674859b712c401f8b0c1eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b993b63f3f724ad4b31f2f38e8e38e8d",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ec965887f255411996c3b659333c5118",
       "value": 1
      }
     },
     "2f11e44efa91407ba36898350ce65cd3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4ab501de287940588f65f15d83cc21ed",
       "placeholder": "​",
       "style": "IPY_MODEL_351ef721a1424937a0cc44503f077527",
       "value": " 5/? [01:09&lt;00:00, 13.99s/it]"
      }
     },
     "351ef721a1424937a0cc44503f077527": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4ab501de287940588f65f15d83cc21ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b993b63f3f724ad4b31f2f38e8e38e8d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bbe90c5fb0914a6e8b0bae509aa0943d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ec965887f255411996c3b659333c5118": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "f474e16ad9504611b0e4b98dadf08b9a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_22887a747e674859b712c401f8b0c1eb",
        "IPY_MODEL_2f11e44efa91407ba36898350ce65cd3"
       ],
       "layout": "IPY_MODEL_bbe90c5fb0914a6e8b0bae509aa0943d"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
