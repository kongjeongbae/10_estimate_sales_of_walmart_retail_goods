{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모든 시간대를 대상으로 하는 것이 아닌, 예측해야하는 시간대의 target이 비슷한 데이터를 바탕으로\n",
    "- 2016-04-25 ~ 2016-05-22 : d_1914 ~ d_1941 (public)\n",
    "- 2016-05-23 ~ 2016-06-19 : d_1942 ~ d_1969 (private)\n",
    "- 모델을 제작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/yassinealouini/trends-per-store  \n",
    "{'CA_1': 1.4515535682921805,  \n",
    " 'CA_2': 1.2478469436321578,  \n",
    " 'CA_3': 2.0503897391977617,  \n",
    " 'CA_4': 0.8015278327204106,  \n",
    " 'TX_1': 1.0426264577891047,  \n",
    " 'TX_2': 1.2509886678837656,  \n",
    " 'TX_3': 1.2319171250395966,  \n",
    " 'WI_1': 1.1729008570725148,  \n",
    " 'WI_2': 1.416137702642638,  \n",
    " 'WI_3': 1.1452668162125874}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 라이브러리 로드 및 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import TimeSeriesSplit, KFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle \n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from mypackage import *\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style=\"color:red\">파일명 체크!!!</div>\n",
    "- all_df: 기초작업 수준. \n",
    "- all_df4: lag 데이터 엄청 많이 만들어 놓은 것.\n",
    "- all_df5: 'id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'd', 'sales', 'date', 'wm_yr_wk', 'weekday', 'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX', 'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'revenue', sales_rolling_mean_t7', 'rolling_mean_t7', 'rolling_std_t7', 'sales_rolling_mean_t28', 'rolling_mean_t28', 'rolling_std_t28', 'sales_rolling_mean_t56', 'rolling_mean_t56', 'rolling_std_t56', 'sales_rolling_mean_t112','rolling_mean_t112', 'rolling_std_t112', 'sales_rolling_mean_t168', 'rolling_mean_t168', 'rolling_std_t168', 'lag_t28', 'lag_t29', 'lag_t30', 'lag_t31', 'lag_t32', 'lag_t33', 'lag_t34', 'revenue_lag_t28', 'revenue_lag_t29', 'revenue_lag_t30','revenue_lag_t31', 'revenue_lag_t32', 'revenue_lag_t33', 'revenue_lag_t34'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('data loading')\n",
    "with open('inputs/all_df.pickle', 'rb') as f:\n",
    "    all_df = pickle.load(f)\n",
    "print('data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['weekofmonth'] = np.ceil(all_df['day'] // 7).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = all_df['week'] == 13\n",
    "c2 = all_df['week'] == 14\n",
    "c3 = all_df['week'] == 15\n",
    "c4 = all_df['week'] == 16\n",
    "\n",
    "c5 = all_df['week'] == 17\n",
    "c6 = all_df['week'] == 18\n",
    "c7 = all_df['week'] == 19\n",
    "c8 = all_df['week'] == 20\n",
    "\n",
    "all_df2 = all_df[c1 | c2 | c3 | c4 | c5 | c6 | c7 | c8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_id = LabelEncoder()\n",
    "le_id.fit(all_df2['id'])\n",
    "\n",
    "all_df2['id'] = le_id.transform(all_df2['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df2.columns = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'd',\n",
    "       'sales', 'date', 'wm_yr_wk', 'weekday', 'month', 'year',\n",
    "       'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX', 'snap_WI',\n",
    "       'is_event', 'day', 'week', 'sell_price', 'lag_t28', 'lag_t29',\n",
    "       'lag_t30', 'lag_t24', 'lag_t25', 'lag_t26', 'lag_t27',\n",
    "       'rolling_mean_t7', 'rolling_std_t7', 'rolling_mean_t30',\n",
    "       'rolling_std_t30', 'rolling_mean_t90', 'rolling_mean_t180',\n",
    "       'rolling_mean_t60', 'rolling_std_t60', 'lag_price_t1',\n",
    "       'price_change_t1', 'rolling_price_max_t365', 'price_change_t365',\n",
    "       'rolling_price_std_t7', 'rolling_price_std_t30', 'weekofmonth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id_gb_sell_price_mean = all_df2.groupby(['id', 'year', 'week'])['sell_price'].mean().rename('item_id_gb_sell_price_mean')\n",
    "all_df2 = pd.merge(all_df2, item_id_gb_sell_price_mean, on=['id', 'year', 'week'], how='left')\n",
    "\n",
    "item_id_gb_sell_price_std = all_df2.groupby(['id', 'year', 'week'])['sell_price'].std().rename('item_id_gb_sell_price_std')\n",
    "all_df2 = pd.merge(all_df2, item_id_gb_sell_price_std, on=['id', 'year', 'week'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['d', 'sales', 'store_id', 'snap_CA', 'snap_TX', 'snap_WI', 'state_id', 'date', 'wm_yr_wk', 'is_event' ,'lag_t24', 'lag_t25', 'lag_t26', 'lag_t27', 'lag_price_t1', 'rolling_price_max_t365']\n",
    "\n",
    "features = all_df2.columns.drop(drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stores = []\n",
    "test_index = []\n",
    "for i in range(10):\n",
    "    all_df3 = all_df2[all_df2.store_id == i]\n",
    "    \n",
    "    train_set = all_df3[all_df3['date'] <= '2016-04-24']\n",
    "    train_set_X = train_set[features]\n",
    "    train_set_y = train_set['sales']\n",
    "\n",
    "    # 테스트 셋\n",
    "    test = all_df3[all_df3['date'] > '2016-04-24']\n",
    "    test_set = test[features]\n",
    "    test_index.append(test.index)\n",
    "\n",
    "    var_set = all_df3[(all_df3['date'] > '2015-04-27') & (all_df3['date'] <= '2015-05-22')]\n",
    "    var_set_X = var_set[features]\n",
    "    var_set_y = var_set['sales']\n",
    "    \n",
    "    \n",
    "    \n",
    "    n_fold = 2\n",
    "    folds = KFold(n_splits=n_fold, shuffle=True)\n",
    "    splits = folds.split(train_set_X, train_set_y)\n",
    "\n",
    "    y_preds = np.zeros(test_set.shape[0])\n",
    "\n",
    "\n",
    "    for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "        print('Fold:',fold_n+1)\n",
    "\n",
    "        X_train, X_valid = train_set_X.iloc[train_index], train_set_X.iloc[valid_index]\n",
    "        y_train, y_valid = train_set_y.iloc[train_index], train_set_y.iloc[valid_index]\n",
    "\n",
    "        lgb = LGBMRegressor(\n",
    "            objective = 'regression',\n",
    "            boosting_type = 'gbdt',\n",
    "            num_leaves = 2048,\n",
    "            colsample_bytree = 0.8,\n",
    "            subsample = 0.8,\n",
    "            n_estimators = 600, ## 중요!!!!\n",
    "            learning_rate = 0.05,\n",
    "            n_jobs = -1,\n",
    "            reg_lambda = 0.1,\n",
    "            device = 'gpu'\n",
    "        )\n",
    "        lgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], early_stopping_rounds = 20, verbose = True)\n",
    "\n",
    "\n",
    "        # 예측\n",
    "        y_preds += lgb.predict(test_set, num_iteration=lgb.best_iteration_) / n_fold\n",
    "\n",
    "        # 메모리 정리\n",
    "        del X_train, X_valid, y_train, y_valid\n",
    "\n",
    "\n",
    "\n",
    "    stores.append(y_preds)\n",
    "    print(pd.DataFrame(lgb.feature_importances_, index=features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0번 - 14.8375 5.29964  \n",
    "1번 - 6.80630 3.22881  \n",
    "2번 - 30.5934 8.55259  \n",
    "3번 - 3.67819 1.82227  \n",
    "4번 - 10.6207 4.35351  \n",
    "5번 - 15.6138 4.49576  \n",
    "6번 - 12.2176 3.38841  \n",
    "7번 - 5.10856 2.16503  \n",
    "8번 - 12.8646 5.08373  \n",
    "9번 - 13.4699 4.28131  \n",
    "\n",
    "2번이 문제임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 8))\n",
    "i = 3\n",
    "all_df3 = all_df2[all_df2.store_id == i]\n",
    "all_df3 = all_df3[all_df3.date < '2016-04-24']\n",
    "sns.lineplot(x=all_df3_train.groupby('date')['sales'].mean().index, y=all_df3_train.groupby('date')['sales'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df3_train.groupby('date')['sales'].mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df4_train.groupby('date')['sales'].mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df5_train.groupby('date')['sales'].mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 8))\n",
    "sns.boxplot(all_df3_train.weekofmonth, all_df3_train.sales, showfliers=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df3_train.groupby('snap_WI')['sales'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df3_train.snap_WI.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df3_train[all_df3_train.sales < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df3_train[all_df3_train.weekday == 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_df_1 = all_df2[all_df2.store_id == 1]\n",
    "all_df_2 = all_df2[all_df2.store_id == 2]\n",
    "all_df_3 = all_df2[all_df2.store_id == 3]\n",
    "all_df_4 = all_df2[all_df2.store_id == 4]\n",
    "all_df_5 = all_df2[all_df2.store_id == 5]\n",
    "all_df_6 = all_df2[all_df2.store_id == 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "all_df_1.groupby('dept_id')['sales'].mean(),\n",
    "all_df_2.groupby('dept_id')['sales'].mean(),\n",
    "all_df_3.groupby('dept_id')['sales'].mean(),\n",
    "all_df_4.groupby('dept_id')['sales'].mean(),\n",
    "all_df_5.groupby('dept_id')['sales'].mean(),\n",
    "all_df_6.groupby('dept_id')['sales'].mean(),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = [all_df_1, all_df_2, all_df_3, all_df_4, all_df_5, all_df_6]\n",
    "for i in tmp:\n",
    "    print(len(i[(i.dept_id == 2) & (i.sales > 50)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_df2[(all_df2.item_id == 1361) & (all_df2.sales > 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores = []\n",
    "test_index = []\n",
    "all_df3 = all_df2[all_df2.store_id == 2]\n",
    "\n",
    "train_set = all_df3[all_df3['date'] <= '2016-04-24']\n",
    "train_set_X = train_set[features]\n",
    "train_set_y = train_set['sales']\n",
    "\n",
    "# 테스트 셋\n",
    "test = all_df3[all_df3['date'] > '2016-04-24']\n",
    "test_set = test[features]\n",
    "test_index.append(test.index)\n",
    "\n",
    "var_set = all_df3[(all_df3['date'] > '2015-04-27') & (all_df3['date'] <= '2015-05-22')]\n",
    "var_set_X = var_set[features]\n",
    "var_set_y = var_set['sales']\n",
    "\n",
    "\n",
    "\n",
    "n_fold = 2\n",
    "folds = KFold(n_splits=n_fold, shuffle=True)\n",
    "splits = folds.split(train_set_X, train_set_y)\n",
    "\n",
    "y_preds = np.zeros(test_set.shape[0])\n",
    "\n",
    "\n",
    "for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "    print('Fold:',fold_n+1)\n",
    "\n",
    "    X_train, X_valid = train_set_X.iloc[train_index], train_set_X.iloc[valid_index]\n",
    "    y_train, y_valid = train_set_y.iloc[train_index], train_set_y.iloc[valid_index]\n",
    "\n",
    "    lgb = LGBMRegressor(\n",
    "        objective = 'regression',\n",
    "        boosting_type = 'gbdt',\n",
    "        num_leaves = 2048,\n",
    "        colsample_bytree = 0.8,\n",
    "        subsample = 0.8,\n",
    "        n_estimators = 600, ## 중요!!!!\n",
    "        learning_rate = 0.05,\n",
    "        n_jobs = -1,\n",
    "        reg_lambda = 10,\n",
    "        device = 'gpu'\n",
    "    )\n",
    "    lgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], early_stopping_rounds = 20, verbose = True)\n",
    "\n",
    "\n",
    "    # 예측\n",
    "    y_preds += lgb.predict(test_set, num_iteration=lgb.best_iteration_) / n_fold\n",
    "\n",
    "    # 메모리 정리\n",
    "    del X_train, X_valid, y_train, y_valid\n",
    "\n",
    "\n",
    "\n",
    "stores.append(y_preds)\n",
    "print(pd.DataFrame(lgb.feature_importances_, index=features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_index = [all_df2[all_df2.store_id == i].index for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_v = []\n",
    "for i in stores:\n",
    "    for j in i:\n",
    "        s_v.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_i = []\n",
    "for i in range(10):\n",
    "    for j in test_index:\n",
    "        s_i.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict = pd.DataFrame(s_v, index=s_i, columns=['sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df2_test = all_df22[all_df22.date  > '2016-04-24']\n",
    "del all_df2_test['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df2_test = pd.merge(all_df2_test, predict, left_index=True, right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('inputs/sample_submission.csv')\n",
    "\n",
    "predictions = all_df2_test[['id', 'date', 'sales']]\n",
    "predictions['id'] = list(le_id.inverse_transform(predictions['id']))\n",
    "\n",
    "\n",
    "predictions = pd.pivot(predictions, index = 'id', columns = 'date', values = 'sales').reset_index()\n",
    "predictions.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "\n",
    "evaluation_rows = [row for row in sub['id'] if 'evaluation' in row] \n",
    "evaluation = sub[sub['id'].isin(evaluation_rows)]\n",
    "\n",
    "validation = sub[['id']].merge(predictions, on = 'id')\n",
    "final = pd.concat([validation, evaluation])\n",
    "\n",
    "for i in range(1,29):\n",
    "    final['F'+str(i)] *= 1.0315\n",
    "final.to_csv('submissions/submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/m5-forecasting-accuracy/submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time.sleep(2)\n",
    "os.chdir(\"submissions\")\n",
    "!kaggle competitions submit -c m5-forecasting-accuracy -f submission.csv -m lgb\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 파라미터 및 피처 기록 및 모델 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "write_params_features(features, params, eval_results, mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_feature_importance(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1등 노트북이랑 비교해서 카테고리형 피처 빠진거있나 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "324px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
