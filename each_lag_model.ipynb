{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lag1부터 시작하는, lag2 부터 시작하는.... 28개의 모델을 만드는 모델을 만들어보자.\n",
    "\n",
    "- 모든 시간대를 대상으로 하는 것이 아닌, 예측해야하는 시간대의 target이 비슷한 데이터를 바탕으로\n",
    "- 2016-04-25 ~ 2016-05-22 : d_1914 ~ d_1941 (public)\n",
    "- 2016-05-23 ~ 2016-06-19 : d_1942 ~ d_1969 (private)\n",
    "- 모델을 제작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 라이브러리 로드 및 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import TimeSeriesSplit, KFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle \n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from mypackage import *\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <div style=\"color:red\">파일명 체크!!!</div>\n",
    "- all_df: 기초작업 수준. \n",
    "- all_df4: lag 데이터 엄청 많이 만들어 놓은 것.\n",
    "- all_df5: 'id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'd', 'sales', 'date', 'wm_yr_wk', 'weekday', 'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX', 'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'revenue', sales_rolling_mean_t7', 'rolling_mean_t7', 'rolling_std_t7', 'sales_rolling_mean_t28', 'rolling_mean_t28', 'rolling_std_t28', 'sales_rolling_mean_t56', 'rolling_mean_t56', 'rolling_std_t56', 'sales_rolling_mean_t112','rolling_mean_t112', 'rolling_std_t112', 'sales_rolling_mean_t168', 'rolling_mean_t168', 'rolling_std_t168', 'lag_t28', 'lag_t29', 'lag_t30', 'lag_t31', 'lag_t32', 'lag_t33', 'lag_t34', 'revenue_lag_t28', 'revenue_lag_t29', 'revenue_lag_t30','revenue_lag_t31', 'revenue_lag_t32', 'revenue_lag_t33', 'revenue_lag_t34'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loading\n",
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "print('data loading')\n",
    "with open('inputs/all_df4.pickle', 'rb') as f:\n",
    "    all_df = pickle.load(f)\n",
    "print('data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_df.columns = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'd',\n",
    "       'sales', 'date', 'wm_yr_wk', 'weekday', 'month', 'year',\n",
    "       'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX', 'snap_WI',\n",
    "       'is_event', 'day', 'week', 'sell_price', 'lag_t1', 'lag_t2', 'lag_t3',\n",
    "       'lag_t4', 'lag_t5', 'lag_t6', 'lag_t7', 'lag_t8', 'lag_t9', 'lag_t10',\n",
    "       'lag_t11', 'lag_t12', 'lag_t13', 'lag_t14', 'lag_t15', 'lag_t16',\n",
    "       'lag_t17', 'lag_t18', 'lag_t19', 'lag_t20', 'lag_t21', 'lag_t22',\n",
    "       'lag_t23', 'lag_t24', 'lag_t25', 'lag_t26', 'lag_t27', 'lag_t28',\n",
    "       'rolling_mean_t7', 'rolling_std_t7', 'rolling_mean_t28',\n",
    "       'rolling_std_t28', 'rolling_mean_t56', 'rolling_std_t56',\n",
    "       'rolling_mean_t84', 'rolling_std_t84', 'rolling_mean_t112',\n",
    "       'rolling_std_t112', 'rolling_mean_t168', 'rolling_std_t168',\n",
    "       'price_change_t1', 'price_change_t365', 'rolling_price_std_t7',\n",
    "       'rolling_price_std_t28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(29, 33):\n",
    "    all_df[f'lag_t{i}'] = all_df.groupby(['id'])['sales'].transform(lambda x: x.shift(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['rolling_price_max_t180'] = all_df.groupby(['id'])['sell_price'].transform(lambda x: x.shift(1).rolling(365).max())\n",
    "\n",
    "all_df['price_change_t180'] = (all_df['rolling_price_max_t180'] - all_df['sell_price']) / (all_df['rolling_price_max_t180'])\n",
    "\n",
    "del all_df['rolling_price_max_t180']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['rolling_price_max_t365'] = all_df.groupby(['id'])['sell_price'].transform(lambda x: x.shift(1).rolling(365).max())\n",
    "\n",
    "all_df['price_diff_t365'] = all_df['rolling_price_max_t365'] - all_df['sell_price']\n",
    "\n",
    "del all_df['rolling_price_max_t365']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['rolling_price_max_t180'] = all_df.groupby(['id'])['sell_price'].transform(lambda x: x.shift(1).rolling(365).max())\n",
    "\n",
    "all_df['price_change_t180']a = (all_df['rolling_price_max_t180'] - all_df['sell_price']) / (all_df['rolling_price_max_t180'])\n",
    "\n",
    "del all_df['rolling_price_max_t180']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['rolling_price_max_t60'] = all_df.groupby(['id'])['sell_price'].transform(lambda x: x.shift(1).rolling(365).max())\n",
    "\n",
    "all_df['price_change_t60'] = (all_df['rolling_price_max_t60'] - all_df['sell_price']) / (all_df['rolling_price_max_t60'])\n",
    "\n",
    "del all_df['rolling_price_max_t60']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['rolling_price_max_t28'] = all_df.groupby(['id'])['sell_price'].transform(lambda x: x.shift(1).rolling(365).max())\n",
    "\n",
    "all_df['price_change_t28'] = (all_df['rolling_price_max_t28'] - all_df['sell_price']) / (all_df['rolling_price_max_t28'])\n",
    "\n",
    "del all_df['rolling_price_max_t28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df['rolling_price_std_t56'] = all_df.groupby(['id'])['sell_price'].transform(lambda x: x.rolling(56).std())\n",
    "all_df['rolling_price_std_t112'] = all_df.groupby(['id'])['sell_price'].transform(lambda x: x.rolling(112).std())\n",
    "all_df['rolling_price_std_t168'] = all_df.groupby(['id'])['sell_price'].transform(lambda x: x.rolling(168).std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 탐색"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서는 test셋과 비슷한 시간대를 찾아서, 이 데이터만을 바탕으로 모델을 만들것임.  \n",
    "\n",
    "test: 2016-04-25 ~ 2016-05-22  17~20주차 (16주차나 21주차까지 늘려야될지도 생각해보자)\n",
    "\n",
    "---\n",
    "train: 2015-04-27 ~ 2015-05-24  \n",
    "train: 2014-04-28 ~ 2014-05-25  / 2014-04-21 ~ 2014-05-18\n",
    "train: 2013-04-27 ~ 2013-05-24  \n",
    "train: 2012-04-27 ~ 2012-05-24 \n",
    "train: 2011-04-27 ~ 2011-05-24 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c00 = all_df['week'] == 9\n",
    "# c01 = all_df['week'] == 10\n",
    "# c02 = all_df['week'] == 11\n",
    "# c03 = all_df['week'] == 12\n",
    "\n",
    "c1 = all_df['week'] == 13\n",
    "c2 = all_df['week'] == 14\n",
    "c3 = all_df['week'] == 15\n",
    "c4 = all_df['week'] == 16\n",
    "\n",
    "c5 = all_df['week'] == 17\n",
    "c6 = all_df['week'] == 18\n",
    "c7 = all_df['week'] == 19\n",
    "c8 = all_df['week'] == 20\n",
    "all_df17_20 = all_df[c1 | c2 | c3 | c4 | c5 | c6 | c7 | c8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>target</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>is_event</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>lag_t1</th>\n",
       "      <th>lag_t2</th>\n",
       "      <th>lag_t3</th>\n",
       "      <th>lag_t4</th>\n",
       "      <th>lag_t5</th>\n",
       "      <th>lag_t6</th>\n",
       "      <th>lag_t7</th>\n",
       "      <th>lag_t8</th>\n",
       "      <th>lag_t9</th>\n",
       "      <th>lag_t10</th>\n",
       "      <th>lag_t11</th>\n",
       "      <th>lag_t12</th>\n",
       "      <th>lag_t13</th>\n",
       "      <th>lag_t14</th>\n",
       "      <th>lag_t15</th>\n",
       "      <th>lag_t16</th>\n",
       "      <th>lag_t17</th>\n",
       "      <th>lag_t18</th>\n",
       "      <th>lag_t19</th>\n",
       "      <th>lag_t20</th>\n",
       "      <th>lag_t21</th>\n",
       "      <th>lag_t22</th>\n",
       "      <th>lag_t23</th>\n",
       "      <th>lag_t24</th>\n",
       "      <th>lag_t25</th>\n",
       "      <th>lag_t26</th>\n",
       "      <th>lag_t27</th>\n",
       "      <th>lag_t28</th>\n",
       "      <th>rolling_mean_t7</th>\n",
       "      <th>rolling_std_t7</th>\n",
       "      <th>rolling_mean_t28</th>\n",
       "      <th>rolling_std_t28</th>\n",
       "      <th>rolling_mean_t56</th>\n",
       "      <th>rolling_std_t56</th>\n",
       "      <th>rolling_mean_t84</th>\n",
       "      <th>rolling_std_t84</th>\n",
       "      <th>rolling_mean_t112</th>\n",
       "      <th>rolling_std_t112</th>\n",
       "      <th>rolling_mean_t168</th>\n",
       "      <th>rolling_std_t168</th>\n",
       "      <th>price_change_t1</th>\n",
       "      <th>price_change_t365</th>\n",
       "      <th>rolling_price_std_t7</th>\n",
       "      <th>rolling_price_std_t28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>853715</th>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>1432</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1047</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>2.980469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285645</td>\n",
       "      <td>0.488037</td>\n",
       "      <td>0.214233</td>\n",
       "      <td>0.567871</td>\n",
       "      <td>0.232178</td>\n",
       "      <td>0.571777</td>\n",
       "      <td>0.404785</td>\n",
       "      <td>0.823242</td>\n",
       "      <td>0.508789</td>\n",
       "      <td>1.013672</td>\n",
       "      <td>0.613281</td>\n",
       "      <td>0.990723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853716</th>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>1433</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1047</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>2.480469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142822</td>\n",
       "      <td>0.377930</td>\n",
       "      <td>0.321533</td>\n",
       "      <td>0.547852</td>\n",
       "      <td>0.160767</td>\n",
       "      <td>0.416748</td>\n",
       "      <td>0.107117</td>\n",
       "      <td>0.347656</td>\n",
       "      <td>0.080383</td>\n",
       "      <td>0.304199</td>\n",
       "      <td>0.053558</td>\n",
       "      <td>0.250977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.960464e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853717</th>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>1434</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1047</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>3.980469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571289</td>\n",
       "      <td>0.786621</td>\n",
       "      <td>0.893066</td>\n",
       "      <td>1.166016</td>\n",
       "      <td>1.071289</td>\n",
       "      <td>1.059570</td>\n",
       "      <td>0.928711</td>\n",
       "      <td>0.979004</td>\n",
       "      <td>0.893066</td>\n",
       "      <td>0.998535</td>\n",
       "      <td>0.797852</td>\n",
       "      <td>0.951172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.960464e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853718</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>1435</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1047</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>1.280273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.142578</td>\n",
       "      <td>1.344727</td>\n",
       "      <td>0.928711</td>\n",
       "      <td>1.051758</td>\n",
       "      <td>1.088867</td>\n",
       "      <td>1.066406</td>\n",
       "      <td>1.023438</td>\n",
       "      <td>1.097656</td>\n",
       "      <td>1.161133</td>\n",
       "      <td>1.326172</td>\n",
       "      <td>1.315430</td>\n",
       "      <td>1.567383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853719</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>1436</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1047</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>11617</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.071289</td>\n",
       "      <td>1.719727</td>\n",
       "      <td>1.517578</td>\n",
       "      <td>1.778320</td>\n",
       "      <td>1.536133</td>\n",
       "      <td>1.839844</td>\n",
       "      <td>1.588867</td>\n",
       "      <td>1.876953</td>\n",
       "      <td>1.494141</td>\n",
       "      <td>1.771484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  item_id  dept_id  cat_id  store_id  \\\n",
       "853715  FOODS_3_823_WI_3_validation     1432        2       0         9   \n",
       "853716  FOODS_3_824_WI_3_validation     1433        2       0         9   \n",
       "853717  FOODS_3_825_WI_3_validation     1434        2       0         9   \n",
       "853718  FOODS_3_826_WI_3_validation     1435        2       0         9   \n",
       "853719  FOODS_3_827_WI_3_validation     1436        2       0         9   \n",
       "\n",
       "        state_id     d  target        date  wm_yr_wk  weekday  month  year  \\\n",
       "853715         2  1047       0  2016-05-22     11617        3      5  2016   \n",
       "853716         2  1047       0  2016-05-22     11617        3      5  2016   \n",
       "853717         2  1047       0  2016-05-22     11617        3      5  2016   \n",
       "853718         2  1047       0  2016-05-22     11617        3      5  2016   \n",
       "853719         2  1047       0  2016-05-22     11617        3      5  2016   \n",
       "\n",
       "        event_name_1  event_type_1  snap_CA  snap_TX  snap_WI  is_event  day  \\\n",
       "853715            30             4        0        0        0         0   22   \n",
       "853716            30             4        0        0        0         0   22   \n",
       "853717            30             4        0        0        0         0   22   \n",
       "853718            30             4        0        0        0         0   22   \n",
       "853719            30             4        0        0        0         0   22   \n",
       "\n",
       "        week  sell_price  lag_t1  lag_t2  lag_t3  lag_t4  lag_t5  lag_t6  \\\n",
       "853715    20    2.980469     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "853716    20    2.480469     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "853717    20    3.980469     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "853718    20    1.280273     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "853719    20    1.000000     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "        lag_t7  lag_t8  lag_t9  lag_t10  lag_t11  lag_t12  lag_t13  lag_t14  \\\n",
       "853715     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "853716     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "853717     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "853718     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "853719     0.0     0.0     0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        lag_t15  lag_t16  lag_t17  lag_t18  lag_t19  lag_t20  lag_t21  \\\n",
       "853715      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "853716      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "853717      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "853718      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "853719      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        lag_t22  lag_t23  lag_t24  lag_t25  lag_t26  lag_t27  lag_t28  \\\n",
       "853715      0.0      0.0      0.0      0.0      0.0      0.0      1.0   \n",
       "853716      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "853717      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "853718      0.0      0.0      0.0      0.0      0.0      0.0      3.0   \n",
       "853719      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        rolling_mean_t7  rolling_std_t7  rolling_mean_t28  rolling_std_t28  \\\n",
       "853715         0.285645        0.488037          0.214233         0.567871   \n",
       "853716         0.142822        0.377930          0.321533         0.547852   \n",
       "853717         0.571289        0.786621          0.893066         1.166016   \n",
       "853718         1.142578        1.344727          0.928711         1.051758   \n",
       "853719         0.000000        0.000000          1.071289         1.719727   \n",
       "\n",
       "        rolling_mean_t56  rolling_std_t56  rolling_mean_t84  rolling_std_t84  \\\n",
       "853715          0.232178         0.571777          0.404785         0.823242   \n",
       "853716          0.160767         0.416748          0.107117         0.347656   \n",
       "853717          1.071289         1.059570          0.928711         0.979004   \n",
       "853718          1.088867         1.066406          1.023438         1.097656   \n",
       "853719          1.517578         1.778320          1.536133         1.839844   \n",
       "\n",
       "        rolling_mean_t112  rolling_std_t112  rolling_mean_t168  \\\n",
       "853715           0.508789          1.013672           0.613281   \n",
       "853716           0.080383          0.304199           0.053558   \n",
       "853717           0.893066          0.998535           0.797852   \n",
       "853718           1.161133          1.326172           1.315430   \n",
       "853719           1.588867          1.876953           1.494141   \n",
       "\n",
       "        rolling_std_t168  price_change_t1  price_change_t365  \\\n",
       "853715          0.990723              0.0                0.0   \n",
       "853716          0.250977              0.0                0.0   \n",
       "853717          0.951172              0.0                0.0   \n",
       "853718          1.567383              0.0                0.0   \n",
       "853719          1.771484              0.0                0.0   \n",
       "\n",
       "        rolling_price_std_t7  rolling_price_std_t28  \n",
       "853715          0.000000e+00           0.000000e+00  \n",
       "853716          5.960464e-08           0.000000e+00  \n",
       "853717          0.000000e+00           5.960464e-08  \n",
       "853718          0.000000e+00           0.000000e+00  \n",
       "853719          0.000000e+00           0.000000e+00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df17_20.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kjb\\data_analysis\\10_estimate_sales_of_walmart_retail_goods\\venv\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_id = LabelEncoder()\n",
    "all_df17_20['id'] = le_id.fit_transform(all_df17_20['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df2 = all_df17_20.drop(['d', 'sales', 'date', 'wm_yr_wk'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df2_X = all_df17_20[all_df17_20['date'] <= '2016-04-24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t1', 'lag_t2', 'lag_t3', 'lag_t4'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 11.8663\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4391\n",
      "[3]\tvalid_0's l2: 9.20356\n",
      "[4]\tvalid_0's l2: 8.22339\n",
      "[5]\tvalid_0's l2: 7.42522\n",
      "[6]\tvalid_0's l2: 6.76458\n",
      "[7]\tvalid_0's l2: 6.21828\n",
      "[8]\tvalid_0's l2: 5.78438\n",
      "[9]\tvalid_0's l2: 5.43837\n",
      "[10]\tvalid_0's l2: 5.13985\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.13985\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 11.4725\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.0782\n",
      "[3]\tvalid_0's l2: 8.86949\n",
      "[4]\tvalid_0's l2: 7.90022\n",
      "[5]\tvalid_0's l2: 7.11776\n",
      "[6]\tvalid_0's l2: 6.47487\n",
      "[7]\tvalid_0's l2: 5.94195\n",
      "[8]\tvalid_0's l2: 5.51932\n",
      "[9]\tvalid_0's l2: 5.18014\n",
      "[10]\tvalid_0's l2: 4.89126\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 4.89126\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 11.9181\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.5186\n",
      "[3]\tvalid_0's l2: 9.30865\n",
      "[4]\tvalid_0's l2: 8.34339\n",
      "[5]\tvalid_0's l2: 7.56112\n",
      "[6]\tvalid_0's l2: 6.9115\n",
      "[7]\tvalid_0's l2: 6.37498\n",
      "[8]\tvalid_0's l2: 5.95526\n",
      "[9]\tvalid_0's l2: 5.61426\n",
      "[10]\tvalid_0's l2: 5.32167\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.32167\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 11.6714\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.272\n",
      "[3]\tvalid_0's l2: 9.07237\n",
      "[4]\tvalid_0's l2: 8.10922\n",
      "[5]\tvalid_0's l2: 7.32584\n",
      "[6]\tvalid_0's l2: 6.67403\n",
      "[7]\tvalid_0's l2: 6.13937\n",
      "[8]\tvalid_0's l2: 5.71682\n",
      "[9]\tvalid_0's l2: 5.3737\n",
      "[10]\tvalid_0's l2: 5.07719\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.07719\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 11.7144\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.2948\n",
      "[3]\tvalid_0's l2: 9.06565\n",
      "[4]\tvalid_0's l2: 8.08625\n",
      "[5]\tvalid_0's l2: 7.2966\n",
      "[6]\tvalid_0's l2: 6.64323\n",
      "[7]\tvalid_0's l2: 6.09777\n",
      "[8]\tvalid_0's l2: 5.6716\n",
      "[9]\tvalid_0's l2: 5.32467\n",
      "[10]\tvalid_0's l2: 5.02438\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.02438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kjb\\data_analysis\\10_estimate_sales_of_walmart_retail_goods\\venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "c:\\users\\kjb\\data_analysis\\10_estimate_sales_of_walmart_retail_goods\\venv\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean rmse score over folds is nan\n",
      "2\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t2', 'lag_t3', 'lag_t4', 'lag_t5'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 11.7998\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4124\n",
      "[3]\tvalid_0's l2: 9.24214\n",
      "[4]\tvalid_0's l2: 8.31818\n",
      "[5]\tvalid_0's l2: 7.5583\n",
      "[6]\tvalid_0's l2: 6.91839\n",
      "[7]\tvalid_0's l2: 6.38993\n",
      "[8]\tvalid_0's l2: 5.98073\n",
      "[9]\tvalid_0's l2: 5.64766\n",
      "[10]\tvalid_0's l2: 5.35866\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.35866\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 11.8566\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4515\n",
      "[3]\tvalid_0's l2: 9.27461\n",
      "[4]\tvalid_0's l2: 8.33375\n",
      "[5]\tvalid_0's l2: 7.56712\n",
      "[6]\tvalid_0's l2: 6.92859\n",
      "[7]\tvalid_0's l2: 6.40155\n",
      "[8]\tvalid_0's l2: 5.98587\n",
      "[9]\tvalid_0's l2: 5.64812\n",
      "[10]\tvalid_0's l2: 5.35667\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.35667\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 11.5915\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.1993\n",
      "[3]\tvalid_0's l2: 9.02869\n",
      "[4]\tvalid_0's l2: 8.10506\n",
      "[5]\tvalid_0's l2: 7.35155\n",
      "[6]\tvalid_0's l2: 6.72039\n",
      "[7]\tvalid_0's l2: 6.20132\n",
      "[8]\tvalid_0's l2: 5.78982\n",
      "[9]\tvalid_0's l2: 5.45798\n",
      "[10]\tvalid_0's l2: 5.17145\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.17145\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 12.0945\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.6906\n",
      "[3]\tvalid_0's l2: 9.51751\n",
      "[4]\tvalid_0's l2: 8.57808\n",
      "[5]\tvalid_0's l2: 7.81729\n",
      "[6]\tvalid_0's l2: 7.17841\n",
      "[7]\tvalid_0's l2: 6.65019\n",
      "[8]\tvalid_0's l2: 6.23881\n",
      "[9]\tvalid_0's l2: 5.90246\n",
      "[10]\tvalid_0's l2: 5.60774\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.60774\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 11.6266\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.2359\n",
      "[3]\tvalid_0's l2: 9.06028\n",
      "[4]\tvalid_0's l2: 8.13357\n",
      "[5]\tvalid_0's l2: 7.37853\n",
      "[6]\tvalid_0's l2: 6.74918\n",
      "[7]\tvalid_0's l2: 6.22163\n",
      "[8]\tvalid_0's l2: 5.8172\n",
      "[9]\tvalid_0's l2: 5.48653\n",
      "[10]\tvalid_0's l2: 5.19714\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.19714\n",
      "mean rmse score over folds is nan\n",
      "3\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t3', 'lag_t4', 'lag_t5', 'lag_t6'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 11.4894\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.1227\n",
      "[3]\tvalid_0's l2: 8.98764\n",
      "[4]\tvalid_0's l2: 8.08179\n",
      "[5]\tvalid_0's l2: 7.34267\n",
      "[6]\tvalid_0's l2: 6.7389\n",
      "[7]\tvalid_0's l2: 6.2334\n",
      "[8]\tvalid_0's l2: 5.83376\n",
      "[9]\tvalid_0's l2: 5.50638\n",
      "[10]\tvalid_0's l2: 5.23106\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.23106\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 12.1666\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.7616\n",
      "[3]\tvalid_0's l2: 9.59342\n",
      "[4]\tvalid_0's l2: 8.67039\n",
      "[5]\tvalid_0's l2: 7.91521\n",
      "[6]\tvalid_0's l2: 7.27985\n",
      "[7]\tvalid_0's l2: 6.74831\n",
      "[8]\tvalid_0's l2: 6.33273\n",
      "[9]\tvalid_0's l2: 5.99207\n",
      "[10]\tvalid_0's l2: 5.70327\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.70327\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 11.9585\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.5497\n",
      "[3]\tvalid_0's l2: 9.38281\n",
      "[4]\tvalid_0's l2: 8.44953\n",
      "[5]\tvalid_0's l2: 7.68942\n",
      "[6]\tvalid_0's l2: 7.06509\n",
      "[7]\tvalid_0's l2: 6.53793\n",
      "[8]\tvalid_0's l2: 6.12405\n",
      "[9]\tvalid_0's l2: 5.78541\n",
      "[10]\tvalid_0's l2: 5.49792\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.49792\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 11.6331\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.2662\n",
      "[3]\tvalid_0's l2: 9.12576\n",
      "[4]\tvalid_0's l2: 8.22629\n",
      "[5]\tvalid_0's l2: 7.48861\n",
      "[6]\tvalid_0's l2: 6.87078\n",
      "[7]\tvalid_0's l2: 6.36216\n",
      "[8]\tvalid_0's l2: 5.96118\n",
      "[9]\tvalid_0's l2: 5.63438\n",
      "[10]\tvalid_0's l2: 5.35586\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.35586\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 11.8203\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.418\n",
      "[3]\tvalid_0's l2: 9.24172\n",
      "[4]\tvalid_0's l2: 8.31431\n",
      "[5]\tvalid_0's l2: 7.55442\n",
      "[6]\tvalid_0's l2: 6.92646\n",
      "[7]\tvalid_0's l2: 6.39927\n",
      "[8]\tvalid_0's l2: 5.98701\n",
      "[9]\tvalid_0's l2: 5.6494\n",
      "[10]\tvalid_0's l2: 5.35574\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.35574\n",
      "mean rmse score over folds is nan\n",
      "4\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t4', 'lag_t5', 'lag_t6', 'lag_t7'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 11.8589\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4527\n",
      "[3]\tvalid_0's l2: 9.29364\n",
      "[4]\tvalid_0's l2: 8.36894\n",
      "[5]\tvalid_0's l2: 7.61152\n",
      "[6]\tvalid_0's l2: 6.98921\n",
      "[7]\tvalid_0's l2: 6.47198\n",
      "[8]\tvalid_0's l2: 6.04948\n",
      "[9]\tvalid_0's l2: 5.70862\n",
      "[10]\tvalid_0's l2: 5.42279\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.42279\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 11.6798\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.3012\n",
      "[3]\tvalid_0's l2: 9.15572\n",
      "[4]\tvalid_0's l2: 8.24548\n",
      "[5]\tvalid_0's l2: 7.50413\n",
      "[6]\tvalid_0's l2: 6.88354\n",
      "[7]\tvalid_0's l2: 6.37357\n",
      "[8]\tvalid_0's l2: 5.96279\n",
      "[9]\tvalid_0's l2: 5.62963\n",
      "[10]\tvalid_0's l2: 5.35201\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.35201\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 11.8911\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4961\n",
      "[3]\tvalid_0's l2: 9.35014\n",
      "[4]\tvalid_0's l2: 8.43258\n",
      "[5]\tvalid_0's l2: 7.68009\n",
      "[6]\tvalid_0's l2: 7.06525\n",
      "[7]\tvalid_0's l2: 6.54947\n",
      "[8]\tvalid_0's l2: 6.13562\n",
      "[9]\tvalid_0's l2: 5.79877\n",
      "[10]\tvalid_0's l2: 5.51781\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.51781\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 11.6596\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.2744\n",
      "[3]\tvalid_0's l2: 9.13207\n",
      "[4]\tvalid_0's l2: 8.22475\n",
      "[5]\tvalid_0's l2: 7.48289\n",
      "[6]\tvalid_0's l2: 6.86595\n",
      "[7]\tvalid_0's l2: 6.35001\n",
      "[8]\tvalid_0's l2: 5.93743\n",
      "[9]\tvalid_0's l2: 5.60285\n",
      "[10]\tvalid_0's l2: 5.32436\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.32436\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 12.0346\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.645\n",
      "[3]\tvalid_0's l2: 9.5014\n",
      "[4]\tvalid_0's l2: 8.58475\n",
      "[5]\tvalid_0's l2: 7.83308\n",
      "[6]\tvalid_0's l2: 7.21624\n",
      "[7]\tvalid_0's l2: 6.70249\n",
      "[8]\tvalid_0's l2: 6.2926\n",
      "[9]\tvalid_0's l2: 5.95568\n",
      "[10]\tvalid_0's l2: 5.67922\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.67922\n",
      "mean rmse score over folds is nan\n",
      "5\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t5', 'lag_t6', 'lag_t7', 'lag_t8'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 11.59\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.2277\n",
      "[3]\tvalid_0's l2: 9.11011\n",
      "[4]\tvalid_0's l2: 8.20463\n",
      "[5]\tvalid_0's l2: 7.47176\n",
      "[6]\tvalid_0's l2: 6.87563\n",
      "[7]\tvalid_0's l2: 6.38249\n",
      "[8]\tvalid_0's l2: 5.98618\n",
      "[9]\tvalid_0's l2: 5.66634\n",
      "[10]\tvalid_0's l2: 5.39858\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.39858\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 11.6008\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.2219\n",
      "[3]\tvalid_0's l2: 9.08754\n",
      "[4]\tvalid_0's l2: 8.1738\n",
      "[5]\tvalid_0's l2: 7.43079\n",
      "[6]\tvalid_0's l2: 6.82923\n",
      "[7]\tvalid_0's l2: 6.32693\n",
      "[8]\tvalid_0's l2: 5.92292\n",
      "[9]\tvalid_0's l2: 5.59432\n",
      "[10]\tvalid_0's l2: 5.32343\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.32343\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 11.6503\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.2757\n",
      "[3]\tvalid_0's l2: 9.13457\n",
      "[4]\tvalid_0's l2: 8.22265\n",
      "[5]\tvalid_0's l2: 7.47656\n",
      "[6]\tvalid_0's l2: 6.86065\n",
      "[7]\tvalid_0's l2: 6.3572\n",
      "[8]\tvalid_0's l2: 5.95078\n",
      "[9]\tvalid_0's l2: 5.6198\n",
      "[10]\tvalid_0's l2: 5.34481\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.34481\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 12.1199\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.7256\n",
      "[3]\tvalid_0's l2: 9.58403\n",
      "[4]\tvalid_0's l2: 8.65688\n",
      "[5]\tvalid_0's l2: 7.90302\n",
      "[6]\tvalid_0's l2: 7.28194\n",
      "[7]\tvalid_0's l2: 6.77477\n",
      "[8]\tvalid_0's l2: 6.36349\n",
      "[9]\tvalid_0's l2: 6.02552\n",
      "[10]\tvalid_0's l2: 5.74578\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.74578\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 12.1982\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.7769\n",
      "[3]\tvalid_0's l2: 9.60424\n",
      "[4]\tvalid_0's l2: 8.65779\n",
      "[5]\tvalid_0's l2: 7.88331\n",
      "[6]\tvalid_0's l2: 7.25605\n",
      "[7]\tvalid_0's l2: 6.73192\n",
      "[8]\tvalid_0's l2: 6.30947\n",
      "[9]\tvalid_0's l2: 5.96323\n",
      "[10]\tvalid_0's l2: 5.67189\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.67189\n",
      "mean rmse score over folds is nan\n",
      "6\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t6', 'lag_t7', 'lag_t8', 'lag_t9'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 11.8045\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4317\n",
      "[3]\tvalid_0's l2: 9.28612\n",
      "[4]\tvalid_0's l2: 8.36504\n",
      "[5]\tvalid_0's l2: 7.61176\n",
      "[6]\tvalid_0's l2: 7.00288\n",
      "[7]\tvalid_0's l2: 6.49243\n",
      "[8]\tvalid_0's l2: 6.0864\n",
      "[9]\tvalid_0's l2: 5.75444\n",
      "[10]\tvalid_0's l2: 5.47987\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.47987\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 11.985\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.6063\n",
      "[3]\tvalid_0's l2: 9.45945\n",
      "[4]\tvalid_0's l2: 8.53599\n",
      "[5]\tvalid_0's l2: 7.7736\n",
      "[6]\tvalid_0's l2: 7.1544\n",
      "[7]\tvalid_0's l2: 6.63692\n",
      "[8]\tvalid_0's l2: 6.22137\n",
      "[9]\tvalid_0's l2: 5.88071\n",
      "[10]\tvalid_0's l2: 5.60235\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.60235\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 11.4279\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.0853\n",
      "[3]\tvalid_0's l2: 8.96733\n",
      "[4]\tvalid_0's l2: 8.07724\n",
      "[5]\tvalid_0's l2: 7.34514\n",
      "[6]\tvalid_0's l2: 6.74821\n",
      "[7]\tvalid_0's l2: 6.25451\n",
      "[8]\tvalid_0's l2: 5.8578\n",
      "[9]\tvalid_0's l2: 5.52984\n",
      "[10]\tvalid_0's l2: 5.26208\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.26208\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 11.8257\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4462\n",
      "[3]\tvalid_0's l2: 9.30105\n",
      "[4]\tvalid_0's l2: 8.3862\n",
      "[5]\tvalid_0's l2: 7.62997\n",
      "[6]\tvalid_0's l2: 7.02317\n",
      "[7]\tvalid_0's l2: 6.51178\n",
      "[8]\tvalid_0's l2: 6.10033\n",
      "[9]\tvalid_0's l2: 5.76584\n",
      "[10]\tvalid_0's l2: 5.48967\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.48967\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 12.157\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.7721\n",
      "[3]\tvalid_0's l2: 9.61819\n",
      "[4]\tvalid_0's l2: 8.68876\n",
      "[5]\tvalid_0's l2: 7.92323\n",
      "[6]\tvalid_0's l2: 7.3062\n",
      "[7]\tvalid_0's l2: 6.79597\n",
      "[8]\tvalid_0's l2: 6.38476\n",
      "[9]\tvalid_0's l2: 6.04968\n",
      "[10]\tvalid_0's l2: 5.77382\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.77382\n",
      "mean rmse score over folds is nan\n",
      "7\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t7', 'lag_t8', 'lag_t9', 'lag_t10'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 11.8092\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.448\n",
      "[3]\tvalid_0's l2: 9.31941\n",
      "[4]\tvalid_0's l2: 8.40365\n",
      "[5]\tvalid_0's l2: 7.65535\n",
      "[6]\tvalid_0's l2: 7.05082\n",
      "[7]\tvalid_0's l2: 6.54987\n",
      "[8]\tvalid_0's l2: 6.14384\n",
      "[9]\tvalid_0's l2: 5.81372\n",
      "[10]\tvalid_0's l2: 5.53699\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.53699\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 11.7779\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4247\n",
      "[3]\tvalid_0's l2: 9.30328\n",
      "[4]\tvalid_0's l2: 8.38877\n",
      "[5]\tvalid_0's l2: 7.64839\n",
      "[6]\tvalid_0's l2: 7.04687\n",
      "[7]\tvalid_0's l2: 6.55188\n",
      "[8]\tvalid_0's l2: 6.14664\n",
      "[9]\tvalid_0's l2: 5.81666\n",
      "[10]\tvalid_0's l2: 5.54637\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.54637\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 12.0605\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.7049\n",
      "[3]\tvalid_0's l2: 9.57118\n",
      "[4]\tvalid_0's l2: 8.6456\n",
      "[5]\tvalid_0's l2: 7.89522\n",
      "[6]\tvalid_0's l2: 7.28366\n",
      "[7]\tvalid_0's l2: 6.77904\n",
      "[8]\tvalid_0's l2: 6.37691\n",
      "[9]\tvalid_0's l2: 6.04742\n",
      "[10]\tvalid_0's l2: 5.77376\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.77376\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 11.7683\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4053\n",
      "[3]\tvalid_0's l2: 9.27352\n",
      "[4]\tvalid_0's l2: 8.35938\n",
      "[5]\tvalid_0's l2: 7.60942\n",
      "[6]\tvalid_0's l2: 7.00273\n",
      "[7]\tvalid_0's l2: 6.5055\n",
      "[8]\tvalid_0's l2: 6.10235\n",
      "[9]\tvalid_0's l2: 5.77126\n",
      "[10]\tvalid_0's l2: 5.49813\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.49813\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 11.8447\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4759\n",
      "[3]\tvalid_0's l2: 9.3302\n",
      "[4]\tvalid_0's l2: 8.39773\n",
      "[5]\tvalid_0's l2: 7.63107\n",
      "[6]\tvalid_0's l2: 7.01542\n",
      "[7]\tvalid_0's l2: 6.50769\n",
      "[8]\tvalid_0's l2: 6.09393\n",
      "[9]\tvalid_0's l2: 5.75585\n",
      "[10]\tvalid_0's l2: 5.47791\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.47791\n",
      "mean rmse score over folds is nan\n",
      "8\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t8', 'lag_t9', 'lag_t10', 'lag_t11'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 11.6388\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\tvalid_0's l2: 10.2936\n",
      "[3]\tvalid_0's l2: 9.18303\n",
      "[4]\tvalid_0's l2: 8.2833\n",
      "[5]\tvalid_0's l2: 7.55079\n",
      "[6]\tvalid_0's l2: 6.95107\n",
      "[7]\tvalid_0's l2: 6.458\n",
      "[8]\tvalid_0's l2: 6.06403\n",
      "[9]\tvalid_0's l2: 5.73694\n",
      "[10]\tvalid_0's l2: 5.46303\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.46303\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 11.8799\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.5274\n",
      "[3]\tvalid_0's l2: 9.41223\n",
      "[4]\tvalid_0's l2: 8.50618\n",
      "[5]\tvalid_0's l2: 7.76925\n",
      "[6]\tvalid_0's l2: 7.16351\n",
      "[7]\tvalid_0's l2: 6.65857\n",
      "[8]\tvalid_0's l2: 6.25814\n",
      "[9]\tvalid_0's l2: 5.93246\n",
      "[10]\tvalid_0's l2: 5.6575\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.6575\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 11.8454\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4973\n",
      "[3]\tvalid_0's l2: 9.37257\n",
      "[4]\tvalid_0's l2: 8.46647\n",
      "[5]\tvalid_0's l2: 7.72367\n",
      "[6]\tvalid_0's l2: 7.11845\n",
      "[7]\tvalid_0's l2: 6.61399\n",
      "[8]\tvalid_0's l2: 6.21294\n",
      "[9]\tvalid_0's l2: 5.88612\n",
      "[10]\tvalid_0's l2: 5.61212\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.61212\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 11.9495\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.6176\n",
      "[3]\tvalid_0's l2: 9.51436\n",
      "[4]\tvalid_0's l2: 8.62212\n",
      "[5]\tvalid_0's l2: 7.90078\n",
      "[6]\tvalid_0's l2: 7.2988\n",
      "[7]\tvalid_0's l2: 6.80623\n",
      "[8]\tvalid_0's l2: 6.40966\n",
      "[9]\tvalid_0's l2: 6.08335\n",
      "[10]\tvalid_0's l2: 5.81094\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.81094\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 12.014\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.6204\n",
      "[3]\tvalid_0's l2: 9.46269\n",
      "[4]\tvalid_0's l2: 8.52877\n",
      "[5]\tvalid_0's l2: 7.76853\n",
      "[6]\tvalid_0's l2: 7.1454\n",
      "[7]\tvalid_0's l2: 6.62418\n",
      "[8]\tvalid_0's l2: 6.21301\n",
      "[9]\tvalid_0's l2: 5.87608\n",
      "[10]\tvalid_0's l2: 5.58579\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.58579\n",
      "mean rmse score over folds is nan\n",
      "9\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t9', 'lag_t10', 'lag_t11', 'lag_t12'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 11.8507\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4914\n",
      "[3]\tvalid_0's l2: 9.36899\n",
      "[4]\tvalid_0's l2: 8.46397\n",
      "[5]\tvalid_0's l2: 7.72255\n",
      "[6]\tvalid_0's l2: 7.11465\n",
      "[7]\tvalid_0's l2: 6.60752\n",
      "[8]\tvalid_0's l2: 6.19651\n",
      "[9]\tvalid_0's l2: 5.86178\n",
      "[10]\tvalid_0's l2: 5.58376\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.58376\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 12.0144\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.6459\n",
      "[3]\tvalid_0's l2: 9.52164\n",
      "[4]\tvalid_0's l2: 8.60615\n",
      "[5]\tvalid_0's l2: 7.85995\n",
      "[6]\tvalid_0's l2: 7.2485\n",
      "[7]\tvalid_0's l2: 6.73427\n",
      "[8]\tvalid_0's l2: 6.3189\n",
      "[9]\tvalid_0's l2: 5.98132\n",
      "[10]\tvalid_0's l2: 5.70375\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.70375\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 12.0227\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.6915\n",
      "[3]\tvalid_0's l2: 9.59466\n",
      "[4]\tvalid_0's l2: 8.70224\n",
      "[5]\tvalid_0's l2: 7.97953\n",
      "[6]\tvalid_0's l2: 7.38315\n",
      "[7]\tvalid_0's l2: 6.89113\n",
      "[8]\tvalid_0's l2: 6.4917\n",
      "[9]\tvalid_0's l2: 6.16684\n",
      "[10]\tvalid_0's l2: 5.89204\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.89204\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 11.7245\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.3624\n",
      "[3]\tvalid_0's l2: 9.24631\n",
      "[4]\tvalid_0's l2: 8.34538\n",
      "[5]\tvalid_0's l2: 7.61508\n",
      "[6]\tvalid_0's l2: 7.00853\n",
      "[7]\tvalid_0's l2: 6.50894\n",
      "[8]\tvalid_0's l2: 6.10667\n",
      "[9]\tvalid_0's l2: 5.77187\n",
      "[10]\tvalid_0's l2: 5.49252\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.49252\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 11.7763\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4187\n",
      "[3]\tvalid_0's l2: 9.29918\n",
      "[4]\tvalid_0's l2: 8.40112\n",
      "[5]\tvalid_0's l2: 7.6702\n",
      "[6]\tvalid_0's l2: 7.06694\n",
      "[7]\tvalid_0's l2: 6.56609\n",
      "[8]\tvalid_0's l2: 6.165\n",
      "[9]\tvalid_0's l2: 5.8353\n",
      "[10]\tvalid_0's l2: 5.56316\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.56316\n",
      "mean rmse score over folds is nan\n",
      "10\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t10', 'lag_t11', 'lag_t12', 'lag_t13'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 12.1944\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.8147\n",
      "[3]\tvalid_0's l2: 9.67171\n",
      "[4]\tvalid_0's l2: 8.74997\n",
      "[5]\tvalid_0's l2: 7.9895\n",
      "[6]\tvalid_0's l2: 7.36442\n",
      "[7]\tvalid_0's l2: 6.84826\n",
      "[8]\tvalid_0's l2: 6.43491\n",
      "[9]\tvalid_0's l2: 6.09423\n",
      "[10]\tvalid_0's l2: 5.81004\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.81004\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 11.5961\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.271\n",
      "[3]\tvalid_0's l2: 9.18796\n",
      "[4]\tvalid_0's l2: 8.29849\n",
      "[5]\tvalid_0's l2: 7.57965\n",
      "[6]\tvalid_0's l2: 6.99499\n",
      "[7]\tvalid_0's l2: 6.50668\n",
      "[8]\tvalid_0's l2: 6.11215\n",
      "[9]\tvalid_0's l2: 5.78716\n",
      "[10]\tvalid_0's l2: 5.5205\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.5205\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 12.1124\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.7357\n",
      "[3]\tvalid_0's l2: 9.60409\n",
      "[4]\tvalid_0's l2: 8.69535\n",
      "[5]\tvalid_0's l2: 7.9472\n",
      "[6]\tvalid_0's l2: 7.3357\n",
      "[7]\tvalid_0's l2: 6.82799\n",
      "[8]\tvalid_0's l2: 6.42023\n",
      "[9]\tvalid_0's l2: 6.08234\n",
      "[10]\tvalid_0's l2: 5.80537\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.80537\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 11.643\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.3035\n",
      "[3]\tvalid_0's l2: 9.20188\n",
      "[4]\tvalid_0's l2: 8.31697\n",
      "[5]\tvalid_0's l2: 7.59079\n",
      "[6]\tvalid_0's l2: 6.99013\n",
      "[7]\tvalid_0's l2: 6.50144\n",
      "[8]\tvalid_0's l2: 6.10624\n",
      "[9]\tvalid_0's l2: 5.78256\n",
      "[10]\tvalid_0's l2: 5.51595\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.51595\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 11.8692\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.527\n",
      "[3]\tvalid_0's l2: 9.42802\n",
      "[4]\tvalid_0's l2: 8.53896\n",
      "[5]\tvalid_0's l2: 7.8112\n",
      "[6]\tvalid_0's l2: 7.21408\n",
      "[7]\tvalid_0's l2: 6.71991\n",
      "[8]\tvalid_0's l2: 6.32277\n",
      "[9]\tvalid_0's l2: 5.9956\n",
      "[10]\tvalid_0's l2: 5.72671\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.72671\n",
      "mean rmse score over folds is nan\n",
      "11\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t11', 'lag_t12', 'lag_t13', 'lag_t14'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 12.0061\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.6634\n",
      "[3]\tvalid_0's l2: 9.56988\n",
      "[4]\tvalid_0's l2: 8.67947\n",
      "[5]\tvalid_0's l2: 7.95801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\tvalid_0's l2: 7.36424\n",
      "[7]\tvalid_0's l2: 6.87374\n",
      "[8]\tvalid_0's l2: 6.46933\n",
      "[9]\tvalid_0's l2: 6.14298\n",
      "[10]\tvalid_0's l2: 5.87614\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.87614\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 11.7925\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4372\n",
      "[3]\tvalid_0's l2: 9.33307\n",
      "[4]\tvalid_0's l2: 8.43804\n",
      "[5]\tvalid_0's l2: 7.70767\n",
      "[6]\tvalid_0's l2: 7.10726\n",
      "[7]\tvalid_0's l2: 6.60798\n",
      "[8]\tvalid_0's l2: 6.20429\n",
      "[9]\tvalid_0's l2: 5.87469\n",
      "[10]\tvalid_0's l2: 5.60215\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.60215\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 11.762\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.3767\n",
      "[3]\tvalid_0's l2: 9.25446\n",
      "[4]\tvalid_0's l2: 8.34635\n",
      "[5]\tvalid_0's l2: 7.60519\n",
      "[6]\tvalid_0's l2: 6.99659\n",
      "[7]\tvalid_0's l2: 6.4881\n",
      "[8]\tvalid_0's l2: 6.07978\n",
      "[9]\tvalid_0's l2: 5.73943\n",
      "[10]\tvalid_0's l2: 5.46546\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.46546\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 11.7933\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4427\n",
      "[3]\tvalid_0's l2: 9.33395\n",
      "[4]\tvalid_0's l2: 8.43666\n",
      "[5]\tvalid_0's l2: 7.7118\n",
      "[6]\tvalid_0's l2: 7.11209\n",
      "[7]\tvalid_0's l2: 6.62449\n",
      "[8]\tvalid_0's l2: 6.22702\n",
      "[9]\tvalid_0's l2: 5.89354\n",
      "[10]\tvalid_0's l2: 5.62312\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.62312\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 12.0415\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.6676\n",
      "[3]\tvalid_0's l2: 9.54258\n",
      "[4]\tvalid_0's l2: 8.62799\n",
      "[5]\tvalid_0's l2: 7.87624\n",
      "[6]\tvalid_0's l2: 7.26307\n",
      "[7]\tvalid_0's l2: 6.75375\n",
      "[8]\tvalid_0's l2: 6.33804\n",
      "[9]\tvalid_0's l2: 5.99635\n",
      "[10]\tvalid_0's l2: 5.72021\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.72021\n",
      "mean rmse score over folds is nan\n",
      "12\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t12', 'lag_t13', 'lag_t14', 'lag_t15'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 12.2149\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.8513\n",
      "[3]\tvalid_0's l2: 9.73344\n",
      "[4]\tvalid_0's l2: 8.81788\n",
      "[5]\tvalid_0's l2: 8.07193\n",
      "[6]\tvalid_0's l2: 7.46956\n",
      "[7]\tvalid_0's l2: 6.96559\n",
      "[8]\tvalid_0's l2: 6.55982\n",
      "[9]\tvalid_0's l2: 6.22602\n",
      "[10]\tvalid_0's l2: 5.95009\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.95009\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 11.8297\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4737\n",
      "[3]\tvalid_0's l2: 9.36075\n",
      "[4]\tvalid_0's l2: 8.45263\n",
      "[5]\tvalid_0's l2: 7.70989\n",
      "[6]\tvalid_0's l2: 7.10893\n",
      "[7]\tvalid_0's l2: 6.61097\n",
      "[8]\tvalid_0's l2: 6.20437\n",
      "[9]\tvalid_0's l2: 5.8709\n",
      "[10]\tvalid_0's l2: 5.59719\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.59719\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 11.9175\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.5425\n",
      "[3]\tvalid_0's l2: 9.41611\n",
      "[4]\tvalid_0's l2: 8.50252\n",
      "[5]\tvalid_0's l2: 7.75441\n",
      "[6]\tvalid_0's l2: 7.14416\n",
      "[7]\tvalid_0's l2: 6.63862\n",
      "[8]\tvalid_0's l2: 6.22894\n",
      "[9]\tvalid_0's l2: 5.89222\n",
      "[10]\tvalid_0's l2: 5.61127\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.61127\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 11.5265\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.2059\n",
      "[3]\tvalid_0's l2: 9.11928\n",
      "[4]\tvalid_0's l2: 8.23238\n",
      "[5]\tvalid_0's l2: 7.50776\n",
      "[6]\tvalid_0's l2: 6.92488\n",
      "[7]\tvalid_0's l2: 6.43778\n",
      "[8]\tvalid_0's l2: 6.04431\n",
      "[9]\tvalid_0's l2: 5.7237\n",
      "[10]\tvalid_0's l2: 5.45952\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.45952\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 11.8985\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.5455\n",
      "[3]\tvalid_0's l2: 9.43768\n",
      "[4]\tvalid_0's l2: 8.53584\n",
      "[5]\tvalid_0's l2: 7.79776\n",
      "[6]\tvalid_0's l2: 7.19275\n",
      "[7]\tvalid_0's l2: 6.69601\n",
      "[8]\tvalid_0's l2: 6.29303\n",
      "[9]\tvalid_0's l2: 5.9646\n",
      "[10]\tvalid_0's l2: 5.6924\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.6924\n",
      "mean rmse score over folds is nan\n",
      "13\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t13', 'lag_t14', 'lag_t15', 'lag_t16'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 11.6761\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.3471\n",
      "[3]\tvalid_0's l2: 9.26328\n",
      "[4]\tvalid_0's l2: 8.38242\n",
      "[5]\tvalid_0's l2: 7.66358\n",
      "[6]\tvalid_0's l2: 7.07703\n",
      "[7]\tvalid_0's l2: 6.59217\n",
      "[8]\tvalid_0's l2: 6.19987\n",
      "[9]\tvalid_0's l2: 5.8765\n",
      "[10]\tvalid_0's l2: 5.61284\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.61284\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 11.8327\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4836\n",
      "[3]\tvalid_0's l2: 9.37241\n",
      "[4]\tvalid_0's l2: 8.48106\n",
      "[5]\tvalid_0's l2: 7.74477\n",
      "[6]\tvalid_0's l2: 7.15127\n",
      "[7]\tvalid_0's l2: 6.6585\n",
      "[8]\tvalid_0's l2: 6.2608\n",
      "[9]\tvalid_0's l2: 5.93992\n",
      "[10]\tvalid_0's l2: 5.67312\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.67312\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 12.2106\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.8315\n",
      "[3]\tvalid_0's l2: 9.68879\n",
      "[4]\tvalid_0's l2: 8.77313\n",
      "[5]\tvalid_0's l2: 8.00981\n",
      "[6]\tvalid_0's l2: 7.39781\n",
      "[7]\tvalid_0's l2: 6.88291\n",
      "[8]\tvalid_0's l2: 6.46633\n",
      "[9]\tvalid_0's l2: 6.12587\n",
      "[10]\tvalid_0's l2: 5.84279\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.84279\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 11.713\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.3683\n",
      "[3]\tvalid_0's l2: 9.26183\n",
      "[4]\tvalid_0's l2: 8.37559\n",
      "[5]\tvalid_0's l2: 7.64311\n",
      "[6]\tvalid_0's l2: 7.05178\n",
      "[7]\tvalid_0's l2: 6.55701\n",
      "[8]\tvalid_0's l2: 6.15852\n",
      "[9]\tvalid_0's l2: 5.83461\n",
      "[10]\tvalid_0's l2: 5.56873\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.56873\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 12.0185\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.651\n",
      "[3]\tvalid_0's l2: 9.52042\n",
      "[4]\tvalid_0's l2: 8.61274\n",
      "[5]\tvalid_0's l2: 7.85984\n",
      "[6]\tvalid_0's l2: 7.24951\n",
      "[7]\tvalid_0's l2: 6.74186\n",
      "[8]\tvalid_0's l2: 6.33235\n",
      "[9]\tvalid_0's l2: 5.99707\n",
      "[10]\tvalid_0's l2: 5.72096\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.72096\n",
      "mean rmse score over folds is nan\n",
      "14\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t14', 'lag_t15', 'lag_t16', 'lag_t17'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 11.8675\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.5177\n",
      "[3]\tvalid_0's l2: 9.39993\n",
      "[4]\tvalid_0's l2: 8.48531\n",
      "[5]\tvalid_0's l2: 7.74392\n",
      "[6]\tvalid_0's l2: 7.13978\n",
      "[7]\tvalid_0's l2: 6.64055\n",
      "[8]\tvalid_0's l2: 6.23743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\tvalid_0's l2: 5.90899\n",
      "[10]\tvalid_0's l2: 5.6365\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.6365\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 11.7169\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.3815\n",
      "[3]\tvalid_0's l2: 9.27446\n",
      "[4]\tvalid_0's l2: 8.37787\n",
      "[5]\tvalid_0's l2: 7.63871\n",
      "[6]\tvalid_0's l2: 7.04735\n",
      "[7]\tvalid_0's l2: 6.55591\n",
      "[8]\tvalid_0's l2: 6.1597\n",
      "[9]\tvalid_0's l2: 5.83272\n",
      "[10]\tvalid_0's l2: 5.56634\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.56634\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 12.3198\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.9568\n",
      "[3]\tvalid_0's l2: 9.82266\n",
      "[4]\tvalid_0's l2: 8.90058\n",
      "[5]\tvalid_0's l2: 8.15027\n",
      "[6]\tvalid_0's l2: 7.54088\n",
      "[7]\tvalid_0's l2: 7.03707\n",
      "[8]\tvalid_0's l2: 6.62651\n",
      "[9]\tvalid_0's l2: 6.29317\n",
      "[10]\tvalid_0's l2: 6.01523\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 6.01523\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 11.6653\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.3372\n",
      "[3]\tvalid_0's l2: 9.24509\n",
      "[4]\tvalid_0's l2: 8.35288\n",
      "[5]\tvalid_0's l2: 7.62654\n",
      "[6]\tvalid_0's l2: 7.03409\n",
      "[7]\tvalid_0's l2: 6.54189\n",
      "[8]\tvalid_0's l2: 6.14525\n",
      "[9]\tvalid_0's l2: 5.81343\n",
      "[10]\tvalid_0's l2: 5.54493\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.54493\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 11.8817\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.5487\n",
      "[3]\tvalid_0's l2: 9.43931\n",
      "[4]\tvalid_0's l2: 8.53775\n",
      "[5]\tvalid_0's l2: 7.79802\n",
      "[6]\tvalid_0's l2: 7.20554\n",
      "[7]\tvalid_0's l2: 6.71123\n",
      "[8]\tvalid_0's l2: 6.31028\n",
      "[9]\tvalid_0's l2: 5.97922\n",
      "[10]\tvalid_0's l2: 5.71215\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.71215\n",
      "mean rmse score over folds is nan\n",
      "15\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t15', 'lag_t16', 'lag_t17', 'lag_t18'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 11.6922\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.357\n",
      "[3]\tvalid_0's l2: 9.25774\n",
      "[4]\tvalid_0's l2: 8.36507\n",
      "[5]\tvalid_0's l2: 7.63922\n",
      "[6]\tvalid_0's l2: 7.04522\n",
      "[7]\tvalid_0's l2: 6.55597\n",
      "[8]\tvalid_0's l2: 6.16061\n",
      "[9]\tvalid_0's l2: 5.83627\n",
      "[10]\tvalid_0's l2: 5.57034\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.57034\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 11.8664\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.5734\n",
      "[3]\tvalid_0's l2: 9.50194\n",
      "[4]\tvalid_0's l2: 8.63171\n",
      "[5]\tvalid_0's l2: 7.92245\n",
      "[6]\tvalid_0's l2: 7.34869\n",
      "[7]\tvalid_0's l2: 6.87256\n",
      "[8]\tvalid_0's l2: 6.48285\n",
      "[9]\tvalid_0's l2: 6.16068\n",
      "[10]\tvalid_0's l2: 5.90035\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.90035\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 11.9301\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.5748\n",
      "[3]\tvalid_0's l2: 9.46017\n",
      "[4]\tvalid_0's l2: 8.54846\n",
      "[5]\tvalid_0's l2: 7.81191\n",
      "[6]\tvalid_0's l2: 7.20726\n",
      "[7]\tvalid_0's l2: 6.7023\n",
      "[8]\tvalid_0's l2: 6.29113\n",
      "[9]\tvalid_0's l2: 5.94901\n",
      "[10]\tvalid_0's l2: 5.67353\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.67353\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 12.1028\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.7402\n",
      "[3]\tvalid_0's l2: 9.59773\n",
      "[4]\tvalid_0's l2: 8.6713\n",
      "[5]\tvalid_0's l2: 7.91687\n",
      "[6]\tvalid_0's l2: 7.30862\n",
      "[7]\tvalid_0's l2: 6.80194\n",
      "[8]\tvalid_0's l2: 6.38941\n",
      "[9]\tvalid_0's l2: 6.05315\n",
      "[10]\tvalid_0's l2: 5.77928\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.77928\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 11.9207\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.5807\n",
      "[3]\tvalid_0's l2: 9.48578\n",
      "[4]\tvalid_0's l2: 8.59343\n",
      "[5]\tvalid_0's l2: 7.86477\n",
      "[6]\tvalid_0's l2: 7.26465\n",
      "[7]\tvalid_0's l2: 6.76819\n",
      "[8]\tvalid_0's l2: 6.36818\n",
      "[9]\tvalid_0's l2: 6.03591\n",
      "[10]\tvalid_0's l2: 5.76569\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.76569\n",
      "mean rmse score over folds is nan\n",
      "16\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t16', 'lag_t17', 'lag_t18', 'lag_t19'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 11.9003\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.5625\n",
      "[3]\tvalid_0's l2: 9.45352\n",
      "[4]\tvalid_0's l2: 8.54417\n",
      "[5]\tvalid_0's l2: 7.80552\n",
      "[6]\tvalid_0's l2: 7.21106\n",
      "[7]\tvalid_0's l2: 6.71752\n",
      "[8]\tvalid_0's l2: 6.31162\n",
      "[9]\tvalid_0's l2: 5.97265\n",
      "[10]\tvalid_0's l2: 5.70347\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.70347\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 11.9177\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.5613\n",
      "[3]\tvalid_0's l2: 9.44095\n",
      "[4]\tvalid_0's l2: 8.52905\n",
      "[5]\tvalid_0's l2: 7.78824\n",
      "[6]\tvalid_0's l2: 7.18886\n",
      "[7]\tvalid_0's l2: 6.68899\n",
      "[8]\tvalid_0's l2: 6.27864\n",
      "[9]\tvalid_0's l2: 5.94051\n",
      "[10]\tvalid_0's l2: 5.67037\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.67037\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 11.687\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.3815\n",
      "[3]\tvalid_0's l2: 9.30584\n",
      "[4]\tvalid_0's l2: 8.42894\n",
      "[5]\tvalid_0's l2: 7.71113\n",
      "[6]\tvalid_0's l2: 7.13144\n",
      "[7]\tvalid_0's l2: 6.64915\n",
      "[8]\tvalid_0's l2: 6.25367\n",
      "[9]\tvalid_0's l2: 5.92391\n",
      "[10]\tvalid_0's l2: 5.66216\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.66216\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 12.0396\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.689\n",
      "[3]\tvalid_0's l2: 9.56528\n",
      "[4]\tvalid_0's l2: 8.65138\n",
      "[5]\tvalid_0's l2: 7.90352\n",
      "[6]\tvalid_0's l2: 7.30569\n",
      "[7]\tvalid_0's l2: 6.79858\n",
      "[8]\tvalid_0's l2: 6.38968\n",
      "[9]\tvalid_0's l2: 6.04626\n",
      "[10]\tvalid_0's l2: 5.76966\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.76966\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 12.0004\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.6799\n",
      "[3]\tvalid_0's l2: 9.59576\n",
      "[4]\tvalid_0's l2: 8.69888\n",
      "[5]\tvalid_0's l2: 7.97364\n",
      "[6]\tvalid_0's l2: 7.38581\n",
      "[7]\tvalid_0's l2: 6.89354\n",
      "[8]\tvalid_0's l2: 6.49313\n",
      "[9]\tvalid_0's l2: 6.16054\n",
      "[10]\tvalid_0's l2: 5.89606\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.89606\n",
      "mean rmse score over folds is nan\n",
      "17\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t17', 'lag_t18', 'lag_t19', 'lag_t20'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 11.8241\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4837\n",
      "[3]\tvalid_0's l2: 9.37929\n",
      "[4]\tvalid_0's l2: 8.46707\n",
      "[5]\tvalid_0's l2: 7.72692\n",
      "[6]\tvalid_0's l2: 7.13512\n",
      "[7]\tvalid_0's l2: 6.63733\n",
      "[8]\tvalid_0's l2: 6.23079\n",
      "[9]\tvalid_0's l2: 5.89753\n",
      "[10]\tvalid_0's l2: 5.63095\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.63095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 11.9881\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.6292\n",
      "[3]\tvalid_0's l2: 9.51831\n",
      "[4]\tvalid_0's l2: 8.60941\n",
      "[5]\tvalid_0's l2: 7.86066\n",
      "[6]\tvalid_0's l2: 7.25357\n",
      "[7]\tvalid_0's l2: 6.75278\n",
      "[8]\tvalid_0's l2: 6.35083\n",
      "[9]\tvalid_0's l2: 6.01035\n",
      "[10]\tvalid_0's l2: 5.73876\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.73876\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 11.7004\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.3967\n",
      "[3]\tvalid_0's l2: 9.32538\n",
      "[4]\tvalid_0's l2: 8.45575\n",
      "[5]\tvalid_0's l2: 7.74527\n",
      "[6]\tvalid_0's l2: 7.17463\n",
      "[7]\tvalid_0's l2: 6.70069\n",
      "[8]\tvalid_0's l2: 6.31663\n",
      "[9]\tvalid_0's l2: 6.00112\n",
      "[10]\tvalid_0's l2: 5.74688\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.74688\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 12.2748\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.9177\n",
      "[3]\tvalid_0's l2: 9.79191\n",
      "[4]\tvalid_0's l2: 8.87309\n",
      "[5]\tvalid_0's l2: 8.11776\n",
      "[6]\tvalid_0's l2: 7.51187\n",
      "[7]\tvalid_0's l2: 7.0126\n",
      "[8]\tvalid_0's l2: 6.60184\n",
      "[9]\tvalid_0's l2: 6.26366\n",
      "[10]\tvalid_0's l2: 5.98381\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.98381\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 11.7755\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4619\n",
      "[3]\tvalid_0's l2: 9.38127\n",
      "[4]\tvalid_0's l2: 8.49137\n",
      "[5]\tvalid_0's l2: 7.7615\n",
      "[6]\tvalid_0's l2: 7.1712\n",
      "[7]\tvalid_0's l2: 6.6789\n",
      "[8]\tvalid_0's l2: 6.28106\n",
      "[9]\tvalid_0's l2: 5.94774\n",
      "[10]\tvalid_0's l2: 5.6777\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.6777\n",
      "mean rmse score over folds is nan\n",
      "18\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t18', 'lag_t19', 'lag_t20', 'lag_t21'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 11.7964\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4631\n",
      "[3]\tvalid_0's l2: 9.36806\n",
      "[4]\tvalid_0's l2: 8.47885\n",
      "[5]\tvalid_0's l2: 7.74983\n",
      "[6]\tvalid_0's l2: 7.16212\n",
      "[7]\tvalid_0's l2: 6.67662\n",
      "[8]\tvalid_0's l2: 6.27968\n",
      "[9]\tvalid_0's l2: 5.94959\n",
      "[10]\tvalid_0's l2: 5.68257\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.68257\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 11.7588\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4345\n",
      "[3]\tvalid_0's l2: 9.34599\n",
      "[4]\tvalid_0's l2: 8.45826\n",
      "[5]\tvalid_0's l2: 7.73522\n",
      "[6]\tvalid_0's l2: 7.14981\n",
      "[7]\tvalid_0's l2: 6.6587\n",
      "[8]\tvalid_0's l2: 6.2658\n",
      "[9]\tvalid_0's l2: 5.93695\n",
      "[10]\tvalid_0's l2: 5.6741\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.6741\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 11.8828\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.542\n",
      "[3]\tvalid_0's l2: 9.43528\n",
      "[4]\tvalid_0's l2: 8.54061\n",
      "[5]\tvalid_0's l2: 7.80729\n",
      "[6]\tvalid_0's l2: 7.21251\n",
      "[7]\tvalid_0's l2: 6.71256\n",
      "[8]\tvalid_0's l2: 6.30371\n",
      "[9]\tvalid_0's l2: 5.96746\n",
      "[10]\tvalid_0's l2: 5.69849\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.69849\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 11.8177\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4721\n",
      "[3]\tvalid_0's l2: 9.36999\n",
      "[4]\tvalid_0's l2: 8.47456\n",
      "[5]\tvalid_0's l2: 7.73537\n",
      "[6]\tvalid_0's l2: 7.13954\n",
      "[7]\tvalid_0's l2: 6.63805\n",
      "[8]\tvalid_0's l2: 6.23439\n",
      "[9]\tvalid_0's l2: 5.9027\n",
      "[10]\tvalid_0's l2: 5.63191\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.63191\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 12.2695\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.9021\n",
      "[3]\tvalid_0's l2: 9.78387\n",
      "[4]\tvalid_0's l2: 8.87308\n",
      "[5]\tvalid_0's l2: 8.12805\n",
      "[6]\tvalid_0's l2: 7.52689\n",
      "[7]\tvalid_0's l2: 7.02079\n",
      "[8]\tvalid_0's l2: 6.61353\n",
      "[9]\tvalid_0's l2: 6.27435\n",
      "[10]\tvalid_0's l2: 5.9983\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.9983\n",
      "mean rmse score over folds is nan\n",
      "19\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t19', 'lag_t20', 'lag_t21', 'lag_t22'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 11.6979\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.3724\n",
      "[3]\tvalid_0's l2: 9.28569\n",
      "[4]\tvalid_0's l2: 8.40094\n",
      "[5]\tvalid_0's l2: 7.67959\n",
      "[6]\tvalid_0's l2: 7.0959\n",
      "[7]\tvalid_0's l2: 6.61028\n",
      "[8]\tvalid_0's l2: 6.21317\n",
      "[9]\tvalid_0's l2: 5.88672\n",
      "[10]\tvalid_0's l2: 5.62315\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.62315\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 11.8673\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.5206\n",
      "[3]\tvalid_0's l2: 9.41719\n",
      "[4]\tvalid_0's l2: 8.51288\n",
      "[5]\tvalid_0's l2: 7.77748\n",
      "[6]\tvalid_0's l2: 7.18211\n",
      "[7]\tvalid_0's l2: 6.68766\n",
      "[8]\tvalid_0's l2: 6.28364\n",
      "[9]\tvalid_0's l2: 5.947\n",
      "[10]\tvalid_0's l2: 5.67619\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.67619\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 12.0669\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.736\n",
      "[3]\tvalid_0's l2: 9.6413\n",
      "[4]\tvalid_0's l2: 8.74071\n",
      "[5]\tvalid_0's l2: 8.0075\n",
      "[6]\tvalid_0's l2: 7.40983\n",
      "[7]\tvalid_0's l2: 6.9181\n",
      "[8]\tvalid_0's l2: 6.51702\n",
      "[9]\tvalid_0's l2: 6.18624\n",
      "[10]\tvalid_0's l2: 5.91564\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.91564\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 11.9693\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.6148\n",
      "[3]\tvalid_0's l2: 9.50577\n",
      "[4]\tvalid_0's l2: 8.6035\n",
      "[5]\tvalid_0's l2: 7.86979\n",
      "[6]\tvalid_0's l2: 7.27349\n",
      "[7]\tvalid_0's l2: 6.77687\n",
      "[8]\tvalid_0's l2: 6.37304\n",
      "[9]\tvalid_0's l2: 6.04148\n",
      "[10]\tvalid_0's l2: 5.77173\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.77173\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 11.9259\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.594\n",
      "[3]\tvalid_0's l2: 9.50199\n",
      "[4]\tvalid_0's l2: 8.60569\n",
      "[5]\tvalid_0's l2: 7.87343\n",
      "[6]\tvalid_0's l2: 7.2818\n",
      "[7]\tvalid_0's l2: 6.79293\n",
      "[8]\tvalid_0's l2: 6.39455\n",
      "[9]\tvalid_0's l2: 6.06069\n",
      "[10]\tvalid_0's l2: 5.7944\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.7944\n",
      "mean rmse score over folds is nan\n",
      "20\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t20', 'lag_t21', 'lag_t22', 'lag_t23'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 11.8511\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.5051\n",
      "[3]\tvalid_0's l2: 9.39193\n",
      "[4]\tvalid_0's l2: 8.49536\n",
      "[5]\tvalid_0's l2: 7.75771\n",
      "[6]\tvalid_0's l2: 7.15524\n",
      "[7]\tvalid_0's l2: 6.65807\n",
      "[8]\tvalid_0's l2: 6.25815\n",
      "[9]\tvalid_0's l2: 5.92555\n",
      "[10]\tvalid_0's l2: 5.6536\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.6536\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 11.9151\n",
      "Training until validation scores don't improve for 20 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\tvalid_0's l2: 10.6038\n",
      "[3]\tvalid_0's l2: 9.52058\n",
      "[4]\tvalid_0's l2: 8.64002\n",
      "[5]\tvalid_0's l2: 7.90827\n",
      "[6]\tvalid_0's l2: 7.32169\n",
      "[7]\tvalid_0's l2: 6.82859\n",
      "[8]\tvalid_0's l2: 6.42767\n",
      "[9]\tvalid_0's l2: 6.09137\n",
      "[10]\tvalid_0's l2: 5.81728\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.81728\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 11.6448\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.3335\n",
      "[3]\tvalid_0's l2: 9.24062\n",
      "[4]\tvalid_0's l2: 8.35952\n",
      "[5]\tvalid_0's l2: 7.62435\n",
      "[6]\tvalid_0's l2: 7.04141\n",
      "[7]\tvalid_0's l2: 6.55218\n",
      "[8]\tvalid_0's l2: 6.14992\n",
      "[9]\tvalid_0's l2: 5.8173\n",
      "[10]\tvalid_0's l2: 5.55037\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.55037\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 12.2155\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.8524\n",
      "[3]\tvalid_0's l2: 9.72212\n",
      "[4]\tvalid_0's l2: 8.80542\n",
      "[5]\tvalid_0's l2: 8.04946\n",
      "[6]\tvalid_0's l2: 7.44955\n",
      "[7]\tvalid_0's l2: 6.93958\n",
      "[8]\tvalid_0's l2: 6.52419\n",
      "[9]\tvalid_0's l2: 6.18132\n",
      "[10]\tvalid_0's l2: 5.91032\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.91032\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 11.9434\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.633\n",
      "[3]\tvalid_0's l2: 9.54319\n",
      "[4]\tvalid_0's l2: 8.66767\n",
      "[5]\tvalid_0's l2: 7.94504\n",
      "[6]\tvalid_0's l2: 7.35923\n",
      "[7]\tvalid_0's l2: 6.86342\n",
      "[8]\tvalid_0's l2: 6.46723\n",
      "[9]\tvalid_0's l2: 6.13749\n",
      "[10]\tvalid_0's l2: 5.87813\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.87813\n",
      "mean rmse score over folds is nan\n",
      "21\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t21', 'lag_t22', 'lag_t23', 'lag_t24'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 12.1178\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.7665\n",
      "[3]\tvalid_0's l2: 9.64755\n",
      "[4]\tvalid_0's l2: 8.73425\n",
      "[5]\tvalid_0's l2: 7.99162\n",
      "[6]\tvalid_0's l2: 7.39163\n",
      "[7]\tvalid_0's l2: 6.88995\n",
      "[8]\tvalid_0's l2: 6.48405\n",
      "[9]\tvalid_0's l2: 6.14758\n",
      "[10]\tvalid_0's l2: 5.87638\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.87638\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 11.6834\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.3566\n",
      "[3]\tvalid_0's l2: 9.25679\n",
      "[4]\tvalid_0's l2: 8.35975\n",
      "[5]\tvalid_0's l2: 7.62593\n",
      "[6]\tvalid_0's l2: 7.03516\n",
      "[7]\tvalid_0's l2: 6.54599\n",
      "[8]\tvalid_0's l2: 6.15112\n",
      "[9]\tvalid_0's l2: 5.8221\n",
      "[10]\tvalid_0's l2: 5.55943\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.55943\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 11.9386\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.6275\n",
      "[3]\tvalid_0's l2: 9.53059\n",
      "[4]\tvalid_0's l2: 8.64083\n",
      "[5]\tvalid_0's l2: 7.91001\n",
      "[6]\tvalid_0's l2: 7.32862\n",
      "[7]\tvalid_0's l2: 6.83618\n",
      "[8]\tvalid_0's l2: 6.44053\n",
      "[9]\tvalid_0's l2: 6.11996\n",
      "[10]\tvalid_0's l2: 5.85573\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.85573\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 11.6814\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.3739\n",
      "[3]\tvalid_0's l2: 9.29371\n",
      "[4]\tvalid_0's l2: 8.40965\n",
      "[5]\tvalid_0's l2: 7.68756\n",
      "[6]\tvalid_0's l2: 7.10924\n",
      "[7]\tvalid_0's l2: 6.62852\n",
      "[8]\tvalid_0's l2: 6.23676\n",
      "[9]\tvalid_0's l2: 5.91484\n",
      "[10]\tvalid_0's l2: 5.65262\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.65262\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 12.1385\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.7905\n",
      "[3]\tvalid_0's l2: 9.67014\n",
      "[4]\tvalid_0's l2: 8.75887\n",
      "[5]\tvalid_0's l2: 8.00965\n",
      "[6]\tvalid_0's l2: 7.40407\n",
      "[7]\tvalid_0's l2: 6.89885\n",
      "[8]\tvalid_0's l2: 6.49231\n",
      "[9]\tvalid_0's l2: 6.15492\n",
      "[10]\tvalid_0's l2: 5.88202\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.88202\n",
      "mean rmse score over folds is nan\n",
      "22\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t22', 'lag_t23', 'lag_t24', 'lag_t25'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 11.7253\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.416\n",
      "[3]\tvalid_0's l2: 9.33048\n",
      "[4]\tvalid_0's l2: 8.45388\n",
      "[5]\tvalid_0's l2: 7.7307\n",
      "[6]\tvalid_0's l2: 7.15222\n",
      "[7]\tvalid_0's l2: 6.66424\n",
      "[8]\tvalid_0's l2: 6.27126\n",
      "[9]\tvalid_0's l2: 5.94069\n",
      "[10]\tvalid_0's l2: 5.67963\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.67963\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 12.1516\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.7973\n",
      "[3]\tvalid_0's l2: 9.68795\n",
      "[4]\tvalid_0's l2: 8.7707\n",
      "[5]\tvalid_0's l2: 8.02547\n",
      "[6]\tvalid_0's l2: 7.4268\n",
      "[7]\tvalid_0's l2: 6.91835\n",
      "[8]\tvalid_0's l2: 6.50676\n",
      "[9]\tvalid_0's l2: 6.16082\n",
      "[10]\tvalid_0's l2: 5.88334\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.88334\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 11.8574\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.5329\n",
      "[3]\tvalid_0's l2: 9.44609\n",
      "[4]\tvalid_0's l2: 8.55566\n",
      "[5]\tvalid_0's l2: 7.83717\n",
      "[6]\tvalid_0's l2: 7.25225\n",
      "[7]\tvalid_0's l2: 6.76696\n",
      "[8]\tvalid_0's l2: 6.36104\n",
      "[9]\tvalid_0's l2: 6.02546\n",
      "[10]\tvalid_0's l2: 5.75644\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.75644\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 12.2369\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.9061\n",
      "[3]\tvalid_0's l2: 9.81186\n",
      "[4]\tvalid_0's l2: 8.91418\n",
      "[5]\tvalid_0's l2: 8.1923\n",
      "[6]\tvalid_0's l2: 7.60095\n",
      "[7]\tvalid_0's l2: 7.10958\n",
      "[8]\tvalid_0's l2: 6.70619\n",
      "[9]\tvalid_0's l2: 6.37415\n",
      "[10]\tvalid_0's l2: 6.10657\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 6.10657\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 11.6576\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.3421\n",
      "[3]\tvalid_0's l2: 9.26909\n",
      "[4]\tvalid_0's l2: 8.38545\n",
      "[5]\tvalid_0's l2: 7.66179\n",
      "[6]\tvalid_0's l2: 7.08471\n",
      "[7]\tvalid_0's l2: 6.59484\n",
      "[8]\tvalid_0's l2: 6.19284\n",
      "[9]\tvalid_0's l2: 5.86026\n",
      "[10]\tvalid_0's l2: 5.596\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.596\n",
      "mean rmse score over folds is nan\n",
      "23\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t23', 'lag_t24', 'lag_t25', 'lag_t26'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 12.1146\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.7591\n",
      "[3]\tvalid_0's l2: 9.64541\n",
      "[4]\tvalid_0's l2: 8.73048\n",
      "[5]\tvalid_0's l2: 7.98057\n",
      "[6]\tvalid_0's l2: 7.37508\n",
      "[7]\tvalid_0's l2: 6.87264\n",
      "[8]\tvalid_0's l2: 6.45745\n",
      "[9]\tvalid_0's l2: 6.10959\n",
      "[10]\tvalid_0's l2: 5.83544\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.83544\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 11.8396\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.5204\n",
      "[3]\tvalid_0's l2: 9.43569\n",
      "[4]\tvalid_0's l2: 8.54307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\tvalid_0's l2: 7.8166\n",
      "[6]\tvalid_0's l2: 7.2323\n",
      "[7]\tvalid_0's l2: 6.74056\n",
      "[8]\tvalid_0's l2: 6.33836\n",
      "[9]\tvalid_0's l2: 5.99515\n",
      "[10]\tvalid_0's l2: 5.7277\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.7277\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 12.0517\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.7425\n",
      "[3]\tvalid_0's l2: 9.66264\n",
      "[4]\tvalid_0's l2: 8.76943\n",
      "[5]\tvalid_0's l2: 8.04503\n",
      "[6]\tvalid_0's l2: 7.46808\n",
      "[7]\tvalid_0's l2: 6.98732\n",
      "[8]\tvalid_0's l2: 6.58638\n",
      "[9]\tvalid_0's l2: 6.25312\n",
      "[10]\tvalid_0's l2: 5.98722\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.98722\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 11.9647\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.6195\n",
      "[3]\tvalid_0's l2: 9.51905\n",
      "[4]\tvalid_0's l2: 8.60502\n",
      "[5]\tvalid_0's l2: 7.86083\n",
      "[6]\tvalid_0's l2: 7.27947\n",
      "[7]\tvalid_0's l2: 6.78674\n",
      "[8]\tvalid_0's l2: 6.37794\n",
      "[9]\tvalid_0's l2: 6.03959\n",
      "[10]\tvalid_0's l2: 5.77405\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.77405\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 11.6731\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.3487\n",
      "[3]\tvalid_0's l2: 9.26313\n",
      "[4]\tvalid_0's l2: 8.36265\n",
      "[5]\tvalid_0's l2: 7.62983\n",
      "[6]\tvalid_0's l2: 7.0433\n",
      "[7]\tvalid_0's l2: 6.55111\n",
      "[8]\tvalid_0's l2: 6.14059\n",
      "[9]\tvalid_0's l2: 5.80742\n",
      "[10]\tvalid_0's l2: 5.53989\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.53989\n",
      "mean rmse score over folds is nan\n",
      "24\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t24', 'lag_t25', 'lag_t26', 'lag_t27'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 11.991\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.6515\n",
      "[3]\tvalid_0's l2: 9.5408\n",
      "[4]\tvalid_0's l2: 8.6322\n",
      "[5]\tvalid_0's l2: 7.88679\n",
      "[6]\tvalid_0's l2: 7.29471\n",
      "[7]\tvalid_0's l2: 6.79743\n",
      "[8]\tvalid_0's l2: 6.39608\n",
      "[9]\tvalid_0's l2: 6.05947\n",
      "[10]\tvalid_0's l2: 5.7889\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.7889\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 12.2533\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.9072\n",
      "[3]\tvalid_0's l2: 9.79819\n",
      "[4]\tvalid_0's l2: 8.88041\n",
      "[5]\tvalid_0's l2: 8.12962\n",
      "[6]\tvalid_0's l2: 7.53235\n",
      "[7]\tvalid_0's l2: 7.02688\n",
      "[8]\tvalid_0's l2: 6.62295\n",
      "[9]\tvalid_0's l2: 6.27947\n",
      "[10]\tvalid_0's l2: 6.00602\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 6.00602\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 11.8247\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4981\n",
      "[3]\tvalid_0's l2: 9.41431\n",
      "[4]\tvalid_0's l2: 8.50619\n",
      "[5]\tvalid_0's l2: 7.77129\n",
      "[6]\tvalid_0's l2: 7.1892\n",
      "[7]\tvalid_0's l2: 6.70163\n",
      "[8]\tvalid_0's l2: 6.3032\n",
      "[9]\tvalid_0's l2: 5.97594\n",
      "[10]\tvalid_0's l2: 5.71105\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.71105\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 11.8593\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.5372\n",
      "[3]\tvalid_0's l2: 9.4485\n",
      "[4]\tvalid_0's l2: 8.55227\n",
      "[5]\tvalid_0's l2: 7.81001\n",
      "[6]\tvalid_0's l2: 7.22114\n",
      "[7]\tvalid_0's l2: 6.72879\n",
      "[8]\tvalid_0's l2: 6.32849\n",
      "[9]\tvalid_0's l2: 5.99456\n",
      "[10]\tvalid_0's l2: 5.72412\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.72412\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 11.7399\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4326\n",
      "[3]\tvalid_0's l2: 9.35438\n",
      "[4]\tvalid_0's l2: 8.46012\n",
      "[5]\tvalid_0's l2: 7.73151\n",
      "[6]\tvalid_0's l2: 7.15474\n",
      "[7]\tvalid_0's l2: 6.67064\n",
      "[8]\tvalid_0's l2: 6.2781\n",
      "[9]\tvalid_0's l2: 5.95169\n",
      "[10]\tvalid_0's l2: 5.69079\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.69079\n",
      "mean rmse score over folds is nan\n",
      "25\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t25', 'lag_t26', 'lag_t27', 'lag_t28'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 11.7999\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4828\n",
      "[3]\tvalid_0's l2: 9.39652\n",
      "[4]\tvalid_0's l2: 8.50346\n",
      "[5]\tvalid_0's l2: 7.77958\n",
      "[6]\tvalid_0's l2: 7.19816\n",
      "[7]\tvalid_0's l2: 6.70556\n",
      "[8]\tvalid_0's l2: 6.31076\n",
      "[9]\tvalid_0's l2: 5.97924\n",
      "[10]\tvalid_0's l2: 5.71268\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.71268\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 12.0061\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.6667\n",
      "[3]\tvalid_0's l2: 9.57279\n",
      "[4]\tvalid_0's l2: 8.67737\n",
      "[5]\tvalid_0's l2: 7.94532\n",
      "[6]\tvalid_0's l2: 7.34682\n",
      "[7]\tvalid_0's l2: 6.84452\n",
      "[8]\tvalid_0's l2: 6.44021\n",
      "[9]\tvalid_0's l2: 6.11287\n",
      "[10]\tvalid_0's l2: 5.84855\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.84855\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 11.9822\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.6315\n",
      "[3]\tvalid_0's l2: 9.52499\n",
      "[4]\tvalid_0's l2: 8.61154\n",
      "[5]\tvalid_0's l2: 7.86794\n",
      "[6]\tvalid_0's l2: 7.2682\n",
      "[7]\tvalid_0's l2: 6.77142\n",
      "[8]\tvalid_0's l2: 6.36716\n",
      "[9]\tvalid_0's l2: 6.02923\n",
      "[10]\tvalid_0's l2: 5.75484\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.75484\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 12.0478\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.7462\n",
      "[3]\tvalid_0's l2: 9.6771\n",
      "[4]\tvalid_0's l2: 8.79939\n",
      "[5]\tvalid_0's l2: 8.08132\n",
      "[6]\tvalid_0's l2: 7.50809\n",
      "[7]\tvalid_0's l2: 7.0279\n",
      "[8]\tvalid_0's l2: 6.63949\n",
      "[9]\tvalid_0's l2: 6.31255\n",
      "[10]\tvalid_0's l2: 6.05537\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 6.05537\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 11.8084\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4922\n",
      "[3]\tvalid_0's l2: 9.40498\n",
      "[4]\tvalid_0's l2: 8.51121\n",
      "[5]\tvalid_0's l2: 7.78108\n",
      "[6]\tvalid_0's l2: 7.20353\n",
      "[7]\tvalid_0's l2: 6.71254\n",
      "[8]\tvalid_0's l2: 6.31388\n",
      "[9]\tvalid_0's l2: 5.97858\n",
      "[10]\tvalid_0's l2: 5.71678\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.71678\n",
      "mean rmse score over folds is nan\n",
      "26\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t26', 'lag_t27', 'lag_t28', 'lag_t29'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 12.0157\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.6678\n",
      "[3]\tvalid_0's l2: 9.55067\n",
      "[4]\tvalid_0's l2: 8.64864\n",
      "[5]\tvalid_0's l2: 7.90917\n",
      "[6]\tvalid_0's l2: 7.31225\n",
      "[7]\tvalid_0's l2: 6.81187\n",
      "[8]\tvalid_0's l2: 6.41101\n",
      "[9]\tvalid_0's l2: 6.0657\n",
      "[10]\tvalid_0's l2: 5.79858\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.79858\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 12.0348\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.7124\n",
      "[3]\tvalid_0's l2: 9.61736\n",
      "[4]\tvalid_0's l2: 8.72343\n",
      "[5]\tvalid_0's l2: 7.99578\n",
      "[6]\tvalid_0's l2: 7.41651\n",
      "[7]\tvalid_0's l2: 6.9287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\tvalid_0's l2: 6.5332\n",
      "[9]\tvalid_0's l2: 6.19602\n",
      "[10]\tvalid_0's l2: 5.93411\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.93411\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 11.7677\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4593\n",
      "[3]\tvalid_0's l2: 9.38286\n",
      "[4]\tvalid_0's l2: 8.49365\n",
      "[5]\tvalid_0's l2: 7.76476\n",
      "[6]\tvalid_0's l2: 7.18413\n",
      "[7]\tvalid_0's l2: 6.69437\n",
      "[8]\tvalid_0's l2: 6.30222\n",
      "[9]\tvalid_0's l2: 5.96615\n",
      "[10]\tvalid_0's l2: 5.70453\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.70453\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 11.9231\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.588\n",
      "[3]\tvalid_0's l2: 9.49368\n",
      "[4]\tvalid_0's l2: 8.60178\n",
      "[5]\tvalid_0's l2: 7.87162\n",
      "[6]\tvalid_0's l2: 7.28382\n",
      "[7]\tvalid_0's l2: 6.79506\n",
      "[8]\tvalid_0's l2: 6.40256\n",
      "[9]\tvalid_0's l2: 6.07282\n",
      "[10]\tvalid_0's l2: 5.80861\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.80861\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 11.9576\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.6312\n",
      "[3]\tvalid_0's l2: 9.54502\n",
      "[4]\tvalid_0's l2: 8.64365\n",
      "[5]\tvalid_0's l2: 7.91908\n",
      "[6]\tvalid_0's l2: 7.32906\n",
      "[7]\tvalid_0's l2: 6.83487\n",
      "[8]\tvalid_0's l2: 6.43336\n",
      "[9]\tvalid_0's l2: 6.09391\n",
      "[10]\tvalid_0's l2: 5.82282\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.82282\n",
      "mean rmse score over folds is nan\n",
      "27\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t27', 'lag_t28', 'lag_t29', 'lag_t30'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 11.9364\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.6151\n",
      "[3]\tvalid_0's l2: 9.53129\n",
      "[4]\tvalid_0's l2: 8.64112\n",
      "[5]\tvalid_0's l2: 7.91291\n",
      "[6]\tvalid_0's l2: 7.3269\n",
      "[7]\tvalid_0's l2: 6.83392\n",
      "[8]\tvalid_0's l2: 6.4353\n",
      "[9]\tvalid_0's l2: 6.09696\n",
      "[10]\tvalid_0's l2: 5.82781\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.82781\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 11.8153\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.5182\n",
      "[3]\tvalid_0's l2: 9.45152\n",
      "[4]\tvalid_0's l2: 8.58444\n",
      "[5]\tvalid_0's l2: 7.87379\n",
      "[6]\tvalid_0's l2: 7.305\n",
      "[7]\tvalid_0's l2: 6.82452\n",
      "[8]\tvalid_0's l2: 6.44102\n",
      "[9]\tvalid_0's l2: 6.11884\n",
      "[10]\tvalid_0's l2: 5.86558\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.86558\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 12.0004\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.6631\n",
      "[3]\tvalid_0's l2: 9.55498\n",
      "[4]\tvalid_0's l2: 8.65668\n",
      "[5]\tvalid_0's l2: 7.91681\n",
      "[6]\tvalid_0's l2: 7.32912\n",
      "[7]\tvalid_0's l2: 6.8292\n",
      "[8]\tvalid_0's l2: 6.43074\n",
      "[9]\tvalid_0's l2: 6.09748\n",
      "[10]\tvalid_0's l2: 5.82814\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.82814\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 12.1364\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.7744\n",
      "[3]\tvalid_0's l2: 9.64954\n",
      "[4]\tvalid_0's l2: 8.74227\n",
      "[5]\tvalid_0's l2: 7.9957\n",
      "[6]\tvalid_0's l2: 7.40118\n",
      "[7]\tvalid_0's l2: 6.89521\n",
      "[8]\tvalid_0's l2: 6.48691\n",
      "[9]\tvalid_0's l2: 6.14611\n",
      "[10]\tvalid_0's l2: 5.87288\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.87288\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 11.7988\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4849\n",
      "[3]\tvalid_0's l2: 9.40511\n",
      "[4]\tvalid_0's l2: 8.5197\n",
      "[5]\tvalid_0's l2: 7.79716\n",
      "[6]\tvalid_0's l2: 7.21807\n",
      "[7]\tvalid_0's l2: 6.73262\n",
      "[8]\tvalid_0's l2: 6.33592\n",
      "[9]\tvalid_0's l2: 6.00578\n",
      "[10]\tvalid_0's l2: 5.74407\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.74407\n",
      "mean rmse score over folds is nan\n",
      "28\n",
      "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
      "       'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
      "       'snap_WI', 'is_event', 'day', 'week', 'sell_price', 'rolling_mean_t7',\n",
      "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
      "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
      "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
      "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
      "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
      "       'lag_t28', 'lag_t29', 'lag_t30', 'lag_t31'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 11.8844\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.5831\n",
      "[3]\tvalid_0's l2: 9.516\n",
      "[4]\tvalid_0's l2: 8.6483\n",
      "[5]\tvalid_0's l2: 7.93416\n",
      "[6]\tvalid_0's l2: 7.36078\n",
      "[7]\tvalid_0's l2: 6.88263\n",
      "[8]\tvalid_0's l2: 6.49458\n",
      "[9]\tvalid_0's l2: 6.17679\n",
      "[10]\tvalid_0's l2: 5.91972\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.91972\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 11.8931\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.5607\n",
      "[3]\tvalid_0's l2: 9.46202\n",
      "[4]\tvalid_0's l2: 8.56541\n",
      "[5]\tvalid_0's l2: 7.83369\n",
      "[6]\tvalid_0's l2: 7.24947\n",
      "[7]\tvalid_0's l2: 6.75355\n",
      "[8]\tvalid_0's l2: 6.35584\n",
      "[9]\tvalid_0's l2: 6.02584\n",
      "[10]\tvalid_0's l2: 5.76355\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.76355\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 12.2664\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.8966\n",
      "[3]\tvalid_0's l2: 9.763\n",
      "[4]\tvalid_0's l2: 8.83109\n",
      "[5]\tvalid_0's l2: 8.07685\n",
      "[6]\tvalid_0's l2: 7.47461\n",
      "[7]\tvalid_0's l2: 6.96227\n",
      "[8]\tvalid_0's l2: 6.54598\n",
      "[9]\tvalid_0's l2: 6.19584\n",
      "[10]\tvalid_0's l2: 5.91775\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.91775\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 11.9605\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.6238\n",
      "[3]\tvalid_0's l2: 9.5367\n",
      "[4]\tvalid_0's l2: 8.63561\n",
      "[5]\tvalid_0's l2: 7.89905\n",
      "[6]\tvalid_0's l2: 7.31589\n",
      "[7]\tvalid_0's l2: 6.82158\n",
      "[8]\tvalid_0's l2: 6.41747\n",
      "[9]\tvalid_0's l2: 6.07905\n",
      "[10]\tvalid_0's l2: 5.80949\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.80949\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 11.6724\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.3834\n",
      "[3]\tvalid_0's l2: 9.31296\n",
      "[4]\tvalid_0's l2: 8.43154\n",
      "[5]\tvalid_0's l2: 7.71428\n",
      "[6]\tvalid_0's l2: 7.14261\n",
      "[7]\tvalid_0's l2: 6.66416\n",
      "[8]\tvalid_0's l2: 6.27637\n",
      "[9]\tvalid_0's l2: 5.95462\n",
      "[10]\tvalid_0's l2: 5.69606\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10]\tvalid_0's l2: 5.69606\n",
      "mean rmse score over folds is nan\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-95730d03b98e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[0mtest_sales\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m         \u001b[0mtest_sales\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "test_date = ['2016-04-25', '2016-04-26', '2016-04-27', '2016-04-28',\n",
    "       '2016-04-29', '2016-04-30', '2016-05-01', '2016-05-02',\n",
    "       '2016-05-03', '2016-05-04', '2016-05-05', '2016-05-06',\n",
    "       '2016-05-07', '2016-05-08', '2016-05-09', '2016-05-10',\n",
    "       '2016-05-11', '2016-05-12', '2016-05-13', '2016-05-14',\n",
    "       '2016-05-15', '2016-05-16', '2016-05-17', '2016-05-18',\n",
    "       '2016-05-19', '2016-05-20', '2016-05-21', '2016-05-22']\n",
    "\n",
    "cols = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'weekday',\n",
    "        'month', 'year', 'event_name_1', 'event_type_1', 'snap_CA', 'snap_TX',\n",
    "        'snap_WI', 'day', 'week', 'sell_price',\n",
    "        'rolling_mean_t7', 'rolling_std_t7', 'rolling_mean_t28',\n",
    "        'rolling_std_t28', 'rolling_mean_t56', 'rolling_std_t56',\n",
    "        'rolling_mean_t84', 'rolling_mean_t168', \n",
    "        'price_change_t1', 'price_change_t365', 'rolling_price_std_t7',\n",
    "        'rolling_price_std_t28']\n",
    "\n",
    "train_y = all_df2_X.sales\n",
    "results = []\n",
    "\n",
    "for i in range(len(test_date)):\n",
    "    print(i+1)\n",
    "    cols2 = cols.copy()\n",
    "    for j in range(i+1, i+5):\n",
    "        cols2.append(f'lag_t{j}')\n",
    "    train_X = all_df2_X[cols2]\n",
    "    test = all_df17_20[all_df17_20['date'] == test_date[i]]\n",
    "    test = test[cols2]\n",
    "    \n",
    "    n_fold = 5\n",
    "    folds = KFold(n_splits=n_fold, shuffle=True)\n",
    "    splits = folds.split(train_X, train_y)\n",
    "\n",
    "    y_preds = np.zeros(test.shape[0])\n",
    "    y_oof = np.zeros(train_X.shape[0])\n",
    "\n",
    "    feature_importances = pd.DataFrame()\n",
    "    feature_importances['feature'] = train_X.columns\n",
    "    mean_score = []\n",
    "\n",
    "    print(train_X.columns)\n",
    "\n",
    "    for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "        print('Fold:',fold_n+1)\n",
    "\n",
    "        X_train, X_valid = train_X.iloc[train_index], train_X.iloc[valid_index]\n",
    "        y_train, y_valid = train_y.iloc[train_index], train_y.iloc[valid_index]\n",
    "\n",
    "        lgb = LGBMRegressor(\n",
    "            objective = 'regression',\n",
    "            boosting_type = 'gbdt',\n",
    "            num_leaves = 4096,\n",
    "            colsample_bytree = 0.8,\n",
    "            subsample = 0.8,\n",
    "            n_estimators = 10, ## 중요!!!!\n",
    "            learning_rate = 0.1,\n",
    "            n_jobs = -1,\n",
    "            device = 'gpu',\n",
    "            reg_lambda = 0.1\n",
    "        )\n",
    "        lgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], early_stopping_rounds = 20, verbose = True)\n",
    "\n",
    "        feature_importances[f'fold_{fold_n + 1}'] = lgb.feature_importances_\n",
    "\n",
    "#         y_pred_valid = lgb.predict(X_valid, num_iteration=lgb.best_iteration_)\n",
    "#         y_oof[valid_index] = y_pred_valid\n",
    "        # validation 측정\n",
    "#         val_score = np.sqrt(metrics.mean_squared_error(y_pred_valid, y_valid))\n",
    "#         print(f'val rmse score is {val_score}')\n",
    "#         mean_score.append(val_score)\n",
    "#         all_pred = lgb.predict(var_set_X, num_iteration=lgb.best_iteration_)\n",
    "#         all_var_score = np.sqrt(metrics.mean_squared_error(all_pred, var_set_y))\n",
    "#         print(f'2015-04-27 부터 2015-05-22까지 데이터로 validation rmse 결과: {all_var_score}')\n",
    "\n",
    "\n",
    "        # 예측\n",
    "        y_preds += lgb.predict(test, num_iteration=lgb.best_iteration_) / n_fold\n",
    "\n",
    "        # 메모리 정리\n",
    "        del X_train, X_valid, y_train, y_valid\n",
    "\n",
    "\n",
    "#     params = lgb.get_params()\n",
    "#     eval_results = lgb.evals_result_['valid_0']['l2']\n",
    "\n",
    "#     print('mean rmse score over folds is',np.mean(mean_score))\n",
    "    results.append(y_preds)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "test_sales = []\n",
    "for i in results:\n",
    "    for j in i:\n",
    "        test_sales.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df2_test = all_df17_20[all_df17_20['date'] > '2016-04-24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kjb\\data_analysis\\10_estimate_sales_of_walmart_retail_goods\\venv\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "all_df2_test['sales'] = test_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>is_event</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>lag_t1</th>\n",
       "      <th>lag_t2</th>\n",
       "      <th>lag_t3</th>\n",
       "      <th>lag_t4</th>\n",
       "      <th>lag_t5</th>\n",
       "      <th>lag_t6</th>\n",
       "      <th>lag_t7</th>\n",
       "      <th>lag_t8</th>\n",
       "      <th>lag_t9</th>\n",
       "      <th>lag_t10</th>\n",
       "      <th>lag_t11</th>\n",
       "      <th>lag_t12</th>\n",
       "      <th>lag_t13</th>\n",
       "      <th>lag_t14</th>\n",
       "      <th>lag_t15</th>\n",
       "      <th>lag_t16</th>\n",
       "      <th>lag_t17</th>\n",
       "      <th>lag_t18</th>\n",
       "      <th>lag_t19</th>\n",
       "      <th>lag_t20</th>\n",
       "      <th>lag_t21</th>\n",
       "      <th>lag_t22</th>\n",
       "      <th>lag_t23</th>\n",
       "      <th>lag_t24</th>\n",
       "      <th>lag_t25</th>\n",
       "      <th>lag_t26</th>\n",
       "      <th>lag_t27</th>\n",
       "      <th>lag_t28</th>\n",
       "      <th>rolling_mean_t7</th>\n",
       "      <th>rolling_std_t7</th>\n",
       "      <th>rolling_mean_t28</th>\n",
       "      <th>rolling_std_t28</th>\n",
       "      <th>rolling_mean_t56</th>\n",
       "      <th>rolling_std_t56</th>\n",
       "      <th>rolling_mean_t84</th>\n",
       "      <th>rolling_std_t84</th>\n",
       "      <th>rolling_mean_t112</th>\n",
       "      <th>rolling_std_t112</th>\n",
       "      <th>rolling_mean_t168</th>\n",
       "      <th>rolling_std_t168</th>\n",
       "      <th>price_change_t1</th>\n",
       "      <th>price_change_t365</th>\n",
       "      <th>rolling_price_std_t7</th>\n",
       "      <th>rolling_price_std_t28</th>\n",
       "      <th>lag_t29</th>\n",
       "      <th>lag_t30</th>\n",
       "      <th>lag_t31</th>\n",
       "      <th>lag_t32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14370</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1017</td>\n",
       "      <td>1.009044</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>11613</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>8.382812</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.142578</td>\n",
       "      <td>0.689941</td>\n",
       "      <td>1.036133</td>\n",
       "      <td>0.922363</td>\n",
       "      <td>1.017578</td>\n",
       "      <td>1.103516</td>\n",
       "      <td>0.940430</td>\n",
       "      <td>1.144531</td>\n",
       "      <td>0.910645</td>\n",
       "      <td>1.103516</td>\n",
       "      <td>0.779785</td>\n",
       "      <td>1.017578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.960464e-08</td>\n",
       "      <td>6.216431e-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14380</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1017</td>\n",
       "      <td>0.578026</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>11613</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>3.970703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714355</td>\n",
       "      <td>0.488037</td>\n",
       "      <td>0.357178</td>\n",
       "      <td>0.488037</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.437012</td>\n",
       "      <td>0.226196</td>\n",
       "      <td>0.420898</td>\n",
       "      <td>0.384033</td>\n",
       "      <td>0.830078</td>\n",
       "      <td>0.380859</td>\n",
       "      <td>0.772461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14390</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1017</td>\n",
       "      <td>0.843942</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>11613</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>2.970703</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285645</td>\n",
       "      <td>0.488037</td>\n",
       "      <td>0.535645</td>\n",
       "      <td>1.201172</td>\n",
       "      <td>0.428467</td>\n",
       "      <td>0.911621</td>\n",
       "      <td>0.321533</td>\n",
       "      <td>0.778809</td>\n",
       "      <td>0.633789</td>\n",
       "      <td>1.065430</td>\n",
       "      <td>0.643066</td>\n",
       "      <td>1.016602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14400</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1017</td>\n",
       "      <td>1.707772</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>11613</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>4.640625</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.708984</td>\n",
       "      <td>1.892578</td>\n",
       "      <td>1.968750</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.907227</td>\n",
       "      <td>2.023438</td>\n",
       "      <td>1.907227</td>\n",
       "      <td>1.892578</td>\n",
       "      <td>1.827148</td>\n",
       "      <td>1.898438</td>\n",
       "      <td>1.763672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14410</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1017</td>\n",
       "      <td>1.176830</td>\n",
       "      <td>2016-04-25</td>\n",
       "      <td>11613</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>2.880859</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714355</td>\n",
       "      <td>1.112305</td>\n",
       "      <td>1.107422</td>\n",
       "      <td>0.994141</td>\n",
       "      <td>1.142578</td>\n",
       "      <td>1.166992</td>\n",
       "      <td>1.011719</td>\n",
       "      <td>1.135742</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.216797</td>\n",
       "      <td>1.136719</td>\n",
       "      <td>1.167969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.960464e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  item_id  dept_id  cat_id  store_id  state_id     d     sales  \\\n",
       "0  14370     1437        3       1         0         0  1017  1.009044   \n",
       "1  14380     1438        3       1         0         0  1017  0.578026   \n",
       "2  14390     1439        3       1         0         0  1017  0.843942   \n",
       "3  14400     1440        3       1         0         0  1017  1.707772   \n",
       "4  14410     1441        3       1         0         0  1017  1.176830   \n",
       "\n",
       "         date  wm_yr_wk  weekday  month  year  event_name_1  event_type_1  \\\n",
       "0  2016-04-25     11613        1      4  2016            30             4   \n",
       "1  2016-04-25     11613        1      4  2016            30             4   \n",
       "2  2016-04-25     11613        1      4  2016            30             4   \n",
       "3  2016-04-25     11613        1      4  2016            30             4   \n",
       "4  2016-04-25     11613        1      4  2016            30             4   \n",
       "\n",
       "   snap_CA  snap_TX  snap_WI  is_event  day  week  sell_price  lag_t1  lag_t2  \\\n",
       "0        0        0        0         0   25    17    8.382812     1.0     1.0   \n",
       "1        0        0        0         0   25    17    3.970703     0.0     0.0   \n",
       "2        0        0        0         0   25    17    2.970703     1.0     1.0   \n",
       "3        0        0        0         0   25    17    4.640625     2.0     7.0   \n",
       "4        0        0        0         0   25    17    2.880859     4.0     2.0   \n",
       "\n",
       "   lag_t3  lag_t4  lag_t5  lag_t6  lag_t7  lag_t8  lag_t9  lag_t10  lag_t11  \\\n",
       "0     0.0     3.0     1.0     1.0     1.0     0.0     3.0      1.0      1.0   \n",
       "1     0.0     0.0     1.0     0.0     0.0     0.0     0.0      0.0      0.0   \n",
       "2     1.0     0.0     1.0     1.0     1.0     2.0     1.0      2.0      2.0   \n",
       "3     3.0     1.0     0.0     1.0     4.0     5.0     0.0      1.0      0.0   \n",
       "4     2.0     2.0     1.0     1.0     0.0     1.0     1.0      2.0      1.0   \n",
       "\n",
       "   lag_t12  lag_t13  lag_t14  lag_t15  lag_t16  lag_t17  lag_t18  lag_t19  \\\n",
       "0      0.0      0.0      0.0      2.0      1.0      0.0      3.0      2.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      1.0      0.0      0.0      0.0      0.0      0.0      1.0      0.0   \n",
       "3      3.0      0.0      2.0      4.0      5.0      2.0      0.0      1.0   \n",
       "4      1.0      0.0      2.0      1.0      1.0      0.0      1.0      0.0   \n",
       "\n",
       "   lag_t20  lag_t21  lag_t22  lag_t23  lag_t24  lag_t25  lag_t26  lag_t27  \\\n",
       "0      4.0      0.0      1.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      1.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      3.0      1.0      2.0      1.0      3.0      0.0      0.0      0.0   \n",
       "4      1.0      0.0      4.0      1.0      0.0      4.0      4.0      0.0   \n",
       "\n",
       "   lag_t28  rolling_mean_t7  rolling_std_t7  rolling_mean_t28  \\\n",
       "0      1.0         1.142578        0.689941          1.036133   \n",
       "1      1.0         0.714355        0.488037          0.357178   \n",
       "2      0.0         0.285645        0.488037          0.535645   \n",
       "3      0.0         3.000000        2.708984          1.892578   \n",
       "4      1.0         0.714355        1.112305          1.107422   \n",
       "\n",
       "   rolling_std_t28  rolling_mean_t56  rolling_std_t56  rolling_mean_t84  \\\n",
       "0         0.922363          1.017578         1.103516          0.940430   \n",
       "1         0.488037          0.250000         0.437012          0.226196   \n",
       "2         1.201172          0.428467         0.911621          0.321533   \n",
       "3         1.968750          2.000000         1.907227          2.023438   \n",
       "4         0.994141          1.142578         1.166992          1.011719   \n",
       "\n",
       "   rolling_std_t84  rolling_mean_t112  rolling_std_t112  rolling_mean_t168  \\\n",
       "0         1.144531           0.910645          1.103516           0.779785   \n",
       "1         0.420898           0.384033          0.830078           0.380859   \n",
       "2         0.778809           0.633789          1.065430           0.643066   \n",
       "3         1.907227           1.892578          1.827148           1.898438   \n",
       "4         1.135742           1.125000          1.216797           1.136719   \n",
       "\n",
       "   rolling_std_t168  price_change_t1  price_change_t365  rolling_price_std_t7  \\\n",
       "0          1.017578              0.0                0.0          5.960464e-08   \n",
       "1          0.772461              0.0                0.0          0.000000e+00   \n",
       "2          1.016602              0.0                0.0          0.000000e+00   \n",
       "3          1.763672              0.0                0.0          0.000000e+00   \n",
       "4          1.167969              0.0                0.0          0.000000e+00   \n",
       "\n",
       "   rolling_price_std_t28  lag_t29  lag_t30  lag_t31  lag_t32  \n",
       "0           6.216431e-02      1.0      1.0      1.0      0.0  \n",
       "1           0.000000e+00      1.0      1.0      1.0      1.0  \n",
       "2           0.000000e+00      0.0      1.0      1.0      0.0  \n",
       "3           0.000000e+00      6.0      6.0      0.0      5.0  \n",
       "4           5.960464e-08      0.0      0.0      0.0      0.0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df2_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kjb\\data_analysis\\10_estimate_sales_of_walmart_retail_goods\\venv\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv('inputs/sample_submission.csv')\n",
    "\n",
    "predictions = all_df2_test[['id', 'date', 'sales']]\n",
    "predictions['id'] = list(le_id.inverse_transform(predictions['id']))\n",
    "\n",
    "\n",
    "predictions = pd.pivot(predictions, index = 'id', columns = 'date', values = 'sales').reset_index()\n",
    "predictions.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "\n",
    "evaluation_rows = [row for row in sub['id'] if 'evaluation' in row] \n",
    "evaluation = sub[sub['id'].isin(evaluation_rows)]\n",
    "\n",
    "validation = sub[['id']].merge(predictions, on = 'id')\n",
    "final = pd.concat([validation, evaluation])\n",
    "\n",
    "for i in range(1,29):\n",
    "    final['F'+str(i)] *= 1.0315\n",
    "final.to_csv('submissions/submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>1.040829</td>\n",
       "      <td>1.008477</td>\n",
       "      <td>1.001335</td>\n",
       "      <td>0.996877</td>\n",
       "      <td>0.974703</td>\n",
       "      <td>1.052290</td>\n",
       "      <td>1.060663</td>\n",
       "      <td>0.949905</td>\n",
       "      <td>0.962422</td>\n",
       "      <td>0.985934</td>\n",
       "      <td>1.078596</td>\n",
       "      <td>1.054044</td>\n",
       "      <td>1.131717</td>\n",
       "      <td>1.164227</td>\n",
       "      <td>1.117989</td>\n",
       "      <td>0.995352</td>\n",
       "      <td>0.990711</td>\n",
       "      <td>1.006945</td>\n",
       "      <td>1.004935</td>\n",
       "      <td>1.082160</td>\n",
       "      <td>1.095978</td>\n",
       "      <td>0.991201</td>\n",
       "      <td>0.970538</td>\n",
       "      <td>0.973718</td>\n",
       "      <td>0.975546</td>\n",
       "      <td>0.987273</td>\n",
       "      <td>1.094747</td>\n",
       "      <td>1.076632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>0.596234</td>\n",
       "      <td>0.592303</td>\n",
       "      <td>0.592461</td>\n",
       "      <td>0.600610</td>\n",
       "      <td>0.590171</td>\n",
       "      <td>0.600521</td>\n",
       "      <td>0.594017</td>\n",
       "      <td>0.523600</td>\n",
       "      <td>0.514450</td>\n",
       "      <td>0.527647</td>\n",
       "      <td>0.520629</td>\n",
       "      <td>0.522556</td>\n",
       "      <td>0.517424</td>\n",
       "      <td>0.526469</td>\n",
       "      <td>0.520571</td>\n",
       "      <td>0.529376</td>\n",
       "      <td>0.529671</td>\n",
       "      <td>0.524702</td>\n",
       "      <td>0.529149</td>\n",
       "      <td>0.538248</td>\n",
       "      <td>0.536614</td>\n",
       "      <td>0.546378</td>\n",
       "      <td>0.549540</td>\n",
       "      <td>0.595673</td>\n",
       "      <td>0.599086</td>\n",
       "      <td>0.599207</td>\n",
       "      <td>0.610455</td>\n",
       "      <td>0.620122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>0.870526</td>\n",
       "      <td>0.834366</td>\n",
       "      <td>0.804685</td>\n",
       "      <td>0.817698</td>\n",
       "      <td>0.842034</td>\n",
       "      <td>0.832011</td>\n",
       "      <td>0.836123</td>\n",
       "      <td>0.772816</td>\n",
       "      <td>0.746999</td>\n",
       "      <td>0.759746</td>\n",
       "      <td>0.745706</td>\n",
       "      <td>0.799203</td>\n",
       "      <td>0.833988</td>\n",
       "      <td>0.802618</td>\n",
       "      <td>0.766931</td>\n",
       "      <td>0.747476</td>\n",
       "      <td>0.748302</td>\n",
       "      <td>0.751212</td>\n",
       "      <td>0.775410</td>\n",
       "      <td>0.789070</td>\n",
       "      <td>0.857362</td>\n",
       "      <td>0.827086</td>\n",
       "      <td>0.807831</td>\n",
       "      <td>0.799655</td>\n",
       "      <td>0.793496</td>\n",
       "      <td>0.798423</td>\n",
       "      <td>0.871123</td>\n",
       "      <td>0.845051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>1.761567</td>\n",
       "      <td>1.590045</td>\n",
       "      <td>1.579701</td>\n",
       "      <td>1.554448</td>\n",
       "      <td>1.749171</td>\n",
       "      <td>2.044780</td>\n",
       "      <td>1.935437</td>\n",
       "      <td>1.663241</td>\n",
       "      <td>1.575218</td>\n",
       "      <td>1.539044</td>\n",
       "      <td>1.607629</td>\n",
       "      <td>1.766325</td>\n",
       "      <td>2.040632</td>\n",
       "      <td>1.816862</td>\n",
       "      <td>1.708681</td>\n",
       "      <td>1.591909</td>\n",
       "      <td>1.592651</td>\n",
       "      <td>1.623299</td>\n",
       "      <td>1.731085</td>\n",
       "      <td>1.933419</td>\n",
       "      <td>1.868436</td>\n",
       "      <td>1.640311</td>\n",
       "      <td>1.531623</td>\n",
       "      <td>1.508171</td>\n",
       "      <td>1.480948</td>\n",
       "      <td>1.687078</td>\n",
       "      <td>1.932614</td>\n",
       "      <td>1.803770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>1.213901</td>\n",
       "      <td>1.090715</td>\n",
       "      <td>1.169567</td>\n",
       "      <td>1.214288</td>\n",
       "      <td>1.340411</td>\n",
       "      <td>1.456490</td>\n",
       "      <td>1.592623</td>\n",
       "      <td>1.363413</td>\n",
       "      <td>1.298521</td>\n",
       "      <td>1.210473</td>\n",
       "      <td>1.190259</td>\n",
       "      <td>1.226741</td>\n",
       "      <td>1.423685</td>\n",
       "      <td>1.379871</td>\n",
       "      <td>1.218338</td>\n",
       "      <td>1.102772</td>\n",
       "      <td>1.121450</td>\n",
       "      <td>1.114823</td>\n",
       "      <td>1.200185</td>\n",
       "      <td>1.348453</td>\n",
       "      <td>1.347771</td>\n",
       "      <td>1.105502</td>\n",
       "      <td>1.043436</td>\n",
       "      <td>1.059877</td>\n",
       "      <td>1.077720</td>\n",
       "      <td>1.162767</td>\n",
       "      <td>1.323020</td>\n",
       "      <td>1.358750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        F1        F2        F3        F4  \\\n",
       "0  HOBBIES_1_001_CA_1_validation  1.040829  1.008477  1.001335  0.996877   \n",
       "1  HOBBIES_1_002_CA_1_validation  0.596234  0.592303  0.592461  0.600610   \n",
       "2  HOBBIES_1_003_CA_1_validation  0.870526  0.834366  0.804685  0.817698   \n",
       "3  HOBBIES_1_004_CA_1_validation  1.761567  1.590045  1.579701  1.554448   \n",
       "4  HOBBIES_1_005_CA_1_validation  1.213901  1.090715  1.169567  1.214288   \n",
       "\n",
       "         F5        F6        F7        F8        F9       F10       F11  \\\n",
       "0  0.974703  1.052290  1.060663  0.949905  0.962422  0.985934  1.078596   \n",
       "1  0.590171  0.600521  0.594017  0.523600  0.514450  0.527647  0.520629   \n",
       "2  0.842034  0.832011  0.836123  0.772816  0.746999  0.759746  0.745706   \n",
       "3  1.749171  2.044780  1.935437  1.663241  1.575218  1.539044  1.607629   \n",
       "4  1.340411  1.456490  1.592623  1.363413  1.298521  1.210473  1.190259   \n",
       "\n",
       "        F12       F13       F14       F15       F16       F17       F18  \\\n",
       "0  1.054044  1.131717  1.164227  1.117989  0.995352  0.990711  1.006945   \n",
       "1  0.522556  0.517424  0.526469  0.520571  0.529376  0.529671  0.524702   \n",
       "2  0.799203  0.833988  0.802618  0.766931  0.747476  0.748302  0.751212   \n",
       "3  1.766325  2.040632  1.816862  1.708681  1.591909  1.592651  1.623299   \n",
       "4  1.226741  1.423685  1.379871  1.218338  1.102772  1.121450  1.114823   \n",
       "\n",
       "        F19       F20       F21       F22       F23       F24       F25  \\\n",
       "0  1.004935  1.082160  1.095978  0.991201  0.970538  0.973718  0.975546   \n",
       "1  0.529149  0.538248  0.536614  0.546378  0.549540  0.595673  0.599086   \n",
       "2  0.775410  0.789070  0.857362  0.827086  0.807831  0.799655  0.793496   \n",
       "3  1.731085  1.933419  1.868436  1.640311  1.531623  1.508171  1.480948   \n",
       "4  1.200185  1.348453  1.347771  1.105502  1.043436  1.059877  1.077720   \n",
       "\n",
       "        F26       F27       F28  \n",
       "0  0.987273  1.094747  1.076632  \n",
       "1  0.599207  0.610455  0.620122  \n",
       "2  0.798423  0.871123  0.845051  \n",
       "3  1.687078  1.932614  1.803770  \n",
       "4  1.162767  1.323020  1.358750  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_df17_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_id_gb_sell_price_mean = all_df17_20.groupby(['store_id', 'item_id', 'year', 'week'])['sell_price'].mean().rename('item_id_gb_sell_price_mean')\n",
    "item_id_gb_sell_price_max = all_df17_20.groupby(['store_id', 'item_id', 'year', 'week'])['sell_price'].max().rename('item_id_gb_sell_price_max')\n",
    "item_id_gb_sell_price_min = all_df17_20.groupby(['store_id', 'item_id', 'year', 'week'])['sell_price'].min().rename('item_id_gb_sell_price_min')\n",
    "item_id_gb_sell_price_std = all_df17_20.groupby(['store_id', 'item_id', 'year', 'week'])['sell_price'].std().rename('item_id_gb_sell_price_std')\n",
    "\n",
    "all_df17_20 = pd.merge(all_df17_20, item_id_gb_sell_price_mean, on=['store_id', 'item_id', 'year', 'week'], how='left')\n",
    "all_df17_20 = pd.merge(all_df17_20, item_id_gb_sell_price_max, on=['store_id', 'item_id', 'year', 'week'], how='left')\n",
    "all_df17_20 = pd.merge(all_df17_20, item_id_gb_sell_price_min, on=['store_id', 'item_id', 'year', 'week'], how='left')\n",
    "all_df17_20 = pd.merge(all_df17_20, item_id_gb_sell_price_std, on=['store_id', 'item_id', 'year', 'week'], how='left')\n",
    "\n",
    "item_id_gb_lag28 = all_df17_20.groupby(['store_id', 'item_id', 'year', 'week'])['lag_t28'].mean().rename('item_id_gb_lag28')\n",
    "# all_df17_20 = pd.merge(all_df17_20, item_id_gb_lag28, on=['store_id', 'item_id', 'year', 'week'], how='left')\n",
    "\n",
    "# all_df17_20['diff'] = all_df17_20['sell_price'] - all_df17_20['item_id_gb_sell_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_df17_20['item_id_gb_sell_price_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id  month\n",
       "0        3        2.177734\n",
       "         4        2.154297\n",
       "         5        2.150391\n",
       "1        3        8.984375\n",
       "         4        8.921875\n",
       "                    ...   \n",
       "3047     4        1.966797\n",
       "         5        1.969727\n",
       "3048     3        5.941406\n",
       "         4        5.941406\n",
       "         5        5.910156\n",
       "Name: sell_price, Length: 9147, dtype: float16"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df17_20.groupby(['item_id', 'month'])['sell_price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 2011, 1) 1.175467366349623\n",
      "(0, 2011, 2) 1.1866185634634305\n",
      "(0, 2011, 3) 1.1864545752705806\n",
      "(0, 2011, 4) 1.0252541816989176\n",
      "(0, 2011, 5) 0.8474909806493932\n",
      "(0, 2011, 6) 0.9391603804526074\n",
      "(0, 2011, 7) 1.1138078058379797\n",
      "(0, 2011, 8) 1.0375532961626763\n",
      "(0, 2011, 9) 1.172843555264021\n",
      "(0, 2011, 10) 1.177271236470974\n",
      "(0, 2011, 11) 0.9255493604460479\n",
      "(0, 2011, 12) 0.7853394555591997\n",
      "(0, 2011, 13) 0.8568383076418498\n",
      "(0, 2011, 14) 1.0288619219416202\n",
      "(0, 2011, 15) 1.0969170219744178\n",
      "(0, 2011, 16) 1.0090193506067564\n",
      "(0, 2011, 17) 1.021318465070515\n",
      "(0, 2011, 18) 0.8091177435224663\n",
      "(0, 2011, 19) 0.7218760249262053\n",
      "(0, 2011, 20) 0.8076418497868153\n",
      "(0, 2011, 21) 0.975729747458183\n",
      "(0, 2011, 22) 1.107248278123975\n",
      "(0, 2011, 23) 1.3732371269268613\n",
      "(0, 2011, 24) 0.9662184322728764\n",
      "(0, 2011, 25) 0.7999344047228599\n",
      "(0, 2011, 26) 0.6838307641849787\n",
      "(0, 2011, 27) 0.6874385044276812\n",
      "(0, 2011, 28) 0.7979665464086586\n",
      "(0, 2011, 29) 0.7940308297802559\n",
      "(0, 2011, 30) 0.9522794358806166\n",
      "(0, 2011, 31) 0.8448671695637914\n",
      "(0, 2012, 1) 1.4408002623811085\n",
      "(0, 2012, 2) 1.2035093473269924\n",
      "(0, 2012, 3) 1.3096097081010167\n",
      "(0, 2012, 4) 1.2563135454247294\n",
      "(0, 2012, 5) 1.3824204657264676\n",
      "(0, 2012, 6) 1.7677927189242375\n",
      "(0, 2012, 7) 1.6990816661200394\n",
      "(0, 2012, 8) 1.2363069858970155\n",
      "(0, 2012, 9) 1.2274516234831092\n",
      "(0, 2012, 10) 1.2453263365037717\n",
      "(0, 2012, 11) 1.2468022302394228\n",
      "(0, 2012, 12) 1.4494916366021646\n",
      "(0, 2012, 13) 1.3981633322400786\n",
      "(0, 2012, 14) 1.395703509347327\n",
      "(0, 2012, 15) 1.374057067891112\n",
      "(0, 2012, 16) 1.123155132830436\n",
      "(0, 2012, 17) 1.0040997048212528\n",
      "(0, 2012, 18) 1.1267628730731387\n",
      "(0, 2012, 19) 1.3502787799278453\n",
      "(0, 2012, 20) 1.5744506395539521\n",
      "(0, 2012, 21) 1.6487372909150542\n",
      "(0, 2012, 22) 1.698589701541489\n",
      "(0, 2012, 23) 0.9734339127582814\n",
      "(0, 2012, 24) 0.9944244014430961\n",
      "(0, 2012, 25) 0.9350606756313545\n",
      "(0, 2012, 26) 1.0118071498852084\n",
      "(0, 2012, 27) 1.10019678583142\n",
      "(0, 2012, 28) 1.2335191866185635\n",
      "(0, 2012, 29) 1.2267956707117087\n",
      "(0, 2012, 30) 1.2476221712036732\n",
      "(0, 2012, 31) 1.6077402427025254\n",
      "(0, 2013, 1) 1.1480813381436537\n",
      "(0, 2013, 2) 1.1936700557559856\n",
      "(0, 2013, 3) 1.374057067891112\n",
      "(0, 2013, 4) 1.5026238110856018\n",
      "(0, 2013, 5) 1.6221712036733356\n",
      "(0, 2013, 6) 1.5811741554608068\n",
      "(0, 2013, 7) 1.5296818629058708\n",
      "(0, 2013, 8) 1.2205641193834045\n",
      "(0, 2013, 9) 1.2204001311905543\n",
      "(0, 2013, 10) 1.3028861921941621\n",
      "(0, 2013, 11) 1.5877336831748114\n",
      "(0, 2013, 12) 1.362905870777304\n",
      "(0, 2013, 13) 1.3984913086257789\n",
      "(0, 2013, 14) 1.4162020334535914\n",
      "(0, 2013, 15) 1.1347982945227943\n",
      "(0, 2013, 16) 1.1015086913742211\n",
      "(0, 2013, 17) 1.181534929485077\n",
      "(0, 2013, 18) 1.278615939652345\n",
      "(0, 2013, 19) 1.534437520498524\n",
      "(0, 2013, 20) 1.6146277468022303\n",
      "(0, 2013, 21) 1.650049196457855\n",
      "(0, 2013, 22) 1.1889143981633323\n",
      "(0, 2013, 23) 0.9960642833715972\n",
      "(0, 2013, 24) 1.0078714332568055\n",
      "(0, 2013, 25) 1.075762545096753\n",
      "(0, 2013, 26) 1.1402099048868481\n",
      "(0, 2013, 27) 1.2525418169891769\n",
      "(0, 2013, 28) 1.3722531977697605\n",
      "(0, 2013, 29) 1.280091833387996\n",
      "(0, 2013, 30) 1.5175467366349622\n",
      "(0, 2013, 31) 1.4034109544112825\n",
      "(0, 2014, 1) 1.2846835027877992\n",
      "(0, 2014, 2) 1.4391603804526074\n",
      "(0, 2014, 3) 1.6236470974089865\n",
      "(0, 2014, 4) 1.7435224663824205\n",
      "(0, 2014, 5) 1.6707117087569694\n",
      "(0, 2014, 6) 1.6653000983929158\n",
      "(0, 2014, 7) 1.3630698589701542\n",
      "(0, 2014, 8) 1.2661528369957362\n",
      "(0, 2014, 9) 1.3696293866841587\n",
      "(0, 2014, 10) 1.4947523778287963\n",
      "(0, 2014, 11) 1.3994752377828796\n",
      "(0, 2014, 12) 1.5459166939980322\n",
      "(0, 2014, 13) 1.5719908166612004\n",
      "(0, 2014, 14) 1.2225319776976058\n",
      "(0, 2014, 15) 1.1382420465726468\n",
      "(0, 2014, 16) 1.4193178091177434\n",
      "(0, 2014, 17) 1.4904886848146934\n",
      "(0, 2014, 18) 1.7673007543456871\n",
      "(0, 2014, 19) 2.0521482453263364\n",
      "(0, 2014, 20) 1.5788783207609052\n",
      "(0, 2014, 21) 1.255821580846179\n",
      "(0, 2014, 22) 1.241390619875369\n",
      "(0, 2014, 23) 1.0967530337815676\n",
      "(0, 2014, 24) 1.2222040013119055\n",
      "(0, 2014, 25) 1.2302394227615612\n",
      "(0, 2014, 26) 1.3979993440472287\n",
      "(0, 2014, 27) 1.465562479501476\n",
      "(0, 2014, 28) 1.2861593965234503\n",
      "(0, 2014, 29) 1.346999016070843\n",
      "(0, 2014, 30) 1.5204985241062643\n",
      "(0, 2014, 31) 1.1833387996064284\n",
      "(0, 2015, 1) 1.5688750409970482\n",
      "(0, 2015, 2) 1.6720236142997704\n",
      "(0, 2015, 3) 1.9934404722859953\n",
      "(0, 2015, 4) 1.874385044276812\n",
      "(0, 2015, 5) 1.482781239750738\n",
      "(0, 2015, 6) 1.3325680551000327\n",
      "(0, 2015, 7) 1.3105936372581175\n",
      "(0, 2015, 8) 1.3948835683830765\n",
      "(0, 2015, 9) 1.568711052804198\n",
      "(0, 2015, 10) 1.5739586749754018\n",
      "(0, 2015, 11) 1.655788783207609\n",
      "(0, 2015, 12) 1.6239750737946868\n",
      "(0, 2015, 13) 1.3330600196785831\n",
      "(0, 2015, 14) 1.1789111183994752\n",
      "(0, 2015, 15) 1.3189570350934732\n",
      "(0, 2015, 16) 1.52853394555592\n",
      "(0, 2015, 17) 1.6077402427025254\n",
      "(0, 2015, 18) 1.8533945555919973\n",
      "(0, 2015, 19) 1.9183338799606429\n",
      "(0, 2015, 20) 1.3548704493276484\n",
      "(0, 2015, 21) 1.1620203345359135\n",
      "(0, 2015, 22) 1.1295506723515907\n",
      "(0, 2015, 23) 1.2487700885536241\n",
      "(0, 2015, 24) 1.2648409314529354\n",
      "(0, 2015, 25) 1.5106592325352575\n",
      "(0, 2015, 26) 1.5090193506067564\n",
      "(0, 2015, 27) 1.3178091177435225\n",
      "(0, 2015, 28) 1.3763529025910135\n",
      "(0, 2015, 29) 1.4780255821580845\n",
      "(0, 2015, 30) 1.2663168251885863\n",
      "(0, 2015, 31) 1.27156444735979\n",
      "(0, 2016, 1) 0.817153164972122\n",
      "(0, 2016, 2) 0.9637586093801246\n",
      "(0, 2016, 3) 1.0652673007543456\n",
      "(0, 2016, 4) 0.7891111839947523\n",
      "(0, 2016, 5) 0.6662840275500164\n",
      "(0, 2016, 6) 0.6500491964578551\n",
      "(0, 2016, 7) 0.5993768448671696\n",
      "(0, 2016, 8) 0.7738602820596917\n",
      "(0, 2016, 9) 1.0022958346999016\n",
      "(0, 2016, 10) 0.9788455231223352\n",
      "(0, 2016, 11) 0.7353230567399147\n",
      "(0, 2016, 12) 0.5869137422105608\n",
      "(0, 2016, 13) 0.5703509347326993\n",
      "(0, 2016, 14) 0.5964250573958675\n",
      "(0, 2016, 15) 0.6530009839291571\n",
      "(0, 2016, 16) 0.8916038045260741\n",
      "(0, 2016, 17) 0.9763857002295835\n",
      "(0, 2016, 18) 0.7125286979337487\n",
      "(0, 2016, 19) 0.6220072154804854\n",
      "(0, 2016, 20) 0.6103640537881273\n",
      "(0, 2016, 21) 0.6082322072810757\n",
      "(0, 2016, 22) 0.7194162020334536\n",
      "(0, 2016, 23) 1.8291243030501805\n",
      "(0, 2016, 24) 2.0049196457855034\n",
      "(0, 2016, 25) 0.0\n",
      "(0, 2016, 26) 0.0\n",
      "(0, 2016, 27) 0.0\n",
      "(0, 2016, 28) 0.6403738930796983\n",
      "(0, 2016, 29) 0.6211872745162348\n",
      "(0, 2016, 30) 0.5475565759265333\n",
      "(0, 2016, 31) 1.3368317481141359\n",
      "(1, 2011, 1) 0.9735979009511315\n",
      "(1, 2011, 2) 0.8955395211544769\n",
      "(1, 2011, 3) 0.8770088553624139\n",
      "(1, 2011, 4) 0.6618563463430633\n",
      "(1, 2011, 5) 0.7053132174483437\n",
      "(1, 2011, 6) 0.6931780911774352\n",
      "(1, 2011, 7) 0.781403738930797\n",
      "(1, 2011, 8) 0.8135454247294195\n",
      "(1, 2011, 9) 0.8932436864545753\n",
      "(1, 2011, 10) 0.8604460478845524\n",
      "(1, 2011, 11) 0.6680878976713677\n",
      "(1, 2011, 12) 0.6416857986224992\n",
      "(1, 2011, 13) 0.7005575598556903\n",
      "(1, 2011, 14) 0.8292882912430305\n",
      "(1, 2011, 15) 0.8765168907838635\n",
      "(1, 2011, 16) 0.8276484093145293\n",
      "(1, 2011, 17) 0.8079698261725156\n",
      "(1, 2011, 18) 0.6003607740242702\n",
      "(1, 2011, 19) 0.6339783535585438\n",
      "(1, 2011, 20) 0.6505411610364054\n",
      "(1, 2011, 21) 0.7707445063955395\n",
      "(1, 2011, 22) 0.8132174483437192\n",
      "(1, 2011, 23) 0.9839291571006887\n",
      "(1, 2011, 24) 0.9294850770744506\n",
      "(1, 2011, 25) 0.6402099048868481\n",
      "(1, 2011, 26) 0.6051164316169236\n",
      "(1, 2011, 27) 0.607084289931125\n",
      "(1, 2011, 28) 0.6541489012791079\n",
      "(1, 2011, 29) 0.724171859626107\n",
      "(1, 2011, 30) 0.8097736962938669\n",
      "(1, 2011, 31) 0.7746802230239422\n",
      "(1, 2012, 1) 1.032633650377173\n",
      "(1, 2012, 2) 0.8155132830436208\n",
      "(1, 2012, 3) 0.8360118071498852\n",
      "(1, 2012, 4) 0.9137422105608396\n",
      "(1, 2012, 5) 0.9962282715644474\n",
      "(1, 2012, 6) 1.1318465070514923\n",
      "(1, 2012, 7) 1.1325024598228928\n",
      "(1, 2012, 8) 0.9898327320432929\n",
      "(1, 2012, 9) 0.8022302394227616\n",
      "(1, 2012, 10) 0.739914726139718\n",
      "(1, 2012, 11) 0.882748442112168\n",
      "(1, 2012, 12) 0.9939324368645458\n",
      "(1, 2012, 13) 0.9655624795014759\n",
      "(1, 2012, 14) 0.9968842243358478\n",
      "(1, 2012, 15) 0.9811413578222368\n",
      "(1, 2012, 16) 0.775828140373893\n",
      "(1, 2012, 17) 0.7095769104624468\n",
      "(1, 2012, 18) 0.8378156772712365\n",
      "(1, 2012, 19) 1.0265660872417186\n",
      "(1, 2012, 20) 1.0482125286979338\n",
      "(1, 2012, 21) 1.2751721876024926\n",
      "(1, 2012, 22) 1.1649721220072156\n",
      "(1, 2012, 23) 0.778615939652345\n",
      "(1, 2012, 24) 0.7500819940964251\n",
      "(1, 2012, 25) 0.6976057723843884\n",
      "(1, 2012, 26) 0.7466382420465727\n",
      "(1, 2012, 27) 0.8330600196785831\n",
      "(1, 2012, 28) 0.9817973105936373\n",
      "(1, 2012, 29) 0.9532633650377172\n",
      "(1, 2012, 30) 0.8494588389635946\n",
      "(1, 2012, 31) 1.2151525090193507\n",
      "(1, 2013, 1) 0.8961954739258773\n",
      "(1, 2013, 2) 0.8624139061987537\n",
      "(1, 2013, 3) 0.9809773696293866\n",
      "(1, 2013, 4) 1.1262709084945883\n",
      "(1, 2013, 5) 1.1134798294522794\n",
      "(1, 2013, 6) 1.1223351918661857\n",
      "(1, 2013, 7) 1.0988848802886193\n",
      "(1, 2013, 8) 0.8164972122007216\n",
      "(1, 2013, 9) 0.8245326336503772\n",
      "(1, 2013, 10) 0.8717612331912102\n",
      "(1, 2013, 11) 1.0524762217120367\n",
      "(1, 2013, 12) 1.0487044932764842\n",
      "(1, 2013, 13) 1.0441128238766808\n",
      "(1, 2013, 14) 1.0306657920629714\n",
      "(1, 2013, 15) 0.8535585437848475\n",
      "(1, 2013, 16) 0.831420137750082\n",
      "(1, 2013, 17) 0.8688094457199081\n",
      "(1, 2013, 18) 1.074122663168252\n",
      "(1, 2013, 19) 1.1202033453591342\n",
      "(1, 2013, 20) 1.3374877008855361\n",
      "(1, 2013, 21) 1.2531977697605772\n",
      "(1, 2013, 22) 0.8697933748770088\n",
      "(1, 2013, 23) 0.7281075762545097\n",
      "(1, 2013, 24) 0.7835355854378485\n",
      "(1, 2013, 25) 0.834371925221384\n",
      "(1, 2013, 26) 0.8632338471630042\n",
      "(1, 2013, 27) 1.0454247294194818\n",
      "(1, 2013, 28) 1.0275500163988194\n",
      "(1, 2013, 29) 0.9401443096097081\n",
      "(1, 2013, 30) 1.088717612331912\n",
      "(1, 2013, 31) 1.2289275172187601\n",
      "(1, 2014, 1) 0.8379796654640865\n",
      "(1, 2014, 2) 0.9804854050508364\n",
      "(1, 2014, 3) 1.082650049196458\n",
      "(1, 2014, 4) 1.118727451623483\n",
      "(1, 2014, 5) 1.0995408330600196\n",
      "(1, 2014, 6) 1.0349294850770745\n",
      "(1, 2014, 7) 0.794194817973106\n",
      "(1, 2014, 8) 0.7712364709740899\n",
      "(1, 2014, 9) 0.9117743522466383\n",
      "(1, 2014, 10) 1.0637914070186947\n",
      "(1, 2014, 11) 0.9562151525090193\n",
      "(1, 2014, 12) 1.0267300754345687\n",
      "(1, 2014, 13) 1.031485733027222\n",
      "(1, 2014, 14) 0.7735323056739914\n",
      "(1, 2014, 15) 0.825680551000328\n",
      "(1, 2014, 16) 0.8738930796982617\n",
      "(1, 2014, 17) 1.017382748442112\n",
      "(1, 2014, 18) 1.1490652673007544\n",
      "(1, 2014, 19) 1.355854378484749\n",
      "(1, 2014, 20) 1.1508691374221056\n",
      "(1, 2014, 21) 0.818629058707773\n",
      "(1, 2014, 22) 0.8258445391931781\n",
      "(1, 2014, 23) 0.7707445063955395\n",
      "(1, 2014, 24) 0.7981305346015087\n",
      "(1, 2014, 25) 0.8379796654640865\n",
      "(1, 2014, 26) 1.1054444080026238\n",
      "(1, 2014, 27) 1.097244998360118\n",
      "(1, 2014, 28) 0.8909478517546736\n",
      "(1, 2014, 29) 1.0488684814693343\n",
      "(1, 2014, 30) 1.0626434896687438\n",
      "(1, 2014, 31) 0.7484421121679239\n",
      "(1, 2015, 1) 0.8263365037717284\n",
      "(1, 2015, 2) 0.8812725483765169\n",
      "(1, 2015, 3) 0.9829452279435881\n",
      "(1, 2015, 4) 0.902755001639882\n",
      "(1, 2015, 5) 0.8502787799278452\n",
      "(1, 2015, 6) 0.7090849458838964\n",
      "(1, 2015, 7) 0.6569367005575598\n",
      "(1, 2015, 8) 0.7307313873401116\n",
      "(1, 2015, 9) 0.8207609052148246\n",
      "(1, 2015, 10) 0.8017382748442112\n",
      "(1, 2015, 11) 0.8934076746474254\n",
      "(1, 2015, 12) 0.784355526402099\n",
      "(1, 2015, 13) 0.6265988848802886\n",
      "(1, 2015, 14) 0.5792062971466054\n",
      "(1, 2015, 15) 0.7722204001311905\n",
      "(1, 2015, 16) 0.8858642177763201\n",
      "(1, 2015, 17) 0.8417513938996393\n",
      "(1, 2015, 18) 0.9563791407018695\n",
      "(1, 2015, 19) 1.0364053788127254\n",
      "(1, 2015, 20) 0.6556247950147589\n",
      "(1, 2015, 21) 0.6877664808133814\n",
      "(1, 2015, 22) 0.6674319448999672\n",
      "(1, 2015, 23) 0.6395539521154476\n",
      "(1, 2015, 24) 0.741554608068219\n",
      "(1, 2015, 25) 0.8588061659560512\n",
      "(1, 2015, 26) 0.8325680551000328\n",
      "(1, 2015, 27) 0.7618891439816333\n",
      "(1, 2015, 28) 0.8653656936700558\n",
      "(1, 2015, 29) 0.8494588389635946\n",
      "(1, 2015, 30) 0.6849786815349295\n",
      "(1, 2015, 31) 0.6674319448999672\n",
      "(1, 2016, 1) 0.7850114791734996\n",
      "(1, 2016, 2) 0.9918005903574942\n",
      "(1, 2016, 3) 1.0728107576254509\n",
      "(1, 2016, 4) 0.6511971138078059\n",
      "(1, 2016, 5) 0.5706789111183995\n",
      "(1, 2016, 6) 0.6118399475237782\n",
      "(1, 2016, 7) 0.6165956051164316\n",
      "(1, 2016, 8) 0.7292554936044605\n",
      "(1, 2016, 9) 1.0418169891767792\n",
      "(1, 2016, 10) 1.032633650377173\n",
      "(1, 2016, 11) 0.6380780583797967\n",
      "(1, 2016, 12) 0.622827156444736\n",
      "(1, 2016, 13) 0.581338143653657\n",
      "(1, 2016, 14) 0.564283371597245\n",
      "(1, 2016, 15) 0.7281075762545097\n",
      "(1, 2016, 16) 0.8776648081338143\n",
      "(1, 2016, 17) 0.9445719908166612\n",
      "(1, 2016, 18) 0.6280747786159396\n",
      "(1, 2016, 19) 0.5954411282387668\n",
      "(1, 2016, 20) 0.6052804198097737\n",
      "(1, 2016, 21) 0.5416530009839292\n",
      "(1, 2016, 22) 0.7308953755329616\n",
      "(1, 2016, 23) 1.929813053460151\n",
      "(1, 2016, 24) 1.9947523778287963\n",
      "(1, 2016, 25) 0.0\n",
      "(1, 2016, 26) 0.0\n",
      "(1, 2016, 27) 0.0\n",
      "(1, 2016, 28) 0.5977369629386684\n",
      "(1, 2016, 29) 0.6223351918661857\n",
      "(1, 2016, 30) 0.5721548048540505\n",
      "(1, 2016, 31) 1.1744834371925221\n",
      "(2, 2011, 1) 1.5034437520498525\n",
      "(2, 2011, 2) 1.5595277140045916\n",
      "(2, 2011, 3) 1.6446375860938012\n",
      "(2, 2011, 4) 1.4337487700885536\n",
      "(2, 2011, 5) 1.2376188914398163\n",
      "(2, 2011, 6) 1.2846835027877992\n",
      "(2, 2011, 7) 1.3950475565759266\n",
      "(2, 2011, 8) 1.334043948835684\n",
      "(2, 2011, 9) 1.5505083633978354\n",
      "(2, 2011, 10) 1.5941292226959658\n",
      "(2, 2011, 11) 1.2758281403738931\n",
      "(2, 2011, 12) 1.1744834371925221\n",
      "(2, 2011, 13) 1.2290915054116103\n",
      "(2, 2011, 14) 1.264348966874385\n",
      "(2, 2011, 15) 1.5070514922925549\n",
      "(2, 2011, 16) 1.3550344375204986\n",
      "(2, 2011, 17) 1.3309281731715317\n",
      "(2, 2011, 18) 1.1634962282715644\n",
      "(2, 2011, 19) 1.081502131846507\n",
      "(2, 2011, 20) 1.1244670383732371\n",
      "(2, 2011, 21) 1.248442112167924\n",
      "(2, 2011, 22) 1.3797966546408658\n",
      "(2, 2011, 23) 1.501147917349951\n",
      "(2, 2011, 24) 1.469990160708429\n",
      "(2, 2011, 25) 1.0941292226959658\n",
      "(2, 2011, 26) 1.031485733027222\n",
      "(2, 2011, 27) 1.004263693014103\n",
      "(2, 2011, 28) 1.0859298130534603\n",
      "(2, 2011, 29) 1.0278779927845194\n",
      "(2, 2011, 30) 1.2733683174811414\n",
      "(2, 2011, 31) 1.1938340439488357\n",
      "(2, 2012, 1) 2.048704493276484\n",
      "(2, 2012, 2) 1.851426697277796\n",
      "(2, 2012, 3) 1.930141029845851\n",
      "(2, 2012, 4) 1.7673007543456871\n",
      "(2, 2012, 5) 1.8966874385044277\n",
      "(2, 2012, 6) 2.089865529681863\n",
      "(2, 2012, 7) 2.379960642833716\n",
      "(2, 2012, 8) 2.161200393571663\n",
      "(2, 2012, 9) 1.9194817973105935\n",
      "(2, 2012, 10) 1.7948507707445065\n",
      "(2, 2012, 11) 1.7622171203673336\n",
      "(2, 2012, 12) 1.8427353230567398\n",
      "(2, 2012, 13) 1.7258117415546081\n",
      "(2, 2012, 14) 1.910134470318137\n",
      "(2, 2012, 15) 1.8242046572646768\n",
      "(2, 2012, 16) 1.618727451623483\n",
      "(2, 2012, 17) 1.5655952771400459\n",
      "(2, 2012, 18) 1.6664480157428665\n",
      "(2, 2012, 19) 1.7732043292882913\n",
      "(2, 2012, 20) 1.8917677927189243\n",
      "(2, 2012, 21) 2.02918989832732\n",
      "(2, 2012, 22) 2.219416202033454\n",
      "(2, 2012, 23) 1.6369301410298458\n",
      "(2, 2012, 24) 1.421449655624795\n",
      "(2, 2012, 25) 1.4408002623811085\n",
      "(2, 2012, 26) 1.5749426041325025\n",
      "(2, 2012, 27) 1.47146605444408\n",
      "(2, 2012, 28) 1.7304034109544113\n",
      "(2, 2012, 29) 1.754345687110528\n",
      "(2, 2012, 30) 1.705805182026894\n",
      "(2, 2012, 31) 2.103312561495572\n",
      "(2, 2013, 1) 1.9834371925221383\n",
      "(2, 2013, 2) 1.9752377828796326\n",
      "(2, 2013, 3) 2.043948835683831\n",
      "(2, 2013, 4) 1.982781239750738\n",
      "(2, 2013, 5) 2.224171859626107\n",
      "(2, 2013, 6) 2.2779599868809446\n",
      "(2, 2013, 7) 2.231551328304362\n",
      "(2, 2013, 8) 1.8573302722204001\n",
      "(2, 2013, 9) 1.9537553296162675\n",
      "(2, 2013, 10) 1.954247294194818\n",
      "(2, 2013, 11) 2.1679239094785174\n",
      "(2, 2013, 12) 2.01443096097081\n",
      "(2, 2013, 13) 2.2151525090193505\n",
      "(2, 2013, 14) 2.1508691374221054\n",
      "(2, 2013, 15) 1.8853722531977697\n",
      "(2, 2013, 16) 1.802722204001312\n",
      "(2, 2013, 17) 1.7823876680878976\n",
      "(2, 2013, 18) 1.9745818301082323\n",
      "(2, 2013, 19) 2.1710396851426697\n",
      "(2, 2013, 20) 2.2505739586749756\n",
      "(2, 2013, 21) 2.447687766480813\n",
      "(2, 2013, 22) 1.8734011151197114\n",
      "(2, 2013, 23) 1.7815677271236472\n",
      "(2, 2013, 24) 1.7258117415546081\n",
      "(2, 2013, 25) 1.6336503771728434\n",
      "(2, 2013, 26) 1.6492292554936046\n",
      "(2, 2013, 27) 1.8453591341423417\n",
      "(2, 2013, 28) 1.954411282387668\n",
      "(2, 2013, 29) 1.7425385372253197\n",
      "(2, 2013, 30) 2.0065595277140047\n",
      "(2, 2013, 31) 1.0993768448671695\n",
      "(2, 2014, 1) 2.1077402427025254\n",
      "(2, 2014, 2) 2.1393899639225977\n",
      "(2, 2014, 3) 2.367169563791407\n",
      "(2, 2014, 4) 2.347326992456543\n",
      "(2, 2014, 5) 2.4025910134470316\n",
      "(2, 2014, 6) 2.455723187930469\n",
      "(2, 2014, 7) 2.1966218432272875\n",
      "(2, 2014, 8) 2.2038373237126927\n",
      "(2, 2014, 9) 2.101344703181371\n",
      "(2, 2014, 10) 2.229911446375861\n",
      "(2, 2014, 11) 2.2566415218104297\n",
      "(2, 2014, 12) 2.295834699901607\n",
      "(2, 2014, 13) 2.3219088225647755\n",
      "(2, 2014, 14) 2.0378812725483764\n",
      "(2, 2014, 15) 1.9417841915382092\n",
      "(2, 2014, 16) 1.891439816333224\n",
      "(2, 2014, 17) 2.1003607740242702\n",
      "(2, 2014, 18) 2.2435224663824203\n",
      "(2, 2014, 19) 2.744506395539521\n",
      "(2, 2014, 20) 2.5149229255493606\n",
      "(2, 2014, 21) 1.9245654312889473\n",
      "(2, 2014, 22) 1.8110856018366677\n",
      "(2, 2014, 23) 1.9324368645457528\n",
      "(2, 2014, 24) 1.9693342079370286\n",
      "(2, 2014, 25) 1.734339127582814\n",
      "(2, 2014, 26) 1.9895047556575927\n",
      "(2, 2014, 27) 2.180551000327976\n",
      "(2, 2014, 28) 1.8876680878976713\n",
      "(2, 2014, 29) 1.9788455231223352\n",
      "(2, 2014, 30) 2.1523450311577568\n",
      "(2, 2014, 31) 1.8297802558215808\n",
      "(2, 2015, 1) 2.074450639553952\n",
      "(2, 2015, 2) 2.1877664808133814\n",
      "(2, 2015, 3) 2.378648737290915\n",
      "(2, 2015, 4) 2.558707773040341\n",
      "(2, 2015, 5) 2.268612659888488\n",
      "(2, 2015, 6) 1.9980321416857987\n",
      "(2, 2015, 7) 1.9153820924893408\n",
      "(2, 2015, 8) 2.007215480485405\n",
      "(2, 2015, 9) 2.178255165628075\n",
      "(2, 2015, 10) 2.0919973761889143\n",
      "(2, 2015, 11) 2.2048212528697935\n",
      "(2, 2015, 12) 2.2646769432600853\n",
      "(2, 2015, 13) 1.7636930141029845\n",
      "(2, 2015, 14) 1.768612659888488\n",
      "(2, 2015, 15) 1.8037061331584126\n",
      "(2, 2015, 16) 2.047064611347983\n",
      "(2, 2015, 17) 2.184650705149229\n",
      "(2, 2015, 18) 2.0249262053132173\n",
      "(2, 2015, 19) 2.554280091833388\n",
      "(2, 2015, 20) 1.902918989832732\n",
      "(2, 2015, 21) 1.7464742538537226\n",
      "(2, 2015, 22) 1.765496884224336\n",
      "(2, 2015, 23) 1.9263693014102985\n",
      "(2, 2015, 24) 1.774352246638242\n",
      "(2, 2015, 25) 2.0819940964250576\n",
      "(2, 2015, 26) 2.163004263693014\n",
      "(2, 2015, 27) 1.8407674647425385\n",
      "(2, 2015, 28) 2.003115775664152\n",
      "(2, 2015, 29) 2.058871761233191\n",
      "(2, 2015, 30) 1.7805837979665464\n",
      "(2, 2015, 31) 1.8383076418497868\n",
      "(2, 2016, 1) 1.0775664152181044\n",
      "(2, 2016, 2) 1.1816989176779271\n",
      "(2, 2016, 3) 1.377336831748114\n",
      "(2, 2016, 4) 1.0859298130534603\n",
      "(2, 2016, 5) 1.020170547720564\n",
      "(2, 2016, 6) 0.9322728763529026\n",
      "(2, 2016, 7) 0.9240734667103968\n",
      "(2, 2016, 8) 1.0152509019350606\n",
      "(2, 2016, 9) 1.2761561167595934\n",
      "(2, 2016, 10) 1.4106264348966875\n",
      "(2, 2016, 11) 1.0790423089537553\n",
      "(2, 2016, 12) 0.9250573958674976\n",
      "(2, 2016, 13) 0.8817645129550672\n",
      "(2, 2016, 14) 0.9007871433256806\n",
      "(2, 2016, 15) 0.8752049852410626\n",
      "(2, 2016, 16) 1.1374221056083962\n",
      "(2, 2016, 17) 1.3563463430632994\n",
      "(2, 2016, 18) 0.9950803542144966\n",
      "(2, 2016, 19) 0.9319448999672023\n",
      "(2, 2016, 20) 0.8584781895703509\n",
      "(2, 2016, 21) 0.822892751721876\n",
      "(2, 2016, 22) 0.9221056083961955\n",
      "(2, 2016, 23) 2.4332568055100032\n",
      "(2, 2016, 24) 2.5323056739914724\n",
      "(2, 2016, 25) 0.0\n",
      "(2, 2016, 26) 0.0\n",
      "(2, 2016, 27) 0.0\n",
      "(2, 2016, 28) 0.8998032141685799\n",
      "(2, 2016, 29) 0.9007871433256806\n",
      "(2, 2016, 30) 0.8530665792062971\n",
      "(2, 2016, 31) 1.7953427353230567\n",
      "(3, 2011, 1) 0.5823220728107577\n",
      "(3, 2011, 2) 0.531485733027222\n",
      "(3, 2011, 3) 0.5572318793046901\n",
      "(3, 2011, 4) 0.4790095113151853\n",
      "(3, 2011, 5) 0.45293538865201705\n",
      "(3, 2011, 6) 0.48048540505083637\n",
      "(3, 2011, 7) 0.47507379468678257\n",
      "(3, 2011, 8) 0.455723187930469\n",
      "(3, 2011, 9) 0.5368973433912758\n",
      "(3, 2011, 10) 0.5860938012463103\n",
      "(3, 2011, 11) 0.5198425713348639\n",
      "(3, 2011, 12) 0.4311249590029518\n",
      "(3, 2011, 13) 0.4655624795014759\n",
      "(3, 2011, 14) 0.4731059363725812\n",
      "(3, 2011, 15) 0.5324696621843227\n",
      "(3, 2011, 16) 0.4735979009511315\n",
      "(3, 2011, 17) 0.5108232207281076\n",
      "(3, 2011, 18) 0.4137422105608396\n",
      "(3, 2011, 19) 0.40619875368973435\n",
      "(3, 2011, 20) 0.4332568055100033\n",
      "(3, 2011, 21) 0.4476877664808134\n",
      "(3, 2011, 22) 0.5154148901279108\n",
      "(3, 2011, 23) 0.5946211872745162\n",
      "(3, 2011, 24) 0.47851754673663494\n",
      "(3, 2011, 25) 0.3732371269268613\n",
      "(3, 2011, 26) 0.36110200065595277\n",
      "(3, 2011, 27) 0.36930141029845853\n",
      "(3, 2011, 28) 0.40521482453263363\n",
      "(3, 2011, 29) 0.44604788455231226\n",
      "(3, 2011, 30) 0.46392259757297477\n",
      "(3, 2011, 31) 0.48573302722204004\n",
      "(3, 2012, 1) 0.7184322728763529\n",
      "(3, 2012, 2) 0.6188914398163332\n",
      "(3, 2012, 3) 0.6415218104296491\n",
      "(3, 2012, 4) 0.6554608068219088\n",
      "(3, 2012, 5) 0.6958019022630371\n",
      "(3, 2012, 6) 0.7707445063955395\n",
      "(3, 2012, 7) 0.7984585109872089\n",
      "(3, 2012, 8) 0.690062315513283\n",
      "(3, 2012, 9) 0.6477533617579534\n",
      "(3, 2012, 10) 0.5826500491964579\n",
      "(3, 2012, 11) 0.6264348966874385\n",
      "(3, 2012, 12) 0.6056083961954739\n",
      "(3, 2012, 13) 0.6031485733027222\n",
      "(3, 2012, 14) 0.6923581502131847\n",
      "(3, 2012, 15) 0.7082650049196458\n",
      "(3, 2012, 16) 0.6216792390947852\n",
      "(3, 2012, 17) 0.5577238438832404\n",
      "(3, 2012, 18) 0.6580846179075106\n",
      "(3, 2012, 19) 0.6392259757297475\n",
      "(3, 2012, 20) 0.7144965562479502\n",
      "(3, 2012, 21) 0.7326992456543129\n",
      "(3, 2012, 22) 0.7527058051820269\n",
      "(3, 2012, 23) 0.6179075106592326\n",
      "(3, 2012, 24) 0.6205313217448344\n",
      "(3, 2012, 25) 0.5513283043620859\n",
      "(3, 2012, 26) 0.5897015414890128\n",
      "(3, 2012, 27) 0.6029845851098721\n",
      "(3, 2012, 28) 0.6362741882584454\n",
      "(3, 2012, 29) 0.6254509675303378\n",
      "(3, 2012, 30) 0.6582486061003607\n",
      "(3, 2012, 31) 0.8809445719908167\n",
      "(3, 2013, 1) 0.6808789767136766\n",
      "(3, 2013, 2) 0.6595605116431617\n",
      "(3, 2013, 3) 0.7204001311905542\n",
      "(3, 2013, 4) 0.780091833387996\n",
      "(3, 2013, 5) 0.7797638570022958\n",
      "(3, 2013, 6) 0.7879632666448015\n",
      "(3, 2013, 7) 0.8212528697933749\n",
      "(3, 2013, 8) 0.7082650049196458\n",
      "(3, 2013, 9) 0.678583142013775\n",
      "(3, 2013, 10) 0.7402427025254181\n",
      "(3, 2013, 11) 0.7194162020334536\n",
      "(3, 2013, 12) 0.6897343391275829\n",
      "(3, 2013, 13) 0.7784519514594949\n",
      "(3, 2013, 14) 0.7477861593965235\n",
      "(3, 2013, 15) 0.7122007215480486\n",
      "(3, 2013, 16) 0.6497212200721548\n",
      "(3, 2013, 17) 0.7051492292554936\n",
      "(3, 2013, 18) 0.6987536897343392\n",
      "(3, 2013, 19) 0.8225647753361758\n",
      "(3, 2013, 20) 0.7641849786815349\n",
      "(3, 2013, 21) 0.9209576910462447\n",
      "(3, 2013, 22) 0.7418825844539193\n",
      "(3, 2013, 23) 0.6133158412594293\n",
      "(3, 2013, 24) 0.5962610692030174\n",
      "(3, 2013, 25) 0.6516890783863561\n",
      "(3, 2013, 26) 0.6423417513938996\n",
      "(3, 2013, 27) 0.6820268940636274\n",
      "(3, 2013, 28) 0.7381108560183667\n",
      "(3, 2013, 29) 0.7330272220400131\n",
      "(3, 2013, 30) 0.8320760905214825\n",
      "(3, 2013, 31) 0.7841915382092489\n",
      "(3, 2014, 1) 0.6948179731059364\n",
      "(3, 2014, 2) 0.732863233847163\n",
      "(3, 2014, 3) 0.7781239750737947\n",
      "(3, 2014, 4) 0.7963266644801574\n",
      "(3, 2014, 5) 0.8325680551000328\n",
      "(3, 2014, 6) 0.8274844211216792\n",
      "(3, 2014, 7) 0.7582814037389308\n",
      "(3, 2014, 8) 0.7367989504755658\n",
      "(3, 2014, 9) 0.7636930141029846\n",
      "(3, 2014, 10) 0.7823876680878977\n",
      "(3, 2014, 11) 0.8041980977369629\n",
      "(3, 2014, 12) 0.8830764184978681\n",
      "(3, 2014, 13) 0.8374877008855363\n",
      "(3, 2014, 14) 0.7366349622827156\n",
      "(3, 2014, 15) 0.722859954083306\n",
      "(3, 2014, 16) 0.7238438832404067\n",
      "(3, 2014, 17) 0.708592981305346\n",
      "(3, 2014, 18) 0.8440472285995408\n",
      "(3, 2014, 19) 0.9954083306001967\n",
      "(3, 2014, 20) 0.7746802230239422\n",
      "(3, 2014, 21) 0.730075434568711\n",
      "(3, 2014, 22) 0.7215480485405051\n",
      "(3, 2014, 23) 0.6703837323712692\n",
      "(3, 2014, 24) 0.7023614299770417\n",
      "(3, 2014, 25) 0.6864545752705805\n",
      "(3, 2014, 26) 0.7184322728763529\n",
      "(3, 2014, 27) 0.7646769432600853\n",
      "(3, 2014, 28) 0.7212200721548049\n",
      "(3, 2014, 29) 0.7502459822892752\n",
      "(3, 2014, 30) 0.7792718924237455\n",
      "(3, 2014, 31) 0.7005575598556903\n",
      "(3, 2015, 1) 0.7991144637586094\n",
      "(3, 2015, 2) 0.8488028861921941\n",
      "(3, 2015, 3) 0.8650377172843555\n",
      "(3, 2015, 4) 0.9829452279435881\n",
      "(3, 2015, 5) 0.8156772712364709\n",
      "(3, 2015, 6) 0.780091833387996\n",
      "(3, 2015, 7) 0.6944899967202361\n",
      "(3, 2015, 8) 0.7394227615611676\n",
      "(3, 2015, 9) 0.7894391603804526\n",
      "(3, 2015, 10) 0.7956707117087569\n",
      "(3, 2015, 11) 0.805673991472614\n",
      "(3, 2015, 12) 0.8197769760577238\n",
      "(3, 2015, 13) 0.751393899639226\n",
      "(3, 2015, 14) 0.697113807805838\n",
      "(3, 2015, 15) 0.7517218760249262\n",
      "(3, 2015, 16) 0.7904230895375532\n",
      "(3, 2015, 17) 0.8041980977369629\n",
      "(3, 2015, 18) 0.8189570350934733\n",
      "(3, 2015, 19) 0.8920957691046245\n",
      "(3, 2015, 20) 0.7445063955395211\n",
      "(3, 2015, 21) 0.7222040013119055\n",
      "(3, 2015, 22) 0.7336831748114135\n",
      "(3, 2015, 23) 0.7782879632666448\n",
      "(3, 2015, 24) 0.7021974417841915\n",
      "(3, 2015, 25) 0.765660872417186\n",
      "(3, 2015, 26) 0.8220728107576255\n",
      "(3, 2015, 27) 0.794194817973106\n",
      "(3, 2015, 28) 0.8058379796654641\n",
      "(3, 2015, 29) 0.8181370941292226\n",
      "(3, 2015, 30) 0.7755001639881929\n",
      "(3, 2015, 31) 0.7389307969826172\n",
      "(3, 2016, 1) 0.4232535257461463\n",
      "(3, 2016, 2) 0.49852410626434895\n",
      "(3, 2016, 3) 0.5149229255493605\n",
      "(3, 2016, 4) 0.45719908166612006\n",
      "(3, 2016, 5) 0.4316169235815021\n",
      "(3, 2016, 6) 0.3979993440472286\n",
      "(3, 2016, 7) 0.39504755657592655\n",
      "(3, 2016, 8) 0.3865201705477206\n",
      "(3, 2016, 9) 0.5024598228927517\n",
      "(3, 2016, 10) 0.5239422761561168\n",
      "(3, 2016, 11) 0.415710068875041\n",
      "(3, 2016, 12) 0.35651033125614956\n",
      "(3, 2016, 13) 0.36306985897015415\n",
      "(3, 2016, 14) 0.40964250573958677\n",
      "(3, 2016, 15) 0.4093145293538865\n",
      "(3, 2016, 16) 0.4655624795014759\n",
      "(3, 2016, 17) 0.49967202361429974\n",
      "(3, 2016, 18) 0.4606428337159725\n",
      "(3, 2016, 19) 0.4389963922597573\n",
      "(3, 2016, 20) 0.409970482125287\n",
      "(3, 2016, 21) 0.4030829780255822\n",
      "(3, 2016, 22) 0.43096097081010165\n",
      "(3, 2016, 23) 0.9688422433584782\n",
      "(3, 2016, 24) 1.0728107576254509\n",
      "(3, 2016, 25) 0.0\n",
      "(3, 2016, 26) 0.0\n",
      "(3, 2016, 27) 0.0\n",
      "(3, 2016, 28) 0.4009511315185307\n",
      "(3, 2016, 29) 0.3678255165628075\n",
      "(3, 2016, 30) 0.38078058379796653\n",
      "(3, 2016, 31) 0.8101016726795671\n",
      "(4, 2011, 1) 0.9430960970810102\n",
      "(4, 2011, 2) 0.7605772384388324\n",
      "(4, 2011, 3) 0.827156444735979\n",
      "(4, 2011, 4) 0.602820596917022\n",
      "(4, 2011, 5) 0.6849786815349295\n",
      "(4, 2011, 6) 0.8043620859298131\n",
      "(4, 2011, 7) 0.8192850114791735\n",
      "(4, 2011, 8) 0.741390619875369\n",
      "(4, 2011, 9) 0.8865201705477206\n",
      "(4, 2011, 10) 0.8584781895703509\n",
      "(4, 2011, 11) 0.697113807805838\n",
      "(4, 2011, 12) 0.6974417841915382\n",
      "(4, 2011, 13) 0.8045260741226632\n",
      "(4, 2011, 14) 0.7295834699901607\n",
      "(4, 2011, 15) 0.9081666120039357\n",
      "(4, 2011, 16) 0.7818957035093473\n",
      "(4, 2011, 17) 0.7597572974745819\n",
      "(4, 2011, 18) 0.6108560183666776\n",
      "(4, 2011, 19) 0.5769104624467039\n",
      "(4, 2011, 20) 0.6505411610364054\n",
      "(4, 2011, 21) 0.697113807805838\n",
      "(4, 2011, 22) 0.7520498524106264\n",
      "(4, 2011, 23) 0.755657592653329\n",
      "(4, 2011, 24) 0.8038701213512627\n",
      "(4, 2011, 25) 0.6008527386028206\n",
      "(4, 2011, 26) 0.5828140373893079\n",
      "(4, 2011, 27) 0.5421449655624795\n",
      "(4, 2011, 28) 0.5296818629058708\n",
      "(4, 2011, 29) 0.5826500491964579\n",
      "(4, 2011, 30) 0.7023614299770417\n",
      "(4, 2011, 31) 0.5847818957035094\n",
      "(4, 2012, 1) 1.1526730075434568\n",
      "(4, 2012, 2) 0.8294522794358806\n",
      "(4, 2012, 3) 1.0460806821908823\n",
      "(4, 2012, 4) 0.8870121351262709\n",
      "(4, 2012, 5) 1.1705477205641195\n",
      "(4, 2012, 6) 1.31420137750082\n",
      "(4, 2012, 7) 1.2620531321744834\n",
      "(4, 2012, 8) 1.1288947195801902\n",
      "(4, 2012, 9) 0.875696949819613\n",
      "(4, 2012, 10) 0.8279763857002296\n",
      "(4, 2012, 11) 0.9376844867169564\n",
      "(4, 2012, 12) 1.0631354542472942\n",
      "(4, 2012, 13) 1.1121679239094786\n",
      "(4, 2012, 14) 1.0514922925549361\n",
      "(4, 2012, 15) 1.1261069203017382\n",
      "(4, 2012, 16) 0.8542144965562479\n",
      "(4, 2012, 17) 0.8524106264348967\n",
      "(4, 2012, 18) 0.8365037717284356\n",
      "(4, 2012, 19) 0.9506395539521154\n",
      "(4, 2012, 20) 0.9878648737290915\n",
      "(4, 2012, 21) 1.0616595605116432\n",
      "(4, 2012, 22) 1.1807149885208266\n",
      "(4, 2012, 23) 0.9147261397179403\n",
      "(4, 2012, 24) 0.864217776320105\n",
      "(4, 2012, 25) 0.831420137750082\n",
      "(4, 2012, 26) 0.7968186290587078\n",
      "(4, 2012, 27) 0.7545096753033782\n",
      "(4, 2012, 28) 0.9337487700885536\n",
      "(4, 2012, 29) 0.9204657264676943\n",
      "(4, 2012, 30) 0.8576582486061004\n",
      "(4, 2012, 31) 0.9694981961298786\n",
      "(4, 2013, 1) 0.9694981961298786\n",
      "(4, 2013, 2) 0.7981305346015087\n",
      "(4, 2013, 3) 0.8263365037717284\n",
      "(4, 2013, 4) 1.0218104296490653\n",
      "(4, 2013, 5) 1.1139717940308298\n",
      "(4, 2013, 6) 1.078714332568055\n",
      "(4, 2013, 7) 1.1702197441784192\n",
      "(4, 2013, 8) 0.9250573958674976\n",
      "(4, 2013, 9) 0.921449655624795\n",
      "(4, 2013, 10) 0.8156772712364709\n",
      "(4, 2013, 11) 0.9955723187930469\n",
      "(4, 2013, 12) 1.0816661200393571\n",
      "(4, 2013, 13) 1.2038373237126927\n",
      "(4, 2013, 14) 1.0929813053460151\n",
      "(4, 2013, 15) 1.0897015414890128\n",
      "(4, 2013, 16) 0.921449655624795\n",
      "(4, 2013, 17) 0.9178419153820925\n",
      "(4, 2013, 18) 1.020006559527714\n",
      "(4, 2013, 19) 1.1172515578878321\n",
      "(4, 2013, 20) 1.1489012791079043\n",
      "(4, 2013, 21) 1.1590685470646114\n",
      "(4, 2013, 22) 0.8724171859626106\n",
      "(4, 2013, 23) 0.8540505083633978\n",
      "(4, 2013, 24) 0.8101016726795671\n",
      "(4, 2013, 25) 0.7732043292882912\n",
      "(4, 2013, 26) 0.8430632994424402\n",
      "(4, 2013, 27) 0.7641849786815349\n",
      "(4, 2013, 28) 1.0418169891767792\n",
      "(4, 2013, 29) 0.9345687110528041\n",
      "(4, 2013, 30) 1.0067235159068546\n",
      "(4, 2013, 31) 1.3082978025582157\n",
      "(4, 2014, 1) 1.0098392915710068\n",
      "(4, 2014, 2) 0.9048868481469334\n",
      "(4, 2014, 3) 1.1354542472941949\n",
      "(4, 2014, 4) 1.1334863889799935\n",
      "(4, 2014, 5) 1.1098720892095768\n",
      "(4, 2014, 6) 1.182846835027878\n",
      "(4, 2014, 7) 1.116923581502132\n",
      "(4, 2014, 8) 0.8310921613643818\n",
      "(4, 2014, 9) 0.9132502459822893\n",
      "(4, 2014, 10) 1.0536241390619876\n",
      "(4, 2014, 11) 1.1664480157428665\n",
      "(4, 2014, 12) 1.2053132174483436\n",
      "(4, 2014, 13) 1.2658248606100362\n",
      "(4, 2014, 14) 0.8906198753689735\n",
      "(4, 2014, 15) 0.9901607084289931\n",
      "(4, 2014, 16) 1.0283699573630698\n",
      "(4, 2014, 17) 1.0034437520498525\n",
      "(4, 2014, 18) 1.174319448999672\n",
      "(4, 2014, 19) 1.308625778943916\n",
      "(4, 2014, 20) 1.4250573958674975\n",
      "(4, 2014, 21) 0.911446375860938\n",
      "(4, 2014, 22) 0.9242374549032469\n",
      "(4, 2014, 23) 0.8576582486061004\n",
      "(4, 2014, 24) 0.8868481469334208\n",
      "(4, 2014, 25) 0.8719252213840604\n",
      "(4, 2014, 26) 0.9598228927517218\n",
      "(4, 2014, 27) 1.0696949819612989\n",
      "(4, 2014, 28) 0.8863561823548705\n",
      "(4, 2014, 29) 0.9594949163660217\n",
      "(4, 2014, 30) 1.0346015086913742\n",
      "(4, 2014, 31) 0.9124303050180387\n",
      "(4, 2015, 1) 1.0588717612331913\n",
      "(4, 2015, 2) 1.110036077402427\n",
      "(4, 2015, 3) 1.3160052476221713\n",
      "(4, 2015, 4) 1.1246310265660873\n",
      "(4, 2015, 5) 1.2184322728763528\n",
      "(4, 2015, 6) 0.9945883896359462\n",
      "(4, 2015, 7) 0.9726139717940309\n",
      "(4, 2015, 8) 0.9121023286323384\n",
      "(4, 2015, 9) 1.1510331256149557\n",
      "(4, 2015, 10) 1.080026238110856\n",
      "(4, 2015, 11) 1.1805510003279764\n",
      "(4, 2015, 12) 1.1382420465726468\n",
      "(4, 2015, 13) 1.060183666775992\n",
      "(4, 2015, 14) 0.8883240406690718\n",
      "(4, 2015, 15) 1.0431288947195803\n",
      "(4, 2015, 16) 1.101344703181371\n",
      "(4, 2015, 17) 1.0801902263037062\n",
      "(4, 2015, 18) 1.2459822892751722\n",
      "(4, 2015, 19) 1.269924565431289\n",
      "(4, 2015, 20) 0.9839291571006887\n",
      "(4, 2015, 21) 0.8215808461790751\n",
      "(4, 2015, 22) 0.8527386028205969\n",
      "(4, 2015, 23) 0.9155460806821909\n",
      "(4, 2015, 24) 0.8861921941620203\n",
      "(4, 2015, 25) 0.9603148573302722\n",
      "(4, 2015, 26) 1.0323056739914727\n",
      "(4, 2015, 27) 0.8776648081338143\n",
      "(4, 2015, 28) 0.9739258773368318\n",
      "(4, 2015, 29) 1.034273532305674\n",
      "(4, 2015, 30) 0.8520826500491965\n",
      "(4, 2015, 31) 0.8861921941620203\n",
      "(4, 2016, 1) 0.555755985569039\n",
      "(4, 2016, 2) 0.6589045588717612\n",
      "(4, 2016, 3) 0.7010495244342407\n",
      "(4, 2016, 4) 0.49721220072154804\n",
      "(4, 2016, 5) 0.527222040013119\n",
      "(4, 2016, 6) 0.5249262053132174\n",
      "(4, 2016, 7) 0.5083633978353559\n",
      "(4, 2016, 8) 0.541325024598229\n",
      "(4, 2016, 9) 0.667103968514267\n",
      "(4, 2016, 10) 0.6802230239422762\n",
      "(4, 2016, 11) 0.5195145949491636\n",
      "(4, 2016, 12) 0.4967202361429977\n",
      "(4, 2016, 13) 0.4676943260085274\n",
      "(4, 2016, 14) 0.47950147589373565\n",
      "(4, 2016, 15) 0.505739586749754\n",
      "(4, 2016, 16) 0.6106920301738274\n",
      "(4, 2016, 17) 0.6874385044276812\n",
      "(4, 2016, 18) 0.5591997376188914\n",
      "(4, 2016, 19) 0.5341095441128239\n",
      "(4, 2016, 20) 0.475729747458183\n",
      "(4, 2016, 21) 0.4552312233519187\n",
      "(4, 2016, 22) 0.4955723187930469\n",
      "(4, 2016, 23) 1.2135126270908494\n",
      "(4, 2016, 24) 1.322728763529026\n",
      "(4, 2016, 25) 0.0\n",
      "(4, 2016, 26) 0.0\n",
      "(4, 2016, 27) 0.0\n",
      "(4, 2016, 28) 0.4962282715644474\n",
      "(4, 2016, 29) 0.40980649393243684\n",
      "(4, 2016, 30) 0.4593309281731715\n",
      "(4, 2016, 31) 0.8629058707773041\n",
      "(5, 2011, 1) 1.1316825188586421\n",
      "(5, 2011, 2) 0.9734339127582814\n",
      "(5, 2011, 3) 1.055591997376189\n",
      "(5, 2011, 4) 0.8074778615939653\n",
      "(5, 2011, 5) 0.8297802558215809\n",
      "(5, 2011, 6) 0.9168579862249918\n",
      "(5, 2011, 7) 1.0347654968842244\n",
      "(5, 2011, 8) 0.888652017054772\n",
      "(5, 2011, 9) 1.1018366677599214\n",
      "(5, 2011, 10) 1.0588717612331913\n",
      "(5, 2011, 11) 0.9034109544112824\n",
      "(5, 2011, 12) 0.8955395211544769\n",
      "(5, 2011, 13) 0.9632666448015743\n",
      "(5, 2011, 14) 1.0095113151853066\n",
      "(5, 2011, 15) 1.164316169235815\n",
      "(5, 2011, 16) 0.9940964250573958\n",
      "(5, 2011, 17) 0.9936044604788455\n",
      "(5, 2011, 18) 0.8712692686126599\n",
      "(5, 2011, 19) 0.7633650377172844\n",
      "(5, 2011, 20) 0.7956707117087569\n",
      "(5, 2011, 21) 0.8835683830764185\n",
      "(5, 2011, 22) 1.0603476549688422\n",
      "(5, 2011, 23) 1.2017054772056412\n",
      "(5, 2011, 24) 1.0846179075106592\n",
      "(5, 2011, 25) 0.8435552640209905\n",
      "(5, 2011, 26) 0.6812069530993768\n",
      "(5, 2011, 27) 0.6926861265988848\n",
      "(5, 2011, 28) 0.7974745818301082\n",
      "(5, 2011, 29) 0.8265004919645785\n",
      "(5, 2011, 30) 0.8904558871761233\n",
      "(5, 2011, 31) 0.7940308297802559\n",
      "(5, 2012, 1) 1.5150869137422105\n",
      "(5, 2012, 2) 1.1284027550016398\n",
      "(5, 2012, 3) 1.311577566415218\n",
      "(5, 2012, 4) 1.192850114791735\n",
      "(5, 2012, 5) 1.4317809117743523\n",
      "(5, 2012, 6) 1.717120367333552\n",
      "(5, 2012, 7) 1.6741554608068219\n",
      "(5, 2012, 8) 1.3666775992128566\n",
      "(5, 2012, 9) 1.2953427353230567\n",
      "(5, 2012, 10) 1.1566087241718597\n",
      "(5, 2012, 11) 1.2366349622827157\n",
      "(5, 2012, 12) 1.3838963594621188\n",
      "(5, 2012, 13) 1.467366349622827\n",
      "(5, 2012, 14) 1.4788455231223352\n",
      "(5, 2012, 15) 1.5606756313545425\n",
      "(5, 2012, 16) 1.1075762545096752\n",
      "(5, 2012, 17) 1.080026238110856\n",
      "(5, 2012, 18) 1.1731715316497213\n",
      "(5, 2012, 19) 1.305510003279764\n",
      "(5, 2012, 20) 1.3802886192194161\n",
      "(5, 2012, 21) 1.5549360446047884\n",
      "(5, 2012, 22) 1.5418169891767792\n",
      "(5, 2012, 23) 1.0990488684814694\n",
      "(5, 2012, 24) 0.9717940308297802\n",
      "(5, 2012, 25) 0.9655624795014759\n",
      "(5, 2012, 26) 1.0990488684814694\n",
      "(5, 2012, 27) 1.1395539521154476\n",
      "(5, 2012, 28) 1.2074450639553953\n",
      "(5, 2012, 29) 1.3028861921941621\n",
      "(5, 2012, 30) 1.1764512955067234\n",
      "(5, 2012, 31) 1.594293210888816\n",
      "(5, 2013, 1) 1.2850114791734994\n",
      "(5, 2013, 2) 1.138570022958347\n",
      "(5, 2013, 3) 1.2994424401443097\n",
      "(5, 2013, 4) 1.2709084945883897\n",
      "(5, 2013, 5) 1.561495572318793\n",
      "(5, 2013, 6) 1.5396851426697278\n",
      "(5, 2013, 7) 1.570186946539849\n",
      "(5, 2013, 8) 1.2820596917021974\n",
      "(5, 2013, 9) 1.321252869793375\n",
      "(5, 2013, 10) 1.1454575270580518\n",
      "(5, 2013, 11) 1.517382748442112\n",
      "(5, 2013, 12) 1.4175139389963922\n",
      "(5, 2013, 13) 1.5654312889471957\n",
      "(5, 2013, 14) 1.5095113151853066\n",
      "(5, 2013, 15) 1.338471630042637\n",
      "(5, 2013, 16) 1.177107248278124\n",
      "(5, 2013, 17) 1.2231879304690063\n",
      "(5, 2013, 18) 1.4219416202033455\n",
      "(5, 2013, 19) 1.5652673007543456\n",
      "(5, 2013, 20) 1.6746474253853723\n",
      "(5, 2013, 21) 1.6238110856018366\n",
      "(5, 2013, 22) 1.1607084289931124\n",
      "(5, 2013, 23) 1.115775664152181\n",
      "(5, 2013, 24) 0.9967202361429977\n",
      "(5, 2013, 25) 1.1297146605444408\n",
      "(5, 2013, 26) 1.248606100360774\n",
      "(5, 2013, 27) 1.1607084289931124\n",
      "(5, 2013, 28) 1.3878320760905214\n",
      "(5, 2013, 29) 1.2474581830108231\n",
      "(5, 2013, 30) 1.3624139061987537\n",
      "(5, 2013, 31) 1.602820596917022\n",
      "(5, 2014, 1) 1.084453919317809\n",
      "(5, 2014, 2) 1.058543784847491\n",
      "(5, 2014, 3) 1.258609380124631\n",
      "(5, 2014, 4) 1.340275500163988\n",
      "(5, 2014, 5) 1.3292882912430306\n",
      "(5, 2014, 6) 1.3837323712692686\n",
      "(5, 2014, 7) 1.1648081338143654\n",
      "(5, 2014, 8) 1.0383732371269268\n",
      "(5, 2014, 9) 1.121515250901935\n",
      "(5, 2014, 10) 1.2474581830108231\n",
      "(5, 2014, 11) 1.3419153820924894\n",
      "(5, 2014, 12) 1.324532633650377\n",
      "(5, 2014, 13) 1.3853722531977697\n",
      "(5, 2014, 14) 1.0452607412266317\n",
      "(5, 2014, 15) 1.159724499836012\n",
      "(5, 2014, 16) 1.0780583797966545\n",
      "(5, 2014, 17) 1.1589045588717612\n",
      "(5, 2014, 18) 1.4811413578222368\n",
      "(5, 2014, 19) 1.612987864873729\n",
      "(5, 2014, 20) 1.5306657920629714\n",
      "(5, 2014, 21) 1.0659232535257461\n",
      "(5, 2014, 22) 1.1279107904230896\n",
      "(5, 2014, 23) 1.077074450639554\n",
      "(5, 2014, 24) 1.1024926205313217\n",
      "(5, 2014, 25) 1.0993768448671695\n",
      "(5, 2014, 26) 0.9130862577894392\n",
      "(5, 2014, 27) 1.405542800918334\n",
      "(5, 2014, 28) 1.091177435224664\n",
      "(5, 2014, 29) 1.14283371597245\n",
      "(5, 2014, 30) 1.2136766152836995\n",
      "(5, 2014, 31) 1.0737946867825516\n",
      "(5, 2015, 1) 1.268612659888488\n",
      "(5, 2015, 2) 1.3053460150869138\n",
      "(5, 2015, 3) 1.501147917349951\n",
      "(5, 2015, 4) 1.364381764512955\n",
      "(5, 2015, 5) 1.2735323056739916\n",
      "(5, 2015, 6) 1.1653000983929158\n",
      "(5, 2015, 7) 1.1707117087569694\n",
      "(5, 2015, 8) 1.1589045588717612\n",
      "(5, 2015, 9) 1.3366677599212857\n",
      "(5, 2015, 10) 1.177271236470974\n",
      "(5, 2015, 11) 1.4065267300754345\n",
      "(5, 2015, 12) 1.3289603148573303\n",
      "(5, 2015, 13) 1.2292554936044604\n",
      "(5, 2015, 14) 1.060183666775992\n",
      "(5, 2015, 15) 1.2235159068547066\n",
      "(5, 2015, 16) 1.2459822892751722\n",
      "(5, 2015, 17) 1.254181698917678\n",
      "(5, 2015, 18) 1.561495572318793\n",
      "(5, 2015, 19) 1.5018038701213512\n",
      "(5, 2015, 20) 1.1338143653656936\n",
      "(5, 2015, 21) 1.0239422761561168\n",
      "(5, 2015, 22) 1.0311577566415218\n",
      "(5, 2015, 23) 1.0969170219744178\n",
      "(5, 2015, 24) 0.604296490652673\n",
      "(5, 2015, 25) 1.6971138078058379\n",
      "(5, 2015, 26) 1.2151525090193507\n",
      "(5, 2015, 27) 1.1034765496884225\n",
      "(5, 2015, 28) 1.2044932764840932\n",
      "(5, 2015, 29) 1.2336831748114137\n",
      "(5, 2015, 30) 1.0411610364053787\n",
      "(5, 2015, 31) 1.0534601508691375\n",
      "(5, 2016, 1) 0.6744834371925221\n",
      "(5, 2016, 2) 0.7846835027877993\n",
      "(5, 2016, 3) 0.8478189570350935\n",
      "(5, 2016, 4) 0.6216792390947852\n",
      "(5, 2016, 5) 0.6102000655952772\n",
      "(5, 2016, 6) 0.5519842571334864\n",
      "(5, 2016, 7) 0.6223351918661857\n",
      "(5, 2016, 8) 0.6146277468022302\n",
      "(5, 2016, 9) 0.7904230895375532\n",
      "(5, 2016, 10) 0.825680551000328\n",
      "(5, 2016, 11) 0.661364381764513\n",
      "(5, 2016, 12) 0.5713348638897999\n",
      "(5, 2016, 13) 0.5490324696621843\n",
      "(5, 2016, 14) 0.6315185306657921\n",
      "(5, 2016, 15) 0.6390619875368974\n",
      "(5, 2016, 16) 0.7338471630042637\n",
      "(5, 2016, 17) 0.8196129878648737\n",
      "(5, 2016, 18) 0.5429649065267301\n",
      "(5, 2016, 19) 0.6111839947523778\n",
      "(5, 2016, 20) 0.5549360446047884\n",
      "(5, 2016, 21) 0.5651033125614956\n",
      "(5, 2016, 22) 0.6398819285011479\n",
      "(5, 2016, 23) 1.4703181370941292\n",
      "(5, 2016, 24) 1.4076746474253854\n",
      "(5, 2016, 25) 0.0\n",
      "(5, 2016, 26) 0.0\n",
      "(5, 2016, 27) 0.0\n",
      "(5, 2016, 28) 0.6133158412594293\n",
      "(5, 2016, 29) 0.47540177107248277\n",
      "(5, 2016, 30) 0.5144309609708101\n",
      "(5, 2016, 31) 1.1003607740242702\n",
      "(6, 2011, 1) 0.8173171531649721\n",
      "(6, 2011, 2) 0.7682846835027878\n",
      "(6, 2011, 3) 0.8722531977697606\n",
      "(6, 2011, 4) 0.6262709084945884\n",
      "(6, 2011, 5) 0.6359462118727451\n",
      "(6, 2011, 6) 0.6751393899639226\n",
      "(6, 2011, 7) 0.7802558215808462\n",
      "(6, 2011, 8) 0.7046572646769432\n",
      "(6, 2011, 9) 0.8037061331584126\n",
      "(6, 2011, 10) 0.7345031157756642\n",
      "(6, 2011, 11) 0.7461462774680223\n",
      "(6, 2011, 12) 0.7044932764840931\n",
      "(6, 2011, 13) 0.7630370613315841\n",
      "(6, 2011, 14) 0.7208920957691046\n",
      "(6, 2011, 15) 0.8770088553624139\n",
      "(6, 2011, 16) 0.8009183338799607\n",
      "(6, 2011, 17) 0.7764840931452935\n",
      "(6, 2011, 18) 0.6505411610364054\n",
      "(6, 2011, 19) 0.5969170219744179\n",
      "(6, 2011, 20) 0.6403738930796983\n",
      "(6, 2011, 21) 0.7094129222695966\n",
      "(6, 2011, 22) 0.8212528697933749\n",
      "(6, 2011, 23) 0.9396523450311578\n",
      "(6, 2011, 24) 0.7015414890127911\n",
      "(6, 2011, 25) 0.6346343063299442\n",
      "(6, 2011, 26) 0.5513283043620859\n",
      "(6, 2011, 27) 0.5260741226631682\n",
      "(6, 2011, 28) 0.6080682190882256\n",
      "(6, 2011, 29) 0.5849458838963595\n",
      "(6, 2011, 30) 0.6413578222367989\n",
      "(6, 2011, 31) 0.6205313217448344\n",
      "(6, 2012, 1) 1.1046244670383731\n",
      "(6, 2012, 2) 0.8607740242702525\n",
      "(6, 2012, 3) 0.9622827156444737\n",
      "(6, 2012, 4) 0.8840603476549689\n",
      "(6, 2012, 5) 1.0652673007543456\n",
      "(6, 2012, 6) 1.1280747786159397\n",
      "(6, 2012, 7) 1.2307313873401116\n",
      "(6, 2012, 8) 0.929977041653001\n",
      "(6, 2012, 9) 0.898491308625779\n",
      "(6, 2012, 10) 0.7789439160380452\n",
      "(6, 2012, 11) 0.8829124303050181\n",
      "(6, 2012, 12) 1.0408330600196787\n",
      "(6, 2012, 13) 1.017054772056412\n",
      "(6, 2012, 14) 0.9970482125286979\n",
      "(6, 2012, 15) 1.107248278123975\n",
      "(6, 2012, 16) 0.8225647753361758\n",
      "(6, 2012, 17) 0.8374877008855363\n",
      "(6, 2012, 18) 0.8255165628074779\n",
      "(6, 2012, 19) 0.8978353558543785\n",
      "(6, 2012, 20) 0.9770416530009839\n",
      "(6, 2012, 21) 0.9560511643161692\n",
      "(6, 2012, 22) 1.1016726795670713\n",
      "(6, 2012, 23) 0.8983273204329288\n",
      "(6, 2012, 24) 0.6982617251557888\n",
      "(6, 2012, 25) 0.7851754673663496\n",
      "(6, 2012, 26) 0.7979665464086586\n",
      "(6, 2012, 27) 0.8069858970154149\n",
      "(6, 2012, 28) 0.8320760905214825\n",
      "(6, 2012, 29) 0.8989832732043292\n",
      "(6, 2012, 30) 0.8568383076418498\n",
      "(6, 2012, 31) 1.0495244342407346\n",
      "(6, 2013, 1) 1.015742866513611\n",
      "(6, 2013, 2) 0.8647097408986553\n",
      "(6, 2013, 3) 0.9427681206953099\n",
      "(6, 2013, 4) 0.9419481797310594\n",
      "(6, 2013, 5) 1.0673991472613973\n",
      "(6, 2013, 6) 1.1079042308953755\n",
      "(6, 2013, 7) 1.1067563135454248\n",
      "(6, 2013, 8) 0.9430960970810102\n",
      "(6, 2013, 9) 0.9547392587733683\n",
      "(6, 2013, 10) 0.8120695309937684\n",
      "(6, 2013, 11) 1.066907182682847\n",
      "(6, 2013, 12) 1.0088553624139063\n",
      "(6, 2013, 13) 1.104132502459823\n",
      "(6, 2013, 14) 1.0688750409970482\n",
      "(6, 2013, 15) 1.021318465070515\n",
      "(6, 2013, 16) 0.9340767464742539\n",
      "(6, 2013, 17) 0.8973433912758282\n",
      "(6, 2013, 18) 0.9931124959002952\n",
      "(6, 2013, 19) 1.0851098720892096\n",
      "(6, 2013, 20) 1.0747786159396524\n",
      "(6, 2013, 21) 1.0006559527714005\n",
      "(6, 2013, 22) 0.8973433912758282\n",
      "(6, 2013, 23) 0.8087897671367662\n",
      "(6, 2013, 24) 0.8156772712364709\n",
      "(6, 2013, 25) 0.8081338143653657\n",
      "(6, 2013, 26) 0.8417513938996393\n",
      "(6, 2013, 27) 0.8320760905214825\n",
      "(6, 2013, 28) 0.9206297146605444\n",
      "(6, 2013, 29) 0.9652345031157756\n",
      "(6, 2013, 30) 1.0951131518530666\n",
      "(6, 2013, 31) 0.991472613971794\n",
      "(6, 2014, 1) 1.1561167595933093\n",
      "(6, 2014, 2) 1.0375532961626763\n",
      "(6, 2014, 3) 1.3073138734011152\n",
      "(6, 2014, 4) 1.2207281075762546\n",
      "(6, 2014, 5) 1.25713348638898\n",
      "(6, 2014, 6) 1.2464742538537226\n",
      "(6, 2014, 7) 1.082650049196458\n",
      "(6, 2014, 8) 0.9396523450311578\n",
      "(6, 2014, 9) 1.0767464742538537\n",
      "(6, 2014, 10) 1.164152181042965\n",
      "(6, 2014, 11) 1.2081010167267956\n",
      "(6, 2014, 12) 1.2897671367661527\n",
      "(6, 2014, 13) 1.2645129550672352\n",
      "(6, 2014, 14) 1.0052476221712037\n",
      "(6, 2014, 15) 1.2354870449327648\n",
      "(6, 2014, 16) 1.1033125614955723\n",
      "(6, 2014, 17) 1.1369301410298458\n",
      "(6, 2014, 18) 1.2894391603804527\n",
      "(6, 2014, 19) 1.4178419153820925\n",
      "(6, 2014, 20) 1.161364381764513\n",
      "(6, 2014, 21) 1.0705149229255493\n",
      "(6, 2014, 22) 0.9606428337159725\n",
      "(6, 2014, 23) 0.9944244014430961\n",
      "(6, 2014, 24) 1.0236142997704165\n",
      "(6, 2014, 25) 1.0232863233847163\n",
      "(6, 2014, 26) 1.0867497540177107\n",
      "(6, 2014, 27) 1.10003279763857\n",
      "(6, 2014, 28) 1.0396851426697278\n",
      "(6, 2014, 29) 1.0934732699245655\n",
      "(6, 2014, 30) 1.0788783207609052\n",
      "(6, 2014, 31) 1.131518530665792\n",
      "(6, 2015, 1) 1.4350606756313546\n",
      "(6, 2015, 2) 1.2648409314529354\n",
      "(6, 2015, 3) 1.5619875368973435\n",
      "(6, 2015, 4) 1.3804526074122663\n",
      "(6, 2015, 5) 1.2064611347982945\n",
      "(6, 2015, 6) 1.2546736634962283\n",
      "(6, 2015, 7) 1.3130534601508692\n",
      "(6, 2015, 8) 1.1316825188586421\n",
      "(6, 2015, 9) 1.4147261397179403\n",
      "(6, 2015, 10) 1.265496884224336\n",
      "(6, 2015, 11) 1.3906198753689734\n",
      "(6, 2015, 12) 1.4580190226303706\n",
      "(6, 2015, 13) 1.3235487044932766\n",
      "(6, 2015, 14) 1.1180714988520826\n",
      "(6, 2015, 15) 1.2336831748114137\n",
      "(6, 2015, 16) 1.305510003279764\n",
      "(6, 2015, 17) 1.308789767136766\n",
      "(6, 2015, 18) 1.47130206625123\n",
      "(6, 2015, 19) 1.3525746146277469\n",
      "(6, 2015, 20) 1.2354870449327648\n",
      "(6, 2015, 21) 1.0665792062971466\n",
      "(6, 2015, 22) 1.0436208592981306\n",
      "(6, 2015, 23) 1.020006559527714\n",
      "(6, 2015, 24) 1.105772384388324\n",
      "(6, 2015, 25) 1.1980977369629386\n",
      "(6, 2015, 26) 1.1757953427353232\n",
      "(6, 2015, 27) 1.1251229911446377\n",
      "(6, 2015, 28) 1.1767792718924237\n",
      "(6, 2015, 29) 1.187274516234831\n",
      "(6, 2015, 30) 1.1498852082650048\n",
      "(6, 2015, 31) 1.0895375532961626\n",
      "(6, 2016, 1) 0.7133486388979994\n",
      "(6, 2016, 2) 0.7038373237126927\n",
      "(6, 2016, 3) 0.7553296162676287\n",
      "(6, 2016, 4) 0.6024926205313218\n",
      "(6, 2016, 5) 0.5788783207609052\n",
      "(6, 2016, 6) 0.6183994752377828\n",
      "(6, 2016, 7) 0.6075762545096753\n",
      "(6, 2016, 8) 0.6095441128238767\n",
      "(6, 2016, 9) 0.7333551984257134\n",
      "(6, 2016, 10) 0.760085273860282\n",
      "(6, 2016, 11) 0.651525090193506\n",
      "(6, 2016, 12) 0.6403738930796983\n",
      "(6, 2016, 13) 0.5729747458183011\n",
      "(6, 2016, 14) 0.5767464742538537\n",
      "(6, 2016, 15) 0.6262709084945884\n",
      "(6, 2016, 16) 0.6987536897343392\n",
      "(6, 2016, 17) 0.7410626434896688\n",
      "(6, 2016, 18) 0.5160708428993113\n",
      "(6, 2016, 19) 0.6457855034437521\n",
      "(6, 2016, 20) 0.5436208592981305\n",
      "(6, 2016, 21) 0.554280091833388\n",
      "(6, 2016, 22) 0.6052804198097737\n",
      "(6, 2016, 23) 1.3391275828140374\n",
      "(6, 2016, 24) 1.2978025582158084\n",
      "(6, 2016, 25) 0.0\n",
      "(6, 2016, 26) 0.0\n",
      "(6, 2016, 27) 0.0\n",
      "(6, 2016, 28) 0.5800262381108561\n",
      "(6, 2016, 29) 0.47950147589373565\n",
      "(6, 2016, 30) 0.4739258773368317\n",
      "(6, 2016, 31) 1.0888816005247621\n",
      "(7, 2011, 1) 0.6031485733027222\n",
      "(7, 2011, 2) 0.6193834043948836\n",
      "(7, 2011, 3) 0.5537881272548376\n",
      "(7, 2011, 4) 0.4337487700885536\n",
      "(7, 2011, 5) 0.4734339127582814\n",
      "(7, 2011, 6) 0.4667103968514267\n",
      "(7, 2011, 7) 0.5331256149557232\n",
      "(7, 2011, 8) 0.4734339127582814\n",
      "(7, 2011, 9) 0.5498524106264349\n",
      "(7, 2011, 10) 0.49180059035749424\n",
      "(7, 2011, 11) 0.45080354214496554\n",
      "(7, 2011, 12) 0.4722859954083306\n",
      "(7, 2011, 13) 0.5216464414562152\n",
      "(7, 2011, 14) 0.5511643161692358\n",
      "(7, 2011, 15) 0.5575598556903902\n",
      "(7, 2011, 16) 0.5618235487044932\n",
      "(7, 2011, 17) 0.49524434240734666\n",
      "(7, 2011, 18) 0.42735323056739916\n",
      "(7, 2011, 19) 0.39176779271892426\n",
      "(7, 2011, 20) 0.4722859954083306\n",
      "(7, 2011, 21) 0.5608396195473926\n",
      "(7, 2011, 22) 0.5073794686782551\n",
      "(7, 2011, 23) 0.6126598884880289\n",
      "(7, 2011, 24) 0.3184650705149229\n",
      "(7, 2011, 25) 0.4247294194817973\n",
      "(7, 2011, 26) 0.39455559199737616\n",
      "(7, 2011, 27) 0.3689734339127583\n",
      "(7, 2011, 28) 0.4403082978025582\n",
      "(7, 2011, 29) 0.5077074450639554\n",
      "(7, 2011, 30) 0.5997048212528698\n",
      "(7, 2011, 31) 0.5264020990488685\n",
      "(7, 2012, 1) 0.6118399475237782\n",
      "(7, 2012, 2) 0.5350934732699245\n",
      "(7, 2012, 3) 0.5878976713676616\n",
      "(7, 2012, 4) 0.6036405378812726\n",
      "(7, 2012, 5) 0.6649721220072154\n",
      "(7, 2012, 6) 0.6794030829780255\n",
      "(7, 2012, 7) 0.7161364381764513\n",
      "(7, 2012, 8) 0.5019678583142014\n",
      "(7, 2012, 9) 0.5072154804854051\n",
      "(7, 2012, 10) 0.5280419809773697\n",
      "(7, 2012, 11) 0.5683830764184978\n",
      "(7, 2012, 12) 0.6705477205641194\n",
      "(7, 2012, 13) 0.634306329944244\n",
      "(7, 2012, 14) 0.6008527386028206\n",
      "(7, 2012, 15) 0.5903574942604133\n",
      "(7, 2012, 16) 0.5339455559199737\n",
      "(7, 2012, 17) 0.5316497212200721\n",
      "(7, 2012, 18) 0.5160708428993113\n",
      "(7, 2012, 19) 0.590029517874713\n",
      "(7, 2012, 20) 0.6354542472941949\n",
      "(7, 2012, 21) 0.7795998688094458\n",
      "(7, 2012, 22) 0.6516890783863561\n",
      "(7, 2012, 23) 0.5109872089209577\n",
      "(7, 2012, 24) 0.5001639881928501\n",
      "(7, 2012, 25) 0.46080682190882255\n",
      "(7, 2012, 26) 0.47294194817973106\n",
      "(7, 2012, 27) 0.5765824860610036\n",
      "(7, 2012, 28) 0.6880944571990817\n",
      "(7, 2012, 29) 0.5892095769104625\n",
      "(7, 2012, 30) 0.5765824860610036\n",
      "(7, 2012, 31) 0.8816005247622172\n",
      "(7, 2013, 1) 0.7474581830108232\n",
      "(7, 2013, 2) 0.731387340111512\n",
      "(7, 2013, 3) 0.8912758281403739\n",
      "(7, 2013, 4) 0.9163660216464414\n",
      "(7, 2013, 5) 1.0265660872417186\n",
      "(7, 2013, 6) 1.0537881272548377\n",
      "(7, 2013, 7) 0.859954083306002\n",
      "(7, 2013, 8) 0.715644473597901\n",
      "(7, 2013, 9) 0.6835027877992784\n",
      "(7, 2013, 10) 0.8048540505083634\n",
      "(7, 2013, 11) 1.0198425713348638\n",
      "(7, 2013, 12) 0.8791407018694654\n",
      "(7, 2013, 13) 1.0278779927845194\n",
      "(7, 2013, 14) 0.964250573958675\n",
      "(7, 2013, 15) 0.8087897671367662\n",
      "(7, 2013, 16) 0.7978025582158085\n",
      "(7, 2013, 17) 0.8240406690718268\n",
      "(7, 2013, 18) 0.9211216792390948\n",
      "(7, 2013, 19) 0.9460478845523123\n",
      "(7, 2013, 20) 1.154148901279108\n",
      "(7, 2013, 21) 0.988520826500492\n",
      "(7, 2013, 22) 0.6530009839291571\n",
      "(7, 2013, 23) 0.5591997376188914\n",
      "(7, 2013, 24) 0.7422105608396196\n",
      "(7, 2013, 25) 0.7126926861265989\n",
      "(7, 2013, 26) 0.780091833387996\n",
      "(7, 2013, 27) 0.8848802886192194\n",
      "(7, 2013, 28) 0.9020990488684815\n",
      "(7, 2013, 29) 0.9024270252541817\n",
      "(7, 2013, 30) 1.0532961626762873\n",
      "(7, 2013, 31) 0.7553296162676287\n",
      "(7, 2014, 1) 0.8725811741554608\n",
      "(7, 2014, 2) 0.9788455231223352\n",
      "(7, 2014, 3) 1.1111839947523778\n",
      "(7, 2014, 4) 1.1802230239422762\n",
      "(7, 2014, 5) 1.1779271892423746\n",
      "(7, 2014, 6) 1.0993768448671695\n",
      "(7, 2014, 7) 0.8019022630370614\n",
      "(7, 2014, 8) 0.8727451623483109\n",
      "(7, 2014, 9) 0.9765496884224336\n",
      "(7, 2014, 10) 1.1702197441784192\n",
      "(7, 2014, 11) 1.0469006231551328\n",
      "(7, 2014, 12) 1.2600852738602821\n",
      "(7, 2014, 13) 1.0688750409970482\n",
      "(7, 2014, 14) 0.9988520826500492\n",
      "(7, 2014, 15) 0.9334207937028534\n",
      "(7, 2014, 16) 1.0067235159068546\n",
      "(7, 2014, 17) 1.1705477205641195\n",
      "(7, 2014, 18) 1.253033781567727\n",
      "(7, 2014, 19) 1.5473925877336832\n",
      "(7, 2014, 20) 0.8392915710068874\n",
      "(7, 2014, 21) 0.7792718924237455\n",
      "(7, 2014, 22) 0.7641849786815349\n",
      "(7, 2014, 23) 0.7861593965234503\n",
      "(7, 2014, 24) 0.8409314529353886\n",
      "(7, 2014, 25) 0.8381436536569367\n",
      "(7, 2014, 26) 1.0723187930469007\n",
      "(7, 2014, 27) 1.07149885208265\n",
      "(7, 2014, 28) 0.8848802886192194\n",
      "(7, 2014, 29) 1.1361102000655954\n",
      "(7, 2014, 30) 1.054280091833388\n",
      "(7, 2014, 31) 0.7553296162676287\n",
      "(7, 2015, 1) 1.1216792390947852\n",
      "(7, 2015, 2) 1.2666448015742866\n",
      "(7, 2015, 3) 1.4517874713020662\n",
      "(7, 2015, 4) 1.411610364053788\n",
      "(7, 2015, 5) 1.0108232207281076\n",
      "(7, 2015, 6) 0.9470318137094129\n",
      "(7, 2015, 7) 0.8735651033125615\n",
      "(7, 2015, 8) 1.0906854706461135\n",
      "(7, 2015, 9) 1.3025582158084619\n",
      "(7, 2015, 10) 1.152836995736307\n",
      "(7, 2015, 11) 1.2902591013447031\n",
      "(7, 2015, 12) 1.1905542800918334\n",
      "(7, 2015, 13) 0.9790095113151853\n",
      "(7, 2015, 14) 0.9854050508363398\n",
      "(7, 2015, 15) 1.0906854706461135\n",
      "(7, 2015, 16) 1.1474253853722531\n",
      "(7, 2015, 17) 1.248442112167924\n",
      "(7, 2015, 18) 1.5067235159068546\n",
      "(7, 2015, 19) 1.458510987208921\n",
      "(7, 2015, 20) 0.8966874385044277\n",
      "(7, 2015, 21) 0.854378484749098\n",
      "(7, 2015, 22) 0.9058707773040341\n",
      "(7, 2015, 23) 0.8660216464414562\n",
      "(7, 2015, 24) 1.0154148901279108\n",
      "(7, 2015, 25) 1.2341751393899638\n",
      "(7, 2015, 26) 1.134470318137094\n",
      "(7, 2015, 27) 0.9924565431288948\n",
      "(7, 2015, 28) 1.1718596261069203\n",
      "(7, 2015, 29) 1.1302066251229912\n",
      "(7, 2015, 30) 0.9253853722531977\n",
      "(7, 2015, 31) 0.9193178091177435\n",
      "(7, 2016, 1) 0.7153164972122007\n",
      "(7, 2016, 2) 0.8394555591997376\n",
      "(7, 2016, 3) 0.8806165956051164\n",
      "(7, 2016, 4) 0.5195145949491636\n",
      "(7, 2016, 5) 0.5298458510987208\n",
      "(7, 2016, 6) 0.4913086257789439\n",
      "(7, 2016, 7) 0.5391931780911774\n",
      "(7, 2016, 8) 0.6339783535585438\n",
      "(7, 2016, 9) 1.0137750081994097\n",
      "(7, 2016, 10) 0.8191210232863234\n",
      "(7, 2016, 11) 0.572810757625451\n",
      "(7, 2016, 12) 0.5555919973761889\n",
      "(7, 2016, 13) 0.5196785831420138\n",
      "(7, 2016, 14) 0.531485733027222\n",
      "(7, 2016, 15) 0.6333224007871433\n",
      "(7, 2016, 16) 0.7973105936372581\n",
      "(7, 2016, 17) 0.7891111839947523\n",
      "(7, 2016, 18) 0.5306657920629715\n",
      "(7, 2016, 19) 0.5032797638570023\n",
      "(7, 2016, 20) 0.5316497212200721\n",
      "(7, 2016, 21) 0.5450967530337816\n",
      "(7, 2016, 22) 0.6544768776648081\n",
      "(7, 2016, 23) 1.5651033125614955\n",
      "(7, 2016, 24) 1.598556903902919\n",
      "(7, 2016, 25) 0.0\n",
      "(7, 2016, 26) 0.0\n",
      "(7, 2016, 27) 0.0\n",
      "(7, 2016, 28) 0.4983601180714988\n",
      "(7, 2016, 29) 0.45588717612331914\n",
      "(7, 2016, 30) 0.44145621515250905\n",
      "(7, 2016, 31) 0.9373565103312561\n",
      "(8, 2011, 1) 0.6077402427025255\n",
      "(8, 2011, 2) 0.6630042636930141\n",
      "(8, 2011, 3) 0.5701869465398491\n",
      "(8, 2011, 4) 0.5221384060347655\n",
      "(8, 2011, 5) 0.5223023942276156\n",
      "(8, 2011, 6) 0.48409314529353886\n",
      "(8, 2011, 7) 0.5277140045916694\n",
      "(8, 2011, 8) 0.5149229255493605\n",
      "(8, 2011, 9) 0.6262709084945884\n",
      "(8, 2011, 10) 0.47490980649393244\n",
      "(8, 2011, 11) 0.5047556575926533\n",
      "(8, 2011, 12) 0.6108560183666776\n",
      "(8, 2011, 13) 0.5036077402427025\n",
      "(8, 2011, 14) 0.6023286323384717\n",
      "(8, 2011, 15) 0.5367333551984257\n",
      "(8, 2011, 16) 0.5539521154476877\n",
      "(8, 2011, 17) 0.45063955395211547\n",
      "(8, 2011, 18) 0.417185962610692\n",
      "(8, 2011, 19) 0.38307641849786817\n",
      "(8, 2011, 20) 0.4419481797310594\n",
      "(8, 2011, 21) 0.4926205313217448\n",
      "(8, 2011, 22) 0.4158740570678911\n",
      "(8, 2011, 23) 0.5673991472613972\n",
      "(8, 2011, 24) 0.31124959002951785\n",
      "(8, 2011, 25) 0.40833060019678585\n",
      "(8, 2011, 26) 0.39980321416857983\n",
      "(8, 2011, 27) 0.4224335847818957\n",
      "(8, 2011, 28) 0.4137422105608396\n",
      "(8, 2011, 29) 0.5213184650705149\n",
      "(8, 2011, 30) 0.5247622171203673\n",
      "(8, 2011, 31) 0.5444408002623811\n",
      "(8, 2012, 1) 0.5760905214824532\n",
      "(8, 2012, 2) 0.5828140373893079\n",
      "(8, 2012, 3) 0.6754673663496228\n",
      "(8, 2012, 4) 0.5906854706461134\n",
      "(8, 2012, 5) 0.6707117087569695\n",
      "(8, 2012, 6) 0.7076090521482453\n",
      "(8, 2012, 7) 0.6183994752377828\n",
      "(8, 2012, 8) 0.5552640209904887\n",
      "(8, 2012, 9) 0.6500491964578551\n",
      "(8, 2012, 10) 0.5856018366677599\n",
      "(8, 2012, 11) 0.6467694326008527\n",
      "(8, 2012, 12) 0.6690718268284683\n",
      "(8, 2012, 13) 0.508527386028206\n",
      "(8, 2012, 14) 0.6539849130862578\n",
      "(8, 2012, 15) 0.6794030829780255\n",
      "(8, 2012, 16) 0.590029517874713\n",
      "(8, 2012, 17) 0.5080354214496556\n",
      "(8, 2012, 18) 0.558543784847491\n",
      "(8, 2012, 19) 0.5567399147261397\n",
      "(8, 2012, 20) 0.5936372581174155\n",
      "(8, 2012, 21) 0.5595277140045917\n",
      "(8, 2012, 22) 0.5060675631354542\n",
      "(8, 2012, 23) 0.37389307969826174\n",
      "(8, 2012, 24) 0.42079370285339457\n",
      "(8, 2012, 25) 0.37848474909806495\n",
      "(8, 2012, 26) 0.4326008527386028\n",
      "(8, 2012, 27) 0.4844211216792391\n",
      "(8, 2012, 28) 0.5432928829124303\n",
      "(8, 2012, 29) 0.4877008855362414\n",
      "(8, 2012, 30) 0.5283699573630699\n",
      "(8, 2012, 31) 0.7818957035093473\n",
      "(8, 2013, 1) 1.1036405378812726\n",
      "(8, 2013, 2) 1.4378484749098064\n",
      "(8, 2013, 3) 1.5308297802558215\n",
      "(8, 2013, 4) 1.2979665464086585\n",
      "(8, 2013, 5) 1.5347654968842244\n",
      "(8, 2013, 6) 1.5829780255821582\n",
      "(8, 2013, 7) 1.235651033125615\n",
      "(8, 2013, 8) 1.3330600196785831\n",
      "(8, 2013, 9) 1.3346999016070842\n",
      "(8, 2013, 10) 1.178747130206625\n",
      "(8, 2013, 11) 1.4435880616595604\n",
      "(8, 2013, 12) 1.389963922597573\n",
      "(8, 2013, 13) 1.3343719252213841\n",
      "(8, 2013, 14) 1.5588717612331913\n",
      "(8, 2013, 15) 1.3878320760905214\n",
      "(8, 2013, 16) 1.2094129222695966\n",
      "(8, 2013, 17) 1.1757953427353232\n",
      "(8, 2013, 18) 1.0949491636602164\n",
      "(8, 2013, 19) 1.0810101672679566\n",
      "(8, 2013, 20) 1.327320432928829\n",
      "(8, 2013, 21) 1.0751065923253527\n",
      "(8, 2013, 22) 0.8461790751065923\n",
      "(8, 2013, 23) 0.7638570022958348\n",
      "(8, 2013, 24) 0.8179731059363726\n",
      "(8, 2013, 25) 0.8555264020990488\n",
      "(8, 2013, 26) 0.9483437192522138\n",
      "(8, 2013, 27) 1.0036077402427026\n",
      "(8, 2013, 28) 0.9634306329944244\n",
      "(8, 2013, 29) 1.0108232207281076\n",
      "(8, 2013, 30) 1.180059035749426\n",
      "(8, 2013, 31) 0.9760577238438832\n",
      "(8, 2014, 1) 1.2081010167267956\n",
      "(8, 2014, 2) 1.5847818957035094\n",
      "(8, 2014, 3) 1.7978025582158084\n",
      "(8, 2014, 4) 1.3693014102984584\n",
      "(8, 2014, 5) 1.6210232863233847\n",
      "(8, 2014, 6) 1.5980649393243687\n",
      "(8, 2014, 7) 1.1792390947851754\n",
      "(8, 2014, 8) 1.4596589045588717\n",
      "(8, 2014, 9) 1.4709740898655297\n",
      "(8, 2014, 10) 1.3624139061987537\n",
      "(8, 2014, 11) 1.3176451295506724\n",
      "(8, 2014, 12) 1.7669727779599869\n",
      "(8, 2014, 13) 1.3355198425713348\n",
      "(8, 2014, 14) 1.5062315513283044\n",
      "(8, 2014, 15) 1.5454247294194818\n",
      "(8, 2014, 16) 1.2505739586749753\n",
      "(8, 2014, 17) 1.2748442112167924\n",
      "(8, 2014, 18) 1.2504099704821252\n",
      "(8, 2014, 19) 1.4001311905542801\n",
      "(8, 2014, 20) 0.81436536569367\n",
      "(8, 2014, 21) 1.1144637586093802\n",
      "(8, 2014, 22) 0.8963594621187274\n",
      "(8, 2014, 23) 1.0465726467694325\n",
      "(8, 2014, 24) 0.995736306985897\n",
      "(8, 2014, 25) 1.0567399147261398\n",
      "(8, 2014, 26) 1.2538537225319777\n",
      "(8, 2014, 27) 1.0795342735323057\n",
      "(8, 2014, 28) 1.0619875368973435\n",
      "(8, 2014, 29) 1.2366349622827157\n",
      "(8, 2014, 30) 1.1020006559527713\n",
      "(8, 2014, 31) 0.9780255821580847\n",
      "(8, 2015, 1) 1.3350278779927844\n",
      "(8, 2015, 2) 1.530009839291571\n",
      "(8, 2015, 3) 1.8076418497868154\n",
      "(8, 2015, 4) 1.4380124631026565\n",
      "(8, 2015, 5) 1.3404394883568382\n",
      "(8, 2015, 6) 1.464086585765825\n",
      "(8, 2015, 7) 1.1805510003279764\n",
      "(8, 2015, 8) 1.4893407674647425\n",
      "(8, 2015, 9) 1.675959330928173\n",
      "(8, 2015, 10) 1.241226631682519\n",
      "(8, 2015, 11) 1.4750737946867825\n",
      "(8, 2015, 12) 1.6431616923581502\n",
      "(8, 2015, 13) 1.1492292554936046\n",
      "(8, 2015, 14) 1.3963594621187274\n",
      "(8, 2015, 15) 1.5354214496556249\n",
      "(8, 2015, 16) 1.334207937028534\n",
      "(8, 2015, 17) 1.2868153492948509\n",
      "(8, 2015, 18) 1.3466710396851427\n",
      "(8, 2015, 19) 1.3332240078714332\n",
      "(8, 2015, 20) 1.107248278123975\n",
      "(8, 2015, 21) 0.9845851098720892\n",
      "(8, 2015, 22) 1.0249262053132175\n",
      "(8, 2015, 23) 1.0788783207609052\n",
      "(8, 2015, 24) 1.0778943916038046\n",
      "(8, 2015, 25) 1.168743850442768\n",
      "(8, 2015, 26) 1.169891767792719\n",
      "(8, 2015, 27) 1.144473597900951\n",
      "(8, 2015, 28) 1.1374221056083962\n",
      "(8, 2015, 29) 1.060019678583142\n",
      "(8, 2015, 30) 1.025746146277468\n",
      "(8, 2015, 31) 0.9196457855034438\n",
      "(8, 2016, 1) 1.0078714332568055\n",
      "(8, 2016, 2) 1.1592325352574615\n",
      "(8, 2016, 3) 1.1402099048868481\n",
      "(8, 2016, 4) 0.8215808461790751\n",
      "(8, 2016, 5) 0.931452935388652\n",
      "(8, 2016, 6) 1.0073794686782551\n",
      "(8, 2016, 7) 0.8760249262053132\n",
      "(8, 2016, 8) 1.0979009511315185\n",
      "(8, 2016, 9) 1.2876352902591013\n",
      "(8, 2016, 10) 0.9858970154148902\n",
      "(8, 2016, 11) 1.0211544768776648\n",
      "(8, 2016, 12) 0.9731059363725811\n",
      "(8, 2016, 13) 0.7517218760249262\n",
      "(8, 2016, 14) 0.8630698589701542\n",
      "(8, 2016, 15) 1.0264020990488685\n",
      "(8, 2016, 16) 0.9148901279107904\n",
      "(8, 2016, 17) 0.9127582814037389\n",
      "(8, 2016, 18) 0.712856674319449\n",
      "(8, 2016, 19) 0.7320432928829125\n",
      "(8, 2016, 20) 0.6877664808133814\n",
      "(8, 2016, 21) 0.7204001311905542\n",
      "(8, 2016, 22) 0.8179731059363726\n",
      "(8, 2016, 23) 1.7723843883240407\n",
      "(8, 2016, 24) 1.681534929485077\n",
      "(8, 2016, 25) 0.0\n",
      "(8, 2016, 26) 0.0\n",
      "(8, 2016, 27) 0.0\n",
      "(8, 2016, 28) 0.6976057723843884\n",
      "(8, 2016, 29) 0.6626762873073139\n",
      "(8, 2016, 30) 0.5946211872745162\n",
      "(8, 2016, 31) 1.2817317153164973\n",
      "(9, 2011, 1) 1.0675631354542472\n",
      "(9, 2011, 2) 1.277140045916694\n",
      "(9, 2011, 3) 1.225647753361758\n",
      "(9, 2011, 4) 0.8876680878976714\n",
      "(9, 2011, 5) 0.9511315185306658\n",
      "(9, 2011, 6) 0.9860610036077403\n",
      "(9, 2011, 7) 0.954247294194818\n",
      "(9, 2011, 8) 0.979993440472286\n",
      "(9, 2011, 9) 1.1877664808133814\n",
      "(9, 2011, 10) 0.9806493932436865\n",
      "(9, 2011, 11) 1.0149229255493604\n",
      "(9, 2011, 12) 1.0696949819612989\n",
      "(9, 2011, 13) 0.9417841915382092\n",
      "(9, 2011, 14) 1.1051164316169235\n",
      "(9, 2011, 15) 1.2581174155460806\n",
      "(9, 2011, 16) 1.078714332568055\n",
      "(9, 2011, 17) 0.954247294194818\n",
      "(9, 2011, 18) 0.7856674319449\n",
      "(9, 2011, 19) 0.7018694653984913\n",
      "(9, 2011, 20) 0.8440472285995408\n",
      "(9, 2011, 21) 0.9016070842899311\n",
      "(9, 2011, 22) 0.9129222695965891\n",
      "(9, 2011, 23) 1.169891767792719\n",
      "(9, 2011, 24) 0.8133814365365694\n",
      "(9, 2011, 25) 0.7412266316825189\n",
      "(9, 2011, 26) 0.6493932436864546\n",
      "(9, 2011, 27) 0.6598884880288619\n",
      "(9, 2011, 28) 0.7604132502459823\n",
      "(9, 2011, 29) 0.9240734667103968\n",
      "(9, 2011, 30) 0.8542144965562479\n",
      "(9, 2011, 31) 0.7615611675959331\n",
      "(9, 2012, 1) 1.2902591013447031\n",
      "(9, 2012, 2) 1.511479173499508\n",
      "(9, 2012, 3) 1.521318465070515\n",
      "(9, 2012, 4) 1.2932108888160052\n",
      "(9, 2012, 5) 1.5980649393243687\n",
      "(9, 2012, 6) 1.6605444408002623\n",
      "(9, 2012, 7) 1.4624467038373237\n",
      "(9, 2012, 8) 1.368481469334208\n",
      "(9, 2012, 9) 1.3758609380124631\n",
      "(9, 2012, 10) 1.1015086913742211\n",
      "(9, 2012, 11) 1.4404722859954084\n",
      "(9, 2012, 12) 1.6680878976713676\n",
      "(9, 2012, 13) 1.34306329944244\n",
      "(9, 2012, 14) 1.7230239422761562\n",
      "(9, 2012, 15) 1.6039685142669728\n",
      "(9, 2012, 16) 1.192850114791735\n",
      "(9, 2012, 17) 1.1087241718596261\n",
      "(9, 2012, 18) 1.150049196457855\n",
      "(9, 2012, 19) 1.2007215480485405\n",
      "(9, 2012, 20) 1.2917349950803543\n",
      "(9, 2012, 21) 1.4417841915382092\n",
      "(9, 2012, 22) 1.240078714332568\n",
      "(9, 2012, 23) 0.9432600852738603\n",
      "(9, 2012, 24) 0.9078386356182355\n",
      "(9, 2012, 25) 0.9721220072154805\n",
      "(9, 2012, 26) 0.9576910462446704\n",
      "(9, 2012, 27) 1.024270252541817\n",
      "(9, 2012, 28) 1.123155132830436\n",
      "(9, 2012, 29) 1.0806821908822566\n",
      "(9, 2012, 30) 1.068711052804198\n",
      "(9, 2012, 31) 1.5309937684486716\n",
      "(9, 2013, 1) 0.9735979009511315\n",
      "(9, 2013, 2) 1.2244998360118071\n",
      "(9, 2013, 3) 1.2863233847163005\n",
      "(9, 2013, 4) 1.1280747786159397\n",
      "(9, 2013, 5) 1.2817317153164973\n",
      "(9, 2013, 6) 1.3455231223351918\n",
      "(9, 2013, 7) 1.1861265988848804\n",
      "(9, 2013, 8) 1.0811741554608068\n",
      "(9, 2013, 9) 1.0431288947195803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 2013, 10) 1.0231223351918661\n",
      "(9, 2013, 11) 1.232863233847163\n",
      "(9, 2013, 12) 1.155624795014759\n",
      "(9, 2013, 13) 1.1608724171859626\n",
      "(9, 2013, 14) 1.0665792062971466\n",
      "(9, 2013, 15) 1.0360774024270252\n",
      "(9, 2013, 16) 0.9020990488684815\n",
      "(9, 2013, 17) 0.8366677599212856\n",
      "(9, 2013, 18) 0.8878320760905215\n",
      "(9, 2013, 19) 0.9385044276812069\n",
      "(9, 2013, 20) 1.0534601508691375\n",
      "(9, 2013, 21) 0.9773696293866841\n",
      "(9, 2013, 22) 0.7195801902263037\n",
      "(9, 2013, 23) 0.6539849130862578\n",
      "(9, 2013, 24) 0.7582814037389308\n",
      "(9, 2013, 25) 0.8960314857330273\n",
      "(9, 2013, 26) 0.8558543784847491\n",
      "(9, 2013, 27) 0.9567071170875697\n",
      "(9, 2013, 28) 0.934240734667104\n",
      "(9, 2013, 29) 0.9868809445719908\n",
      "(9, 2013, 30) 1.0834699901607083\n",
      "(9, 2013, 31) 1.1482453263365038\n",
      "(9, 2014, 1) 0.8238766808789767\n",
      "(9, 2014, 2) 1.05723187930469\n",
      "(9, 2014, 3) 1.1730075434568712\n",
      "(9, 2014, 4) 1.004263693014103\n",
      "(9, 2014, 5) 1.0441128238766808\n",
      "(9, 2014, 6) 1.0188586421777632\n",
      "(9, 2014, 7) 0.8148573302722204\n",
      "(9, 2014, 8) 0.8786487372909151\n",
      "(9, 2014, 9) 1.031485733027222\n",
      "(9, 2014, 10) 0.8748770088553625\n",
      "(9, 2014, 11) 1.067071170875697\n",
      "(9, 2014, 12) 1.1894063627418825\n",
      "(9, 2014, 13) 1.024106264348967\n",
      "(9, 2014, 14) 1.0275500163988194\n",
      "(9, 2014, 15) 0.972941948179731\n",
      "(9, 2014, 16) 0.9096425057395867\n",
      "(9, 2014, 17) 0.9444080026238111\n",
      "(9, 2014, 18) 0.9824532633650377\n",
      "(9, 2014, 19) 1.248606100360774\n",
      "(9, 2014, 20) 0.9793374877008856\n",
      "(9, 2014, 21) 0.7018694653984913\n",
      "(9, 2014, 22) 0.7884552312233519\n",
      "(9, 2014, 23) 0.7504099704821253\n",
      "(9, 2014, 24) 0.7297474581830108\n",
      "(9, 2014, 25) 0.7712364709740899\n",
      "(9, 2014, 26) 0.8820924893407674\n",
      "(9, 2014, 27) 0.8433912758281403\n",
      "(9, 2014, 28) 0.8150213184650705\n",
      "(9, 2014, 29) 0.9591669399803214\n",
      "(9, 2014, 30) 0.8153492948507708\n",
      "(9, 2014, 31) 0.7464742538537226\n",
      "(9, 2015, 1) 0.9809773696293866\n",
      "(9, 2015, 2) 1.1948179731059363\n",
      "(9, 2015, 3) 1.4266972777959988\n",
      "(9, 2015, 4) 1.161528369957363\n",
      "(9, 2015, 5) 1.1149557231879306\n",
      "(9, 2015, 6) 1.081502131846507\n",
      "(9, 2015, 7) 0.9373565103312561\n",
      "(9, 2015, 8) 1.0821580846179075\n",
      "(9, 2015, 9) 1.1607084289931124\n",
      "(9, 2015, 10) 1.0997048212528697\n",
      "(9, 2015, 11) 1.2204001311905543\n",
      "(9, 2015, 12) 1.2302394227615612\n",
      "(9, 2015, 13) 0.9645785503443752\n",
      "(9, 2015, 14) 1.0938012463102658\n",
      "(9, 2015, 15) 1.108560183666776\n",
      "(9, 2015, 16) 1.0385372253197769\n",
      "(9, 2015, 17) 1.1008527386028206\n",
      "(9, 2015, 18) 1.1584125942932109\n",
      "(9, 2015, 19) 1.231551328304362\n",
      "(9, 2015, 20) 0.8468350278779928\n",
      "(9, 2015, 21) 0.844211216792391\n",
      "(9, 2015, 22) 0.8101016726795671\n",
      "(9, 2015, 23) 0.7602492620531321\n",
      "(9, 2015, 24) 0.8740570678911118\n",
      "(9, 2015, 25) 0.9207937028533946\n",
      "(9, 2015, 26) 0.9673663496228272\n",
      "(9, 2015, 27) 0.8619219416202033\n",
      "(9, 2015, 28) 0.9740898655296819\n",
      "(9, 2015, 29) 0.8342079370285339\n",
      "(9, 2015, 30) 0.7397507379468679\n",
      "(9, 2015, 31) 0.7684486716956379\n",
      "(9, 2016, 1) 0.6976057723843884\n",
      "(9, 2016, 2) 0.855690390291899\n",
      "(9, 2016, 3) 0.8976713676615283\n",
      "(9, 2016, 4) 0.5821580846179075\n",
      "(9, 2016, 5) 0.6411938340439488\n",
      "(9, 2016, 6) 0.631354542472942\n",
      "(9, 2016, 7) 0.5619875368973434\n",
      "(9, 2016, 8) 0.6853066579206297\n",
      "(9, 2016, 9) 0.9240734667103968\n",
      "(9, 2016, 10) 0.8146933420793703\n",
      "(9, 2016, 11) 0.6630042636930141\n",
      "(9, 2016, 12) 0.6784191538209249\n",
      "(9, 2016, 13) 0.5136110200065596\n",
      "(9, 2016, 14) 0.6008527386028206\n",
      "(9, 2016, 15) 0.7564775336175795\n",
      "(9, 2016, 16) 0.8030501803870121\n",
      "(9, 2016, 17) 0.741390619875369\n",
      "(9, 2016, 18) 0.5831420137750082\n",
      "(9, 2016, 19) 0.5462446703837324\n",
      "(9, 2016, 20) 0.5180387012135126\n",
      "(9, 2016, 21) 0.5290259101344703\n",
      "(9, 2016, 22) 0.6277468022302394\n",
      "(9, 2016, 23) 1.5368973433912758\n",
      "(9, 2016, 24) 1.418497868153493\n",
      "(9, 2016, 25) 0.0\n",
      "(9, 2016, 26) 0.0\n",
      "(9, 2016, 27) 0.0\n",
      "(9, 2016, 28) 0.4858970154148901\n",
      "(9, 2016, 29) 0.5567399147261397\n",
      "(9, 2016, 30) 0.46917021974417844\n",
      "(9, 2016, 31) 0.9865529681862906\n"
     ]
    }
   ],
   "source": [
    "# tmp = all_df17_20.groupby(['store_id', 'year','day'])['sales'].mean()\n",
    "\n",
    "# for i in tmp.index:\n",
    "#     print(i, tmp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>is_event</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>revenue</th>\n",
       "      <th>lag_t28</th>\n",
       "      <th>lag_t29</th>\n",
       "      <th>lag_t30</th>\n",
       "      <th>lag_t31</th>\n",
       "      <th>lag_t32</th>\n",
       "      <th>lag_t33</th>\n",
       "      <th>lag_t34</th>\n",
       "      <th>rolling_mean_t7</th>\n",
       "      <th>rolling_std_t7</th>\n",
       "      <th>rolling_mean_t28</th>\n",
       "      <th>rolling_std_t28</th>\n",
       "      <th>rolling_mean_t56</th>\n",
       "      <th>rolling_std_t56</th>\n",
       "      <th>rolling_mean_t84</th>\n",
       "      <th>rolling_std_t84</th>\n",
       "      <th>rolling_mean_t112</th>\n",
       "      <th>rolling_std_t112</th>\n",
       "      <th>rolling_mean_t168</th>\n",
       "      <th>rolling_std_t168</th>\n",
       "      <th>price_change_t1</th>\n",
       "      <th>price_change_t365</th>\n",
       "      <th>rolling_price_std_t7</th>\n",
       "      <th>rolling_price_std_t28</th>\n",
       "      <th>revenue_lag_t28</th>\n",
       "      <th>revenue_lag_t29</th>\n",
       "      <th>revenue_lag_t30</th>\n",
       "      <th>revenue_lag_t31</th>\n",
       "      <th>revenue_lag_t32</th>\n",
       "      <th>revenue_lag_t33</th>\n",
       "      <th>revenue_lag_t34</th>\n",
       "      <th>price_lag_t1</th>\n",
       "      <th>price_lag_t2</th>\n",
       "      <th>price_lag_t3</th>\n",
       "      <th>price_lag_t4</th>\n",
       "      <th>price_lag_t5</th>\n",
       "      <th>price_lag_t6</th>\n",
       "      <th>price_lag_t28</th>\n",
       "      <th>price_lag_t29</th>\n",
       "      <th>price_lag_t30</th>\n",
       "      <th>price_lag_t31</th>\n",
       "      <th>price_lag_t32</th>\n",
       "      <th>price_lag_t33</th>\n",
       "      <th>price_lag_t34</th>\n",
       "      <th>rolling_price_std_t14</th>\n",
       "      <th>rolling_price_max_t365</th>\n",
       "      <th>price_change_t180</th>\n",
       "      <th>item_id_gb_sell_price_x</th>\n",
       "      <th>item_id_gb_sell_price_y</th>\n",
       "      <th>item_id_gb_sell_price</th>\n",
       "      <th>item_id_gb_sell_price_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14370</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1486</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-03-28</td>\n",
       "      <td>11109</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14380</td>\n",
       "      <td>1438</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1486</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-03-28</td>\n",
       "      <td>11109</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14390</td>\n",
       "      <td>1439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1486</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-03-28</td>\n",
       "      <td>11109</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14400</td>\n",
       "      <td>1440</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1486</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-03-28</td>\n",
       "      <td>11109</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>4.339844</td>\n",
       "      <td>8.679688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.339844</td>\n",
       "      <td>4.339844</td>\n",
       "      <td>4.339844</td>\n",
       "      <td>4.339844</td>\n",
       "      <td>4.339844</td>\n",
       "      <td>4.339844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.339844</td>\n",
       "      <td>4.339844</td>\n",
       "      <td>4.339844</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14410</td>\n",
       "      <td>1441</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1486</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-03-28</td>\n",
       "      <td>11109</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  item_id  dept_id  cat_id  store_id  state_id     d  sales  \\\n",
       "0  14370     1437        3       1         0         0  1486      0   \n",
       "1  14380     1438        3       1         0         0  1486      0   \n",
       "2  14390     1439        3       1         0         0  1486      0   \n",
       "3  14400     1440        3       1         0         0  1486      2   \n",
       "4  14410     1441        3       1         0         0  1486      0   \n",
       "\n",
       "         date  wm_yr_wk  weekday  month  year  event_name_1  event_type_1  \\\n",
       "0  2011-03-28     11109        1      3  2011            30             4   \n",
       "1  2011-03-28     11109        1      3  2011            30             4   \n",
       "2  2011-03-28     11109        1      3  2011            30             4   \n",
       "3  2011-03-28     11109        1      3  2011            30             4   \n",
       "4  2011-03-28     11109        1      3  2011            30             4   \n",
       "\n",
       "   snap_CA  snap_TX  snap_WI  is_event  day  week  sell_price   revenue  \\\n",
       "0        0        0        0         0   28    13         NaN       NaN   \n",
       "1        0        0        0         0   28    13         NaN       NaN   \n",
       "2        0        0        0         0   28    13         NaN       NaN   \n",
       "3        0        0        0         0   28    13    4.339844  8.679688   \n",
       "4        0        0        0         0   28    13         NaN       NaN   \n",
       "\n",
       "   lag_t28  lag_t29  lag_t30  lag_t31  lag_t32  lag_t33  lag_t34  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   rolling_mean_t7  rolling_std_t7  rolling_mean_t28  rolling_std_t28  \\\n",
       "0              0.0             0.0               0.0              0.0   \n",
       "1              0.0             0.0               0.0              0.0   \n",
       "2              0.0             0.0               0.0              0.0   \n",
       "3              0.0             0.0               0.0              0.0   \n",
       "4              0.0             0.0               0.0              0.0   \n",
       "\n",
       "   rolling_mean_t56  rolling_std_t56  rolling_mean_t84  rolling_std_t84  \\\n",
       "0               NaN              NaN               NaN              NaN   \n",
       "1               NaN              NaN               NaN              NaN   \n",
       "2               NaN              NaN               NaN              NaN   \n",
       "3               NaN              NaN               NaN              NaN   \n",
       "4               NaN              NaN               NaN              NaN   \n",
       "\n",
       "   rolling_mean_t112  rolling_std_t112  rolling_mean_t168  rolling_std_t168  \\\n",
       "0                NaN               NaN                NaN               NaN   \n",
       "1                NaN               NaN                NaN               NaN   \n",
       "2                NaN               NaN                NaN               NaN   \n",
       "3                NaN               NaN                NaN               NaN   \n",
       "4                NaN               NaN                NaN               NaN   \n",
       "\n",
       "   price_change_t1  price_change_t365  rolling_price_std_t7  \\\n",
       "0              NaN                NaN                   NaN   \n",
       "1              NaN                NaN                   NaN   \n",
       "2              NaN                NaN                   NaN   \n",
       "3              0.0                NaN                   0.0   \n",
       "4              NaN                NaN                   NaN   \n",
       "\n",
       "   rolling_price_std_t28  revenue_lag_t28  revenue_lag_t29  revenue_lag_t30  \\\n",
       "0                    NaN              NaN              NaN              NaN   \n",
       "1                    NaN              NaN              NaN              NaN   \n",
       "2                    NaN              NaN              NaN              NaN   \n",
       "3                    NaN              NaN              NaN              NaN   \n",
       "4                    NaN              NaN              NaN              NaN   \n",
       "\n",
       "   revenue_lag_t31  revenue_lag_t32  revenue_lag_t33  revenue_lag_t34  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "1              NaN              NaN              NaN              NaN   \n",
       "2              NaN              NaN              NaN              NaN   \n",
       "3              NaN              NaN              NaN              NaN   \n",
       "4              NaN              NaN              NaN              NaN   \n",
       "\n",
       "   price_lag_t1  price_lag_t2  price_lag_t3  price_lag_t4  price_lag_t5  \\\n",
       "0           NaN           NaN           NaN           NaN           NaN   \n",
       "1           NaN           NaN           NaN           NaN           NaN   \n",
       "2           NaN           NaN           NaN           NaN           NaN   \n",
       "3      4.339844      4.339844      4.339844      4.339844      4.339844   \n",
       "4           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "   price_lag_t6  price_lag_t28  price_lag_t29  price_lag_t30  price_lag_t31  \\\n",
       "0           NaN            NaN            NaN            NaN            NaN   \n",
       "1           NaN            NaN            NaN            NaN            NaN   \n",
       "2           NaN            NaN            NaN            NaN            NaN   \n",
       "3      4.339844            NaN            NaN            NaN            NaN   \n",
       "4           NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   price_lag_t32  price_lag_t33  price_lag_t34  rolling_price_std_t14  \\\n",
       "0            NaN            NaN            NaN                    NaN   \n",
       "1            NaN            NaN            NaN                    NaN   \n",
       "2            NaN            NaN            NaN                    NaN   \n",
       "3            NaN            NaN            NaN                    0.0   \n",
       "4            NaN            NaN            NaN                    NaN   \n",
       "\n",
       "   rolling_price_max_t365  price_change_t180  item_id_gb_sell_price_x  \\\n",
       "0                     NaN                NaN                      NaN   \n",
       "1                     NaN                NaN                      NaN   \n",
       "2                     NaN                NaN                      NaN   \n",
       "3                     NaN                NaN                 4.339844   \n",
       "4                     NaN                NaN                      NaN   \n",
       "\n",
       "   item_id_gb_sell_price_y  item_id_gb_sell_price  item_id_gb_sell_price_std  \n",
       "0                      NaN                    NaN                        NaN  \n",
       "1                      NaN                    NaN                        NaN  \n",
       "2                      NaN                    NaN                        NaN  \n",
       "3                 4.339844               4.339844                        0.0  \n",
       "4                      NaN                    NaN                        NaN  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df17_20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize = (10, 7))\n",
    "sns.distplot(all_df17_20['event_name_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_id = LabelEncoder()\n",
    "le_id.fit(all_df17_20['id'])\n",
    "\n",
    "all_df17_20['id'] = le_id.transform(all_df17_20['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 피쳐 엔지니어링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare training and test data.\n",
    "- 2011-01-29 ~ 2016-04-24 : d_1    ~ d_1913\n",
    "- 2016-04-25 ~ 2016-05-22 : d_1914 ~ d_1941 (public)\n",
    "- 2016-05-23 ~ 2016-06-19 : d_1942 ~ d_1969 (private)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 모델 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# rf = RandomForestRegressor(n_estimators=100, n_jobs=-1)\n",
    "# rf.fit(train2, np.log(train['target'] + 1))\n",
    "# result = rf.predict(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lightgbm import LGBMRegressor\n",
    "# # lgb = LGBMRegressor(num_leaves=2000, colsample_bytree=0.6, subsample=0.6, n_estimators=600, learning_rate=0.025, n_jobs=-1, device='gpu', max_bin = 63)\n",
    "# lgb = LGBMRegressor(num_leaves=20, colsample_bytree=0.6, subsample=0.6, n_estimators=60, learning_rate=0.02, n_jobs=-1, device='cpu')\n",
    "\n",
    "# lgb.fit(train, target)\n",
    "# result = lgb.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 train set /  test set 선정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature 선정에 있어서 다른 노트북에서는 all_df = all_df.drop(['rolling_price_max_t365', 'lag_price_t1'], inplace = True, axis = 1) 이렇게 진행했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'd',\n",
       "       'sales', 'date', 'wm_yr_wk', 'weekday', 'month', 'year', 'event_name_1',\n",
       "       'event_type_1', 'snap_CA', 'snap_TX', 'snap_WI', 'is_event', 'day',\n",
       "       'week', 'sell_price', 'revenue', 'lag_t28', 'lag_t29', 'lag_t30',\n",
       "       'lag_t31', 'lag_t32', 'lag_t33', 'lag_t34', 'rolling_mean_t7',\n",
       "       'rolling_std_t7', 'rolling_mean_t28', 'rolling_std_t28',\n",
       "       'rolling_mean_t56', 'rolling_std_t56', 'rolling_mean_t84',\n",
       "       'rolling_std_t84', 'rolling_mean_t112', 'rolling_std_t112',\n",
       "       'rolling_mean_t168', 'rolling_std_t168', 'price_change_t1',\n",
       "       'price_change_t365', 'rolling_price_std_t7', 'rolling_price_std_t28',\n",
       "       'revenue_lag_t28', 'revenue_lag_t29', 'revenue_lag_t30',\n",
       "       'revenue_lag_t31', 'revenue_lag_t32', 'revenue_lag_t33',\n",
       "       'revenue_lag_t34', 'price_lag_t1', 'price_lag_t2', 'price_lag_t3',\n",
       "       'price_lag_t4', 'price_lag_t5', 'price_lag_t6', 'price_lag_t28',\n",
       "       'price_lag_t29', 'price_lag_t30', 'price_lag_t31', 'price_lag_t32',\n",
       "       'price_lag_t33', 'price_lag_t34', 'rolling_price_std_t14',\n",
       "       'rolling_price_max_t365', 'price_change_t180', 'item_id_gb_sell_price',\n",
       "       'item_id_gb_lag28', 'diff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df17_20.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>is_event</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>revenue</th>\n",
       "      <th>lag_t28</th>\n",
       "      <th>lag_t29</th>\n",
       "      <th>lag_t30</th>\n",
       "      <th>lag_t31</th>\n",
       "      <th>lag_t32</th>\n",
       "      <th>lag_t33</th>\n",
       "      <th>lag_t34</th>\n",
       "      <th>rolling_mean_t7</th>\n",
       "      <th>rolling_std_t7</th>\n",
       "      <th>rolling_mean_t28</th>\n",
       "      <th>rolling_std_t28</th>\n",
       "      <th>rolling_mean_t56</th>\n",
       "      <th>rolling_std_t56</th>\n",
       "      <th>rolling_mean_t84</th>\n",
       "      <th>rolling_std_t84</th>\n",
       "      <th>rolling_mean_t112</th>\n",
       "      <th>rolling_std_t112</th>\n",
       "      <th>rolling_mean_t168</th>\n",
       "      <th>rolling_std_t168</th>\n",
       "      <th>price_change_t1</th>\n",
       "      <th>price_change_t365</th>\n",
       "      <th>rolling_price_std_t7</th>\n",
       "      <th>rolling_price_std_t28</th>\n",
       "      <th>revenue_lag_t28</th>\n",
       "      <th>revenue_lag_t29</th>\n",
       "      <th>revenue_lag_t30</th>\n",
       "      <th>revenue_lag_t31</th>\n",
       "      <th>revenue_lag_t32</th>\n",
       "      <th>revenue_lag_t33</th>\n",
       "      <th>revenue_lag_t34</th>\n",
       "      <th>price_lag_t1</th>\n",
       "      <th>price_lag_t2</th>\n",
       "      <th>price_lag_t3</th>\n",
       "      <th>price_lag_t4</th>\n",
       "      <th>price_lag_t5</th>\n",
       "      <th>price_lag_t6</th>\n",
       "      <th>price_lag_t28</th>\n",
       "      <th>price_lag_t29</th>\n",
       "      <th>price_lag_t30</th>\n",
       "      <th>price_lag_t31</th>\n",
       "      <th>price_lag_t32</th>\n",
       "      <th>price_lag_t33</th>\n",
       "      <th>price_lag_t34</th>\n",
       "      <th>rolling_price_std_t14</th>\n",
       "      <th>rolling_price_max_t365</th>\n",
       "      <th>price_change_t180</th>\n",
       "      <th>item_id_gb_sell_price</th>\n",
       "      <th>item_id_gb_lag28</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14370</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1486</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-03-28</td>\n",
       "      <td>11109</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  item_id  dept_id  cat_id  store_id  state_id     d  sales  \\\n",
       "0  14370     1437        3       1         0         0  1486      0   \n",
       "\n",
       "         date  wm_yr_wk  weekday  month  year  event_name_1  event_type_1  \\\n",
       "0  2011-03-28     11109        1      3  2011            30             4   \n",
       "\n",
       "   snap_CA  snap_TX  snap_WI  is_event  day  week  sell_price  revenue  \\\n",
       "0        0        0        0         0   28    13         NaN      NaN   \n",
       "\n",
       "   lag_t28  lag_t29  lag_t30  lag_t31  lag_t32  lag_t33  lag_t34  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   rolling_mean_t7  rolling_std_t7  rolling_mean_t28  rolling_std_t28  \\\n",
       "0              0.0             0.0               0.0              0.0   \n",
       "\n",
       "   rolling_mean_t56  rolling_std_t56  rolling_mean_t84  rolling_std_t84  \\\n",
       "0               NaN              NaN               NaN              NaN   \n",
       "\n",
       "   rolling_mean_t112  rolling_std_t112  rolling_mean_t168  rolling_std_t168  \\\n",
       "0                NaN               NaN                NaN               NaN   \n",
       "\n",
       "   price_change_t1  price_change_t365  rolling_price_std_t7  \\\n",
       "0              NaN                NaN                   NaN   \n",
       "\n",
       "   rolling_price_std_t28  revenue_lag_t28  revenue_lag_t29  revenue_lag_t30  \\\n",
       "0                    NaN              NaN              NaN              NaN   \n",
       "\n",
       "   revenue_lag_t31  revenue_lag_t32  revenue_lag_t33  revenue_lag_t34  \\\n",
       "0              NaN              NaN              NaN              NaN   \n",
       "\n",
       "   price_lag_t1  price_lag_t2  price_lag_t3  price_lag_t4  price_lag_t5  \\\n",
       "0           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "   price_lag_t6  price_lag_t28  price_lag_t29  price_lag_t30  price_lag_t31  \\\n",
       "0           NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   price_lag_t32  price_lag_t33  price_lag_t34  rolling_price_std_t14  \\\n",
       "0            NaN            NaN            NaN                    NaN   \n",
       "\n",
       "   rolling_price_max_t365  price_change_t180  item_id_gb_sell_price  \\\n",
       "0                     NaN                NaN                    NaN   \n",
       "\n",
       "   item_id_gb_lag28  diff  \n",
       "0               0.0   NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df17_20.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['d', 'sales', 'date', 'cat_id',  'wm_yr_wk', 'is_event' , 'event_type_1', 'lag_t32', 'lag_t33', 'lag_t34',\n",
    "             'revenue','revenue_lag_t28', 'revenue_lag_t29', 'revenue_lag_t30','revenue_lag_t31', 'revenue_lag_t32', 'revenue_lag_t33', 'revenue_lag_t34',\n",
    "             'price_lag_t1', 'price_lag_t2', 'price_lag_t3', 'price_lag_t4', 'price_lag_t5', 'price_lag_t6',\n",
    "             'rolling_price_std_t14', 'price_lag_t28', 'price_lag_t29',\n",
    "       'price_lag_t30','price_lag_t31', 'price_lag_t32', 'price_lag_t33',\n",
    "       'price_lag_t34', 'price_change_t1' , 'price_change_t180',  'rolling_mean_t112' , 'rolling_std_t112'  ]\n",
    "\n",
    "features = all_df17_20.columns.drop(drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'item_id', 'dept_id', 'store_id', 'state_id', 'weekday', 'month',\n",
       "       'year', 'event_name_1', 'snap_CA', 'snap_TX', 'snap_WI', 'day', 'week',\n",
       "       'sell_price', 'lag_t28', 'lag_t29', 'lag_t30', 'lag_t31',\n",
       "       'rolling_mean_t7', 'rolling_std_t7', 'rolling_mean_t28',\n",
       "       'rolling_std_t28', 'rolling_mean_t56', 'rolling_std_t56',\n",
       "       'rolling_mean_t84', 'rolling_std_t84', 'rolling_mean_t168',\n",
       "       'rolling_std_t168', 'price_change_t365', 'rolling_price_std_t7',\n",
       "       'rolling_price_std_t28', 'rolling_price_max_t365',\n",
       "       'item_id_gb_sell_price', 'item_id_gb_lag28', 'diff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = all_df17_20[all_df17_20['date'] <= '2016-04-24']\n",
    "train_set_X = train_set[features]\n",
    "train_set_y = train_set['sales']\n",
    "\n",
    "# 테스트 셋\n",
    "test = all_df17_20[all_df17_20['date'] > '2016-04-24']\n",
    "test_set = test[features]\n",
    "\n",
    "\n",
    "var_set = all_df17_20[(all_df17_20['date'] > '2015-04-27') & (all_df17_20['date'] <= '2015-05-22')]\n",
    "var_set_X = var_set[features]\n",
    "var_set_y = var_set['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_store(data, store_id):\n",
    "    data = data[data[\"store_id\"] == store_id]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_test_set(data, drop_cols):\n",
    "\n",
    "    features = data.columns.drop(drop_cols)\n",
    "\n",
    "    train_set = data[data['date'] <= '2016-04-24']\n",
    "    train_set_X = train_set[features]\n",
    "    train_set_y = train_set['target']\n",
    "\n",
    "    # 테스트 셋\n",
    "    test = data[data['date'] > '2016-04-24']\n",
    "    test_set = test[features]\n",
    "\n",
    "    var_set = data[(data['date'] > '2015-04-27') & (data['date'] <= '2015-05-22')]\n",
    "    var_set_X = var_set[features]\n",
    "    var_set_y = var_set['target']\n",
    "    \n",
    "    return train_set_X, train_set_y, test, test_set, var_set_X, var_set_y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['id', 'd', 'target', 'date', 'wm_yr_wk', 'is_event', 'lag_t28', 'lag_t29',\n",
    "       'lag_t30', 'lag_t24', 'lag_t25', 'lag_t26', 'lag_t27']\n",
    "\n",
    "train_set_X, train_set_y, test, test_set, var_set_X, var_set_y = make_train_test_set(all_df17_20, drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df17_20[all_df17_20.store_id == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 KFold - LGBM 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_model(data, drop_cols):\n",
    "    train_set_X, train_set_y, test, test_set, var_set_X, var_set_y = make_train_test_set(data, drop_cols)\n",
    "    n_fold = 5\n",
    "    folds = KFold(n_splits=n_fold, shuffle=True, random_state=333)\n",
    "    splits = folds.split(train_set_X, train_set_y)\n",
    "\n",
    "    y_preds = np.zeros(test_set.shape[0])\n",
    "    y_oof = np.zeros(train_set_X.shape[0])\n",
    "\n",
    "    feature_importances = pd.DataFrame()\n",
    "    feature_importances['feature'] = train_set_X.columns\n",
    "    mean_score = []\n",
    "\n",
    "\n",
    "    for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "        print('Fold:',fold_n+1)\n",
    "\n",
    "        X_train, X_valid = train_set_X.iloc[train_index], train_set_X.iloc[valid_index]\n",
    "        y_train, y_valid = train_set_y.iloc[train_index], train_set_y.iloc[valid_index]\n",
    "\n",
    "        lgb = LGBMRegressor(\n",
    "            boosting_type = 'gbdt',\n",
    "            num_leaves = 2048,\n",
    "            colsample_bytree = 0.8,\n",
    "            subsample = 0.8,\n",
    "            n_estimators = 300, ## 중요!!!!\n",
    "            learning_rate = 0.1,\n",
    "            n_jobs = -1,\n",
    "            device = 'gpu',\n",
    "            random_state=333\n",
    "        )\n",
    "        lgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], early_stopping_rounds = 20, verbose = True)\n",
    "\n",
    "        feature_importances[f'fold_{fold_n + 1}'] = lgb.feature_importances_\n",
    "\n",
    "        y_pred_valid = lgb.predict(X_valid, num_iteration=lgb.best_iteration_)\n",
    "\n",
    "        y_oof[valid_index] = y_pred_valid\n",
    "\n",
    "        # validation 측정\n",
    "        val_score = np.sqrt(metrics.mean_squared_error(y_pred_valid, y_valid))\n",
    "        print(f'val rmse score is {val_score}')\n",
    "        mean_score.append(val_score)\n",
    "\n",
    "        all_pred = lgb.predict(var_set_X, num_iteration=lgb.best_iteration_)\n",
    "        all_var_score = np.sqrt(metrics.mean_squared_error(all_pred, var_set_y))\n",
    "        print(f'2015-04-27 부터 2015-05-22까지 데이터로 validation rmse 결과: {all_var_score}')\n",
    "\n",
    "\n",
    "        # 예측\n",
    "        y_preds += lgb.predict(test_set, num_iteration=lgb.best_iteration_) / n_fold\n",
    "\n",
    "        # 메모리 정리\n",
    "        del X_train, X_valid, y_train, y_valid\n",
    "\n",
    "    features = train_set_X.columns\n",
    "    params = lgb.get_params()\n",
    "    eval_results = lgb.evals_result_['valid_0']['l2']\n",
    "\n",
    "    print('mean rmse score over folds is',np.mean(mean_score))\n",
    "    test['sales'] = y_preds\n",
    "    write_params_features(features, params, eval_results)\n",
    "    save_feature_importance(feature_importances)\n",
    "    \n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'item_id', 'dept_id', 'store_id', 'state_id', 'weekday', 'month',\n",
      "       'year', 'event_name_1', 'snap_CA', 'snap_TX', 'snap_WI', 'day', 'week',\n",
      "       'sell_price', 'lag_t28', 'lag_t29', 'lag_t30', 'lag_t31',\n",
      "       'rolling_mean_t7', 'rolling_std_t7', 'rolling_mean_t28',\n",
      "       'rolling_std_t28', 'rolling_mean_t56', 'rolling_std_t56',\n",
      "       'rolling_mean_t84', 'rolling_std_t84', 'rolling_mean_t168',\n",
      "       'rolling_std_t168', 'price_change_t365', 'rolling_price_std_t7',\n",
      "       'rolling_price_std_t28', 'rolling_price_max_t365',\n",
      "       'item_id_gb_sell_price', 'item_id_gb_lag28', 'diff'],\n",
      "      dtype='object')\n",
      "Fold: 1\n",
      "[1]\tvalid_0's l2: 11.4508\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.0644\n",
      "[3]\tvalid_0's l2: 8.93787\n",
      "[4]\tvalid_0's l2: 8.08352\n",
      "[5]\tvalid_0's l2: 7.32279\n",
      "[6]\tvalid_0's l2: 6.76024\n",
      "[7]\tvalid_0's l2: 6.24948\n",
      "[8]\tvalid_0's l2: 5.83694\n",
      "[9]\tvalid_0's l2: 5.49328\n",
      "[10]\tvalid_0's l2: 5.21453\n",
      "[11]\tvalid_0's l2: 5.00862\n",
      "[12]\tvalid_0's l2: 4.81824\n",
      "[13]\tvalid_0's l2: 4.64706\n",
      "[14]\tvalid_0's l2: 4.52\n",
      "[15]\tvalid_0's l2: 4.41576\n",
      "[16]\tvalid_0's l2: 4.32618\n",
      "[17]\tvalid_0's l2: 4.25575\n",
      "[18]\tvalid_0's l2: 4.18847\n",
      "[19]\tvalid_0's l2: 4.13949\n",
      "[20]\tvalid_0's l2: 4.09451\n",
      "[21]\tvalid_0's l2: 4.06148\n",
      "[22]\tvalid_0's l2: 4.03342\n",
      "[23]\tvalid_0's l2: 4.00541\n",
      "[24]\tvalid_0's l2: 3.98037\n",
      "[25]\tvalid_0's l2: 3.96218\n",
      "[26]\tvalid_0's l2: 3.94232\n",
      "[27]\tvalid_0's l2: 3.92947\n",
      "[28]\tvalid_0's l2: 3.91728\n",
      "[29]\tvalid_0's l2: 3.90722\n",
      "[30]\tvalid_0's l2: 3.89611\n",
      "[31]\tvalid_0's l2: 3.88031\n",
      "[32]\tvalid_0's l2: 3.86788\n",
      "[33]\tvalid_0's l2: 3.85667\n",
      "[34]\tvalid_0's l2: 3.84687\n",
      "[35]\tvalid_0's l2: 3.83581\n",
      "[36]\tvalid_0's l2: 3.82853\n",
      "[37]\tvalid_0's l2: 3.82055\n",
      "[38]\tvalid_0's l2: 3.81235\n",
      "[39]\tvalid_0's l2: 3.80548\n",
      "[40]\tvalid_0's l2: 3.80057\n",
      "[41]\tvalid_0's l2: 3.79512\n",
      "[42]\tvalid_0's l2: 3.79035\n",
      "[43]\tvalid_0's l2: 3.7857\n",
      "[44]\tvalid_0's l2: 3.77988\n",
      "[45]\tvalid_0's l2: 3.7759\n",
      "[46]\tvalid_0's l2: 3.7724\n",
      "[47]\tvalid_0's l2: 3.76597\n",
      "[48]\tvalid_0's l2: 3.76074\n",
      "[49]\tvalid_0's l2: 3.75481\n",
      "[50]\tvalid_0's l2: 3.74833\n",
      "[51]\tvalid_0's l2: 3.7447\n",
      "[52]\tvalid_0's l2: 3.74278\n",
      "[53]\tvalid_0's l2: 3.73996\n",
      "[54]\tvalid_0's l2: 3.73753\n",
      "[55]\tvalid_0's l2: 3.73699\n",
      "[56]\tvalid_0's l2: 3.73329\n",
      "[57]\tvalid_0's l2: 3.72875\n",
      "[58]\tvalid_0's l2: 3.72295\n",
      "[59]\tvalid_0's l2: 3.7208\n",
      "[60]\tvalid_0's l2: 3.71556\n",
      "[61]\tvalid_0's l2: 3.71069\n",
      "[62]\tvalid_0's l2: 3.70776\n",
      "[63]\tvalid_0's l2: 3.70446\n",
      "[64]\tvalid_0's l2: 3.70342\n",
      "[65]\tvalid_0's l2: 3.70227\n",
      "[66]\tvalid_0's l2: 3.70014\n",
      "[67]\tvalid_0's l2: 3.69658\n",
      "[68]\tvalid_0's l2: 3.69259\n",
      "[69]\tvalid_0's l2: 3.68981\n",
      "[70]\tvalid_0's l2: 3.68808\n",
      "[71]\tvalid_0's l2: 3.68364\n",
      "[72]\tvalid_0's l2: 3.68232\n",
      "[73]\tvalid_0's l2: 3.68145\n",
      "[74]\tvalid_0's l2: 3.67953\n",
      "[75]\tvalid_0's l2: 3.67881\n",
      "[76]\tvalid_0's l2: 3.67563\n",
      "[77]\tvalid_0's l2: 3.67536\n",
      "[78]\tvalid_0's l2: 3.67309\n",
      "[79]\tvalid_0's l2: 3.67192\n",
      "[80]\tvalid_0's l2: 3.66997\n",
      "[81]\tvalid_0's l2: 3.67023\n",
      "[82]\tvalid_0's l2: 3.66958\n",
      "[83]\tvalid_0's l2: 3.66866\n",
      "[84]\tvalid_0's l2: 3.66759\n",
      "[85]\tvalid_0's l2: 3.66624\n",
      "[86]\tvalid_0's l2: 3.66607\n",
      "[87]\tvalid_0's l2: 3.66605\n",
      "[88]\tvalid_0's l2: 3.66425\n",
      "[89]\tvalid_0's l2: 3.66439\n",
      "[90]\tvalid_0's l2: 3.66414\n",
      "[91]\tvalid_0's l2: 3.66286\n",
      "[92]\tvalid_0's l2: 3.66255\n",
      "[93]\tvalid_0's l2: 3.66092\n",
      "[94]\tvalid_0's l2: 3.65982\n",
      "[95]\tvalid_0's l2: 3.66019\n",
      "[96]\tvalid_0's l2: 3.66066\n",
      "[97]\tvalid_0's l2: 3.66059\n",
      "[98]\tvalid_0's l2: 3.66027\n",
      "[99]\tvalid_0's l2: 3.65974\n",
      "[100]\tvalid_0's l2: 3.65958\n",
      "[101]\tvalid_0's l2: 3.65998\n",
      "[102]\tvalid_0's l2: 3.65881\n",
      "[103]\tvalid_0's l2: 3.65652\n",
      "[104]\tvalid_0's l2: 3.65673\n",
      "[105]\tvalid_0's l2: 3.65721\n",
      "[106]\tvalid_0's l2: 3.65647\n",
      "[107]\tvalid_0's l2: 3.65685\n",
      "[108]\tvalid_0's l2: 3.6561\n",
      "[109]\tvalid_0's l2: 3.65573\n",
      "[110]\tvalid_0's l2: 3.65485\n",
      "[111]\tvalid_0's l2: 3.65517\n",
      "[112]\tvalid_0's l2: 3.65572\n",
      "[113]\tvalid_0's l2: 3.65472\n",
      "[114]\tvalid_0's l2: 3.65437\n",
      "[115]\tvalid_0's l2: 3.65487\n",
      "[116]\tvalid_0's l2: 3.65447\n",
      "[117]\tvalid_0's l2: 3.65532\n",
      "[118]\tvalid_0's l2: 3.65462\n",
      "[119]\tvalid_0's l2: 3.65438\n",
      "[120]\tvalid_0's l2: 3.65445\n",
      "[121]\tvalid_0's l2: 3.65495\n",
      "[122]\tvalid_0's l2: 3.65433\n",
      "[123]\tvalid_0's l2: 3.65494\n",
      "[124]\tvalid_0's l2: 3.65537\n",
      "[125]\tvalid_0's l2: 3.65497\n",
      "[126]\tvalid_0's l2: 3.65522\n",
      "[127]\tvalid_0's l2: 3.65553\n",
      "[128]\tvalid_0's l2: 3.6559\n",
      "[129]\tvalid_0's l2: 3.65543\n",
      "[130]\tvalid_0's l2: 3.65517\n",
      "[131]\tvalid_0's l2: 3.65563\n",
      "[132]\tvalid_0's l2: 3.6558\n",
      "[133]\tvalid_0's l2: 3.65558\n",
      "[134]\tvalid_0's l2: 3.65616\n",
      "[135]\tvalid_0's l2: 3.65663\n",
      "[136]\tvalid_0's l2: 3.65652\n",
      "[137]\tvalid_0's l2: 3.65516\n",
      "[138]\tvalid_0's l2: 3.65545\n",
      "[139]\tvalid_0's l2: 3.65588\n",
      "[140]\tvalid_0's l2: 3.65531\n",
      "[141]\tvalid_0's l2: 3.65591\n",
      "[142]\tvalid_0's l2: 3.65578\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's l2: 3.65433\n",
      "val rmse score is 1.9116298195516142\n",
      "2015-04-27 부터 2015-05-22까지 데이터로 validation rmse 결과: 1.4620565141834345\n",
      "Fold: 2\n",
      "[1]\tvalid_0's l2: 12.1373\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.7089\n",
      "[3]\tvalid_0's l2: 9.5416\n",
      "[4]\tvalid_0's l2: 8.65615\n",
      "[5]\tvalid_0's l2: 7.87189\n",
      "[6]\tvalid_0's l2: 7.28675\n",
      "[7]\tvalid_0's l2: 6.75581\n",
      "[8]\tvalid_0's l2: 6.3245\n",
      "[9]\tvalid_0's l2: 5.96909\n",
      "[10]\tvalid_0's l2: 5.67618\n",
      "[11]\tvalid_0's l2: 5.4568\n",
      "[12]\tvalid_0's l2: 5.2576\n",
      "[13]\tvalid_0's l2: 5.08028\n",
      "[14]\tvalid_0's l2: 4.94621\n",
      "[15]\tvalid_0's l2: 4.8387\n",
      "[16]\tvalid_0's l2: 4.74602\n",
      "[17]\tvalid_0's l2: 4.67034\n",
      "[18]\tvalid_0's l2: 4.59596\n",
      "[19]\tvalid_0's l2: 4.54619\n",
      "[20]\tvalid_0's l2: 4.5009\n",
      "[21]\tvalid_0's l2: 4.4645\n",
      "[22]\tvalid_0's l2: 4.43176\n",
      "[23]\tvalid_0's l2: 4.40205\n",
      "[24]\tvalid_0's l2: 4.3759\n",
      "[25]\tvalid_0's l2: 4.35678\n",
      "[26]\tvalid_0's l2: 4.33475\n",
      "[27]\tvalid_0's l2: 4.31719\n",
      "[28]\tvalid_0's l2: 4.29743\n",
      "[29]\tvalid_0's l2: 4.28702\n",
      "[30]\tvalid_0's l2: 4.27786\n",
      "[31]\tvalid_0's l2: 4.26367\n",
      "[32]\tvalid_0's l2: 4.25188\n",
      "[33]\tvalid_0's l2: 4.23969\n",
      "[34]\tvalid_0's l2: 4.22985\n",
      "[35]\tvalid_0's l2: 4.21918\n",
      "[36]\tvalid_0's l2: 4.21093\n",
      "[37]\tvalid_0's l2: 4.20438\n",
      "[38]\tvalid_0's l2: 4.19739\n",
      "[39]\tvalid_0's l2: 4.18747\n",
      "[40]\tvalid_0's l2: 4.17833\n",
      "[41]\tvalid_0's l2: 4.17117\n",
      "[42]\tvalid_0's l2: 4.16864\n",
      "[43]\tvalid_0's l2: 4.16456\n",
      "[44]\tvalid_0's l2: 4.15965\n",
      "[45]\tvalid_0's l2: 4.15702\n",
      "[46]\tvalid_0's l2: 4.1536\n",
      "[47]\tvalid_0's l2: 4.14693\n",
      "[48]\tvalid_0's l2: 4.14276\n",
      "[49]\tvalid_0's l2: 4.13892\n",
      "[50]\tvalid_0's l2: 4.137\n",
      "[51]\tvalid_0's l2: 4.13172\n",
      "[52]\tvalid_0's l2: 4.13045\n",
      "[53]\tvalid_0's l2: 4.128\n",
      "[54]\tvalid_0's l2: 4.12425\n",
      "[55]\tvalid_0's l2: 4.12238\n",
      "[56]\tvalid_0's l2: 4.11955\n",
      "[57]\tvalid_0's l2: 4.11839\n",
      "[58]\tvalid_0's l2: 4.11622\n",
      "[59]\tvalid_0's l2: 4.11308\n",
      "[60]\tvalid_0's l2: 4.10788\n",
      "[61]\tvalid_0's l2: 4.10455\n",
      "[62]\tvalid_0's l2: 4.10093\n",
      "[63]\tvalid_0's l2: 4.09904\n",
      "[64]\tvalid_0's l2: 4.09846\n",
      "[65]\tvalid_0's l2: 4.09683\n",
      "[66]\tvalid_0's l2: 4.09185\n",
      "[67]\tvalid_0's l2: 4.08954\n",
      "[68]\tvalid_0's l2: 4.08795\n",
      "[69]\tvalid_0's l2: 4.08481\n",
      "[70]\tvalid_0's l2: 4.08429\n",
      "[71]\tvalid_0's l2: 4.07929\n",
      "[72]\tvalid_0's l2: 4.07772\n",
      "[73]\tvalid_0's l2: 4.07363\n",
      "[74]\tvalid_0's l2: 4.06967\n",
      "[75]\tvalid_0's l2: 4.06766\n",
      "[76]\tvalid_0's l2: 4.06661\n",
      "[77]\tvalid_0's l2: 4.06715\n",
      "[78]\tvalid_0's l2: 4.06401\n",
      "[79]\tvalid_0's l2: 4.06497\n",
      "[80]\tvalid_0's l2: 4.06427\n",
      "[81]\tvalid_0's l2: 4.06391\n",
      "[82]\tvalid_0's l2: 4.06334\n",
      "[83]\tvalid_0's l2: 4.0628\n",
      "[84]\tvalid_0's l2: 4.06199\n",
      "[85]\tvalid_0's l2: 4.05947\n",
      "[86]\tvalid_0's l2: 4.05988\n",
      "[87]\tvalid_0's l2: 4.0597\n",
      "[88]\tvalid_0's l2: 4.05918\n",
      "[89]\tvalid_0's l2: 4.05777\n",
      "[90]\tvalid_0's l2: 4.05749\n",
      "[91]\tvalid_0's l2: 4.0568\n",
      "[92]\tvalid_0's l2: 4.05684\n",
      "[93]\tvalid_0's l2: 4.05537\n",
      "[94]\tvalid_0's l2: 4.05495\n",
      "[95]\tvalid_0's l2: 4.05518\n",
      "[96]\tvalid_0's l2: 4.05484\n",
      "[97]\tvalid_0's l2: 4.05363\n",
      "[98]\tvalid_0's l2: 4.05241\n",
      "[99]\tvalid_0's l2: 4.05128\n",
      "[100]\tvalid_0's l2: 4.05072\n",
      "[101]\tvalid_0's l2: 4.0511\n",
      "[102]\tvalid_0's l2: 4.05\n",
      "[103]\tvalid_0's l2: 4.04909\n",
      "[104]\tvalid_0's l2: 4.04936\n",
      "[105]\tvalid_0's l2: 4.04923\n",
      "[106]\tvalid_0's l2: 4.04978\n",
      "[107]\tvalid_0's l2: 4.04969\n",
      "[108]\tvalid_0's l2: 4.04945\n",
      "[109]\tvalid_0's l2: 4.04888\n",
      "[110]\tvalid_0's l2: 4.04869\n",
      "[111]\tvalid_0's l2: 4.04846\n",
      "[112]\tvalid_0's l2: 4.04849\n",
      "[113]\tvalid_0's l2: 4.04841\n",
      "[114]\tvalid_0's l2: 4.04751\n",
      "[115]\tvalid_0's l2: 4.04678\n",
      "[116]\tvalid_0's l2: 4.04555\n",
      "[117]\tvalid_0's l2: 4.04591\n",
      "[118]\tvalid_0's l2: 4.0461\n",
      "[119]\tvalid_0's l2: 4.04566\n",
      "[120]\tvalid_0's l2: 4.04457\n",
      "[121]\tvalid_0's l2: 4.04371\n",
      "[122]\tvalid_0's l2: 4.04431\n",
      "[123]\tvalid_0's l2: 4.04505\n",
      "[124]\tvalid_0's l2: 4.04535\n",
      "[125]\tvalid_0's l2: 4.04433\n",
      "[126]\tvalid_0's l2: 4.04384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[127]\tvalid_0's l2: 4.04351\n",
      "[128]\tvalid_0's l2: 4.04384\n",
      "[129]\tvalid_0's l2: 4.04436\n",
      "[130]\tvalid_0's l2: 4.04328\n",
      "[131]\tvalid_0's l2: 4.04065\n",
      "[132]\tvalid_0's l2: 4.04061\n",
      "[133]\tvalid_0's l2: 4.04033\n",
      "[134]\tvalid_0's l2: 4.0406\n",
      "[135]\tvalid_0's l2: 4.04042\n",
      "[136]\tvalid_0's l2: 4.03997\n",
      "[137]\tvalid_0's l2: 4.04009\n",
      "[138]\tvalid_0's l2: 4.03992\n",
      "[139]\tvalid_0's l2: 4.03974\n",
      "[140]\tvalid_0's l2: 4.04029\n",
      "[141]\tvalid_0's l2: 4.0398\n",
      "[142]\tvalid_0's l2: 4.0398\n",
      "[143]\tvalid_0's l2: 4.03945\n",
      "[144]\tvalid_0's l2: 4.03916\n",
      "[145]\tvalid_0's l2: 4.03882\n",
      "[146]\tvalid_0's l2: 4.03891\n",
      "[147]\tvalid_0's l2: 4.03892\n",
      "[148]\tvalid_0's l2: 4.03909\n",
      "[149]\tvalid_0's l2: 4.03912\n",
      "[150]\tvalid_0's l2: 4.03886\n",
      "[151]\tvalid_0's l2: 4.03856\n",
      "[152]\tvalid_0's l2: 4.03855\n",
      "[153]\tvalid_0's l2: 4.03846\n",
      "[154]\tvalid_0's l2: 4.03862\n",
      "[155]\tvalid_0's l2: 4.03818\n",
      "[156]\tvalid_0's l2: 4.03767\n",
      "[157]\tvalid_0's l2: 4.03756\n",
      "[158]\tvalid_0's l2: 4.03771\n",
      "[159]\tvalid_0's l2: 4.03716\n",
      "[160]\tvalid_0's l2: 4.03752\n",
      "[161]\tvalid_0's l2: 4.03754\n",
      "[162]\tvalid_0's l2: 4.03727\n",
      "[163]\tvalid_0's l2: 4.03697\n",
      "[164]\tvalid_0's l2: 4.03733\n",
      "[165]\tvalid_0's l2: 4.03744\n",
      "[166]\tvalid_0's l2: 4.0373\n",
      "[167]\tvalid_0's l2: 4.03706\n",
      "[168]\tvalid_0's l2: 4.03717\n",
      "[169]\tvalid_0's l2: 4.03777\n",
      "[170]\tvalid_0's l2: 4.03734\n",
      "[171]\tvalid_0's l2: 4.03739\n",
      "[172]\tvalid_0's l2: 4.03737\n",
      "[173]\tvalid_0's l2: 4.0371\n",
      "[174]\tvalid_0's l2: 4.03702\n",
      "[175]\tvalid_0's l2: 4.03658\n",
      "[176]\tvalid_0's l2: 4.03646\n",
      "[177]\tvalid_0's l2: 4.0362\n",
      "[178]\tvalid_0's l2: 4.03595\n",
      "[179]\tvalid_0's l2: 4.03631\n",
      "[180]\tvalid_0's l2: 4.03671\n",
      "[181]\tvalid_0's l2: 4.03595\n",
      "[182]\tvalid_0's l2: 4.03574\n",
      "[183]\tvalid_0's l2: 4.03543\n",
      "[184]\tvalid_0's l2: 4.03521\n",
      "[185]\tvalid_0's l2: 4.03505\n",
      "[186]\tvalid_0's l2: 4.03531\n",
      "[187]\tvalid_0's l2: 4.03549\n",
      "[188]\tvalid_0's l2: 4.03561\n",
      "[189]\tvalid_0's l2: 4.03557\n",
      "[190]\tvalid_0's l2: 4.03595\n",
      "[191]\tvalid_0's l2: 4.0359\n",
      "[192]\tvalid_0's l2: 4.03579\n",
      "[193]\tvalid_0's l2: 4.03579\n",
      "[194]\tvalid_0's l2: 4.03603\n",
      "[195]\tvalid_0's l2: 4.03615\n",
      "[196]\tvalid_0's l2: 4.03621\n",
      "[197]\tvalid_0's l2: 4.03598\n",
      "[198]\tvalid_0's l2: 4.03619\n",
      "[199]\tvalid_0's l2: 4.03653\n",
      "[200]\tvalid_0's l2: 4.03693\n",
      "[201]\tvalid_0's l2: 4.03662\n",
      "[202]\tvalid_0's l2: 4.03634\n",
      "[203]\tvalid_0's l2: 4.03632\n",
      "[204]\tvalid_0's l2: 4.03635\n",
      "[205]\tvalid_0's l2: 4.03638\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid_0's l2: 4.03505\n",
      "val rmse score is 2.008743902930001\n",
      "2015-04-27 부터 2015-05-22까지 데이터로 validation rmse 결과: 1.4078788737347478\n",
      "Fold: 3\n",
      "[1]\tvalid_0's l2: 11.7017\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.2706\n",
      "[3]\tvalid_0's l2: 9.109\n",
      "[4]\tvalid_0's l2: 8.22635\n",
      "[5]\tvalid_0's l2: 7.44393\n",
      "[6]\tvalid_0's l2: 6.8532\n",
      "[7]\tvalid_0's l2: 6.32764\n",
      "[8]\tvalid_0's l2: 5.90051\n",
      "[9]\tvalid_0's l2: 5.55123\n",
      "[10]\tvalid_0's l2: 5.2625\n",
      "[11]\tvalid_0's l2: 5.04524\n",
      "[12]\tvalid_0's l2: 4.85163\n",
      "[13]\tvalid_0's l2: 4.68135\n",
      "[14]\tvalid_0's l2: 4.55019\n",
      "[15]\tvalid_0's l2: 4.44334\n",
      "[16]\tvalid_0's l2: 4.35534\n",
      "[17]\tvalid_0's l2: 4.28347\n",
      "[18]\tvalid_0's l2: 4.21082\n",
      "[19]\tvalid_0's l2: 4.16345\n",
      "[20]\tvalid_0's l2: 4.12144\n",
      "[21]\tvalid_0's l2: 4.08729\n",
      "[22]\tvalid_0's l2: 4.05805\n",
      "[23]\tvalid_0's l2: 4.02846\n",
      "[24]\tvalid_0's l2: 4.00452\n",
      "[25]\tvalid_0's l2: 3.98608\n",
      "[26]\tvalid_0's l2: 3.97088\n",
      "[27]\tvalid_0's l2: 3.95298\n",
      "[28]\tvalid_0's l2: 3.93805\n",
      "[29]\tvalid_0's l2: 3.92721\n",
      "[30]\tvalid_0's l2: 3.91958\n",
      "[31]\tvalid_0's l2: 3.90428\n",
      "[32]\tvalid_0's l2: 3.8937\n",
      "[33]\tvalid_0's l2: 3.88603\n",
      "[34]\tvalid_0's l2: 3.87759\n",
      "[35]\tvalid_0's l2: 3.86991\n",
      "[36]\tvalid_0's l2: 3.86014\n",
      "[37]\tvalid_0's l2: 3.8533\n",
      "[38]\tvalid_0's l2: 3.84702\n",
      "[39]\tvalid_0's l2: 3.83943\n",
      "[40]\tvalid_0's l2: 3.8359\n",
      "[41]\tvalid_0's l2: 3.82887\n",
      "[42]\tvalid_0's l2: 3.82391\n",
      "[43]\tvalid_0's l2: 3.82106\n",
      "[44]\tvalid_0's l2: 3.81804\n",
      "[45]\tvalid_0's l2: 3.81581\n",
      "[46]\tvalid_0's l2: 3.81328\n",
      "[47]\tvalid_0's l2: 3.80921\n",
      "[48]\tvalid_0's l2: 3.80686\n",
      "[49]\tvalid_0's l2: 3.80001\n",
      "[50]\tvalid_0's l2: 3.79385\n",
      "[51]\tvalid_0's l2: 3.79142\n",
      "[52]\tvalid_0's l2: 3.78775\n",
      "[53]\tvalid_0's l2: 3.78324\n",
      "[54]\tvalid_0's l2: 3.77903\n",
      "[55]\tvalid_0's l2: 3.77679\n",
      "[56]\tvalid_0's l2: 3.77297\n",
      "[57]\tvalid_0's l2: 3.77093\n",
      "[58]\tvalid_0's l2: 3.76616\n",
      "[59]\tvalid_0's l2: 3.76395\n",
      "[60]\tvalid_0's l2: 3.76232\n",
      "[61]\tvalid_0's l2: 3.76181\n",
      "[62]\tvalid_0's l2: 3.76055\n",
      "[63]\tvalid_0's l2: 3.75726\n",
      "[64]\tvalid_0's l2: 3.75666\n",
      "[65]\tvalid_0's l2: 3.75537\n",
      "[66]\tvalid_0's l2: 3.75044\n",
      "[67]\tvalid_0's l2: 3.74975\n",
      "[68]\tvalid_0's l2: 3.74705\n",
      "[69]\tvalid_0's l2: 3.74286\n",
      "[70]\tvalid_0's l2: 3.74053\n",
      "[71]\tvalid_0's l2: 3.7361\n",
      "[72]\tvalid_0's l2: 3.73367\n",
      "[73]\tvalid_0's l2: 3.7328\n",
      "[74]\tvalid_0's l2: 3.73001\n",
      "[75]\tvalid_0's l2: 3.72796\n",
      "[76]\tvalid_0's l2: 3.72567\n",
      "[77]\tvalid_0's l2: 3.72552\n",
      "[78]\tvalid_0's l2: 3.72285\n",
      "[79]\tvalid_0's l2: 3.7214\n",
      "[80]\tvalid_0's l2: 3.72178\n",
      "[81]\tvalid_0's l2: 3.72182\n",
      "[82]\tvalid_0's l2: 3.72098\n",
      "[83]\tvalid_0's l2: 3.72003\n",
      "[84]\tvalid_0's l2: 3.71887\n",
      "[85]\tvalid_0's l2: 3.7179\n",
      "[86]\tvalid_0's l2: 3.71643\n",
      "[87]\tvalid_0's l2: 3.71552\n",
      "[88]\tvalid_0's l2: 3.71607\n",
      "[89]\tvalid_0's l2: 3.71609\n",
      "[90]\tvalid_0's l2: 3.71592\n",
      "[91]\tvalid_0's l2: 3.71562\n",
      "[92]\tvalid_0's l2: 3.71524\n",
      "[93]\tvalid_0's l2: 3.71495\n",
      "[94]\tvalid_0's l2: 3.71282\n",
      "[95]\tvalid_0's l2: 3.71323\n",
      "[96]\tvalid_0's l2: 3.71308\n",
      "[97]\tvalid_0's l2: 3.71266\n",
      "[98]\tvalid_0's l2: 3.7127\n",
      "[99]\tvalid_0's l2: 3.71131\n",
      "[100]\tvalid_0's l2: 3.71122\n",
      "[101]\tvalid_0's l2: 3.71152\n",
      "[102]\tvalid_0's l2: 3.71139\n",
      "[103]\tvalid_0's l2: 3.71108\n",
      "[104]\tvalid_0's l2: 3.71026\n",
      "[105]\tvalid_0's l2: 3.71094\n",
      "[106]\tvalid_0's l2: 3.71072\n",
      "[107]\tvalid_0's l2: 3.71021\n",
      "[108]\tvalid_0's l2: 3.7098\n",
      "[109]\tvalid_0's l2: 3.70856\n",
      "[110]\tvalid_0's l2: 3.7088\n",
      "[111]\tvalid_0's l2: 3.70841\n",
      "[112]\tvalid_0's l2: 3.70909\n",
      "[113]\tvalid_0's l2: 3.70772\n",
      "[114]\tvalid_0's l2: 3.70768\n",
      "[115]\tvalid_0's l2: 3.70795\n",
      "[116]\tvalid_0's l2: 3.70788\n",
      "[117]\tvalid_0's l2: 3.7076\n",
      "[118]\tvalid_0's l2: 3.70733\n",
      "[119]\tvalid_0's l2: 3.70774\n",
      "[120]\tvalid_0's l2: 3.70725\n",
      "[121]\tvalid_0's l2: 3.70774\n",
      "[122]\tvalid_0's l2: 3.70696\n",
      "[123]\tvalid_0's l2: 3.70754\n",
      "[124]\tvalid_0's l2: 3.70761\n",
      "[125]\tvalid_0's l2: 3.70707\n",
      "[126]\tvalid_0's l2: 3.7071\n",
      "[127]\tvalid_0's l2: 3.70724\n",
      "[128]\tvalid_0's l2: 3.70746\n",
      "[129]\tvalid_0's l2: 3.7079\n",
      "[130]\tvalid_0's l2: 3.70813\n",
      "[131]\tvalid_0's l2: 3.70732\n",
      "[132]\tvalid_0's l2: 3.7074\n",
      "[133]\tvalid_0's l2: 3.70669\n",
      "[134]\tvalid_0's l2: 3.70697\n",
      "[135]\tvalid_0's l2: 3.70731\n",
      "[136]\tvalid_0's l2: 3.70735\n",
      "[137]\tvalid_0's l2: 3.70715\n",
      "[138]\tvalid_0's l2: 3.70775\n",
      "[139]\tvalid_0's l2: 3.70767\n",
      "[140]\tvalid_0's l2: 3.70744\n",
      "[141]\tvalid_0's l2: 3.70608\n",
      "[142]\tvalid_0's l2: 3.70584\n",
      "[143]\tvalid_0's l2: 3.70622\n",
      "[144]\tvalid_0's l2: 3.70648\n",
      "[145]\tvalid_0's l2: 3.70667\n",
      "[146]\tvalid_0's l2: 3.70681\n",
      "[147]\tvalid_0's l2: 3.70672\n",
      "[148]\tvalid_0's l2: 3.70671\n",
      "[149]\tvalid_0's l2: 3.70699\n",
      "[150]\tvalid_0's l2: 3.70671\n",
      "[151]\tvalid_0's l2: 3.70581\n",
      "[152]\tvalid_0's l2: 3.70527\n",
      "[153]\tvalid_0's l2: 3.70557\n",
      "[154]\tvalid_0's l2: 3.70657\n",
      "[155]\tvalid_0's l2: 3.70622\n",
      "[156]\tvalid_0's l2: 3.70696\n",
      "[157]\tvalid_0's l2: 3.70759\n",
      "[158]\tvalid_0's l2: 3.70805\n",
      "[159]\tvalid_0's l2: 3.70837\n",
      "[160]\tvalid_0's l2: 3.70911\n",
      "[161]\tvalid_0's l2: 3.70928\n",
      "[162]\tvalid_0's l2: 3.70946\n",
      "[163]\tvalid_0's l2: 3.70963\n",
      "[164]\tvalid_0's l2: 3.70982\n",
      "[165]\tvalid_0's l2: 3.71064\n",
      "[166]\tvalid_0's l2: 3.71071\n",
      "[167]\tvalid_0's l2: 3.71128\n",
      "[168]\tvalid_0's l2: 3.71131\n",
      "[169]\tvalid_0's l2: 3.71099\n",
      "[170]\tvalid_0's l2: 3.71089\n",
      "[171]\tvalid_0's l2: 3.7108\n",
      "[172]\tvalid_0's l2: 3.71086\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's l2: 3.70527\n",
      "val rmse score is 1.9249074828307364\n",
      "2015-04-27 부터 2015-05-22까지 데이터로 validation rmse 결과: 1.4606638089040471\n",
      "Fold: 4\n",
      "[1]\tvalid_0's l2: 11.8525\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4301\n",
      "[3]\tvalid_0's l2: 9.27671\n",
      "[4]\tvalid_0's l2: 8.39395\n",
      "[5]\tvalid_0's l2: 7.61504\n",
      "[6]\tvalid_0's l2: 7.02957\n",
      "[7]\tvalid_0's l2: 6.50399\n",
      "[8]\tvalid_0's l2: 6.07375\n",
      "[9]\tvalid_0's l2: 5.72115\n",
      "[10]\tvalid_0's l2: 5.43519\n",
      "[11]\tvalid_0's l2: 5.21493\n",
      "[12]\tvalid_0's l2: 5.01899\n",
      "[13]\tvalid_0's l2: 4.84694\n",
      "[14]\tvalid_0's l2: 4.71687\n",
      "[15]\tvalid_0's l2: 4.6068\n",
      "[16]\tvalid_0's l2: 4.51732\n",
      "[17]\tvalid_0's l2: 4.4396\n",
      "[18]\tvalid_0's l2: 4.36752\n",
      "[19]\tvalid_0's l2: 4.31631\n",
      "[20]\tvalid_0's l2: 4.26909\n",
      "[21]\tvalid_0's l2: 4.23228\n",
      "[22]\tvalid_0's l2: 4.19833\n",
      "[23]\tvalid_0's l2: 4.16827\n",
      "[24]\tvalid_0's l2: 4.14296\n",
      "[25]\tvalid_0's l2: 4.1216\n",
      "[26]\tvalid_0's l2: 4.10026\n",
      "[27]\tvalid_0's l2: 4.0847\n",
      "[28]\tvalid_0's l2: 4.06901\n",
      "[29]\tvalid_0's l2: 4.05883\n",
      "[30]\tvalid_0's l2: 4.0505\n",
      "[31]\tvalid_0's l2: 4.03706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32]\tvalid_0's l2: 4.02625\n",
      "[33]\tvalid_0's l2: 4.0177\n",
      "[34]\tvalid_0's l2: 4.00847\n",
      "[35]\tvalid_0's l2: 3.99913\n",
      "[36]\tvalid_0's l2: 3.98916\n",
      "[37]\tvalid_0's l2: 3.98214\n",
      "[38]\tvalid_0's l2: 3.97414\n",
      "[39]\tvalid_0's l2: 3.96769\n",
      "[40]\tvalid_0's l2: 3.96127\n",
      "[41]\tvalid_0's l2: 3.95609\n",
      "[42]\tvalid_0's l2: 3.95163\n",
      "[43]\tvalid_0's l2: 3.94907\n",
      "[44]\tvalid_0's l2: 3.94581\n",
      "[45]\tvalid_0's l2: 3.94131\n",
      "[46]\tvalid_0's l2: 3.93698\n",
      "[47]\tvalid_0's l2: 3.92972\n",
      "[48]\tvalid_0's l2: 3.92814\n",
      "[49]\tvalid_0's l2: 3.92209\n",
      "[50]\tvalid_0's l2: 3.91839\n",
      "[51]\tvalid_0's l2: 3.91501\n",
      "[52]\tvalid_0's l2: 3.91434\n",
      "[53]\tvalid_0's l2: 3.90762\n",
      "[54]\tvalid_0's l2: 3.90228\n",
      "[55]\tvalid_0's l2: 3.90042\n",
      "[56]\tvalid_0's l2: 3.89898\n",
      "[57]\tvalid_0's l2: 3.89711\n",
      "[58]\tvalid_0's l2: 3.89422\n",
      "[59]\tvalid_0's l2: 3.89207\n",
      "[60]\tvalid_0's l2: 3.88604\n",
      "[61]\tvalid_0's l2: 3.88293\n",
      "[62]\tvalid_0's l2: 3.88108\n",
      "[63]\tvalid_0's l2: 3.87845\n",
      "[64]\tvalid_0's l2: 3.87758\n",
      "[65]\tvalid_0's l2: 3.8771\n",
      "[66]\tvalid_0's l2: 3.87482\n",
      "[67]\tvalid_0's l2: 3.8741\n",
      "[68]\tvalid_0's l2: 3.87274\n",
      "[69]\tvalid_0's l2: 3.86779\n",
      "[70]\tvalid_0's l2: 3.86688\n",
      "[71]\tvalid_0's l2: 3.86461\n",
      "[72]\tvalid_0's l2: 3.86238\n",
      "[73]\tvalid_0's l2: 3.86054\n",
      "[74]\tvalid_0's l2: 3.85836\n",
      "[75]\tvalid_0's l2: 3.85583\n",
      "[76]\tvalid_0's l2: 3.85511\n",
      "[77]\tvalid_0's l2: 3.85352\n",
      "[78]\tvalid_0's l2: 3.8504\n",
      "[79]\tvalid_0's l2: 3.84987\n",
      "[80]\tvalid_0's l2: 3.84987\n",
      "[81]\tvalid_0's l2: 3.85003\n",
      "[82]\tvalid_0's l2: 3.84968\n",
      "[83]\tvalid_0's l2: 3.84837\n",
      "[84]\tvalid_0's l2: 3.84794\n",
      "[85]\tvalid_0's l2: 3.84666\n",
      "[86]\tvalid_0's l2: 3.84563\n",
      "[87]\tvalid_0's l2: 3.8449\n",
      "[88]\tvalid_0's l2: 3.84399\n",
      "[89]\tvalid_0's l2: 3.84242\n",
      "[90]\tvalid_0's l2: 3.8426\n",
      "[91]\tvalid_0's l2: 3.84223\n",
      "[92]\tvalid_0's l2: 3.84219\n",
      "[93]\tvalid_0's l2: 3.84198\n",
      "[94]\tvalid_0's l2: 3.84181\n",
      "[95]\tvalid_0's l2: 3.84131\n",
      "[96]\tvalid_0's l2: 3.84075\n",
      "[97]\tvalid_0's l2: 3.84012\n",
      "[98]\tvalid_0's l2: 3.84088\n",
      "[99]\tvalid_0's l2: 3.8347\n",
      "[100]\tvalid_0's l2: 3.83419\n",
      "[101]\tvalid_0's l2: 3.83249\n",
      "[102]\tvalid_0's l2: 3.83231\n",
      "[103]\tvalid_0's l2: 3.83106\n",
      "[104]\tvalid_0's l2: 3.83061\n",
      "[105]\tvalid_0's l2: 3.82964\n",
      "[106]\tvalid_0's l2: 3.82953\n",
      "[107]\tvalid_0's l2: 3.82915\n",
      "[108]\tvalid_0's l2: 3.82848\n",
      "[109]\tvalid_0's l2: 3.82755\n",
      "[110]\tvalid_0's l2: 3.82475\n",
      "[111]\tvalid_0's l2: 3.82479\n",
      "[112]\tvalid_0's l2: 3.82584\n",
      "[113]\tvalid_0's l2: 3.82624\n",
      "[114]\tvalid_0's l2: 3.82661\n",
      "[115]\tvalid_0's l2: 3.8268\n",
      "[116]\tvalid_0's l2: 3.82723\n",
      "[117]\tvalid_0's l2: 3.82701\n",
      "[118]\tvalid_0's l2: 3.82666\n",
      "[119]\tvalid_0's l2: 3.82624\n",
      "[120]\tvalid_0's l2: 3.827\n",
      "[121]\tvalid_0's l2: 3.82751\n",
      "[122]\tvalid_0's l2: 3.82728\n",
      "[123]\tvalid_0's l2: 3.82688\n",
      "[124]\tvalid_0's l2: 3.82713\n",
      "[125]\tvalid_0's l2: 3.82724\n",
      "[126]\tvalid_0's l2: 3.82716\n",
      "[127]\tvalid_0's l2: 3.82633\n",
      "[128]\tvalid_0's l2: 3.82692\n",
      "[129]\tvalid_0's l2: 3.8269\n",
      "[130]\tvalid_0's l2: 3.82729\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's l2: 3.82475\n",
      "val rmse score is 1.9556963196441517\n",
      "2015-04-27 부터 2015-05-22까지 데이터로 validation rmse 결과: 1.5039655081942656\n",
      "Fold: 5\n",
      "[1]\tvalid_0's l2: 11.8312\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[2]\tvalid_0's l2: 10.4148\n",
      "[3]\tvalid_0's l2: 9.26262\n",
      "[4]\tvalid_0's l2: 8.37469\n",
      "[5]\tvalid_0's l2: 7.5914\n",
      "[6]\tvalid_0's l2: 7.00142\n",
      "[7]\tvalid_0's l2: 6.47396\n",
      "[8]\tvalid_0's l2: 6.04542\n",
      "[9]\tvalid_0's l2: 5.69071\n",
      "[10]\tvalid_0's l2: 5.40135\n",
      "[11]\tvalid_0's l2: 5.18239\n",
      "[12]\tvalid_0's l2: 4.98392\n",
      "[13]\tvalid_0's l2: 4.80504\n",
      "[14]\tvalid_0's l2: 4.66773\n",
      "[15]\tvalid_0's l2: 4.55807\n",
      "[16]\tvalid_0's l2: 4.46345\n",
      "[17]\tvalid_0's l2: 4.38683\n",
      "[18]\tvalid_0's l2: 4.31497\n",
      "[19]\tvalid_0's l2: 4.26231\n",
      "[20]\tvalid_0's l2: 4.21617\n",
      "[21]\tvalid_0's l2: 4.17823\n",
      "[22]\tvalid_0's l2: 4.14409\n",
      "[23]\tvalid_0's l2: 4.11402\n",
      "[24]\tvalid_0's l2: 4.08763\n",
      "[25]\tvalid_0's l2: 4.06946\n",
      "[26]\tvalid_0's l2: 4.04775\n",
      "[27]\tvalid_0's l2: 4.03002\n",
      "[28]\tvalid_0's l2: 4.01323\n",
      "[29]\tvalid_0's l2: 4.00278\n",
      "[30]\tvalid_0's l2: 3.99247\n",
      "[31]\tvalid_0's l2: 3.97634\n",
      "[32]\tvalid_0's l2: 3.96507\n",
      "[33]\tvalid_0's l2: 3.9565\n",
      "[34]\tvalid_0's l2: 3.9505\n",
      "[35]\tvalid_0's l2: 3.94373\n",
      "[36]\tvalid_0's l2: 3.93725\n",
      "[37]\tvalid_0's l2: 3.92941\n",
      "[38]\tvalid_0's l2: 3.92143\n",
      "[39]\tvalid_0's l2: 3.91271\n",
      "[40]\tvalid_0's l2: 3.90894\n",
      "[41]\tvalid_0's l2: 3.90297\n",
      "[42]\tvalid_0's l2: 3.90019\n",
      "[43]\tvalid_0's l2: 3.89849\n",
      "[44]\tvalid_0's l2: 3.89554\n",
      "[45]\tvalid_0's l2: 3.89046\n",
      "[46]\tvalid_0's l2: 3.88718\n",
      "[47]\tvalid_0's l2: 3.88148\n",
      "[48]\tvalid_0's l2: 3.87804\n",
      "[49]\tvalid_0's l2: 3.87181\n",
      "[50]\tvalid_0's l2: 3.86721\n",
      "[51]\tvalid_0's l2: 3.86268\n",
      "[52]\tvalid_0's l2: 3.86066\n",
      "[53]\tvalid_0's l2: 3.85655\n",
      "[54]\tvalid_0's l2: 3.8535\n",
      "[55]\tvalid_0's l2: 3.85275\n",
      "[56]\tvalid_0's l2: 3.84948\n",
      "[57]\tvalid_0's l2: 3.84675\n",
      "[58]\tvalid_0's l2: 3.84483\n",
      "[59]\tvalid_0's l2: 3.84423\n",
      "[60]\tvalid_0's l2: 3.84013\n",
      "[61]\tvalid_0's l2: 3.83834\n",
      "[62]\tvalid_0's l2: 3.83806\n",
      "[63]\tvalid_0's l2: 3.83366\n",
      "[64]\tvalid_0's l2: 3.83277\n",
      "[65]\tvalid_0's l2: 3.83149\n",
      "[66]\tvalid_0's l2: 3.83016\n",
      "[67]\tvalid_0's l2: 3.82789\n",
      "[68]\tvalid_0's l2: 3.8274\n",
      "[69]\tvalid_0's l2: 3.82593\n",
      "[70]\tvalid_0's l2: 3.81919\n",
      "[71]\tvalid_0's l2: 3.81746\n",
      "[72]\tvalid_0's l2: 3.81542\n",
      "[73]\tvalid_0's l2: 3.81502\n",
      "[74]\tvalid_0's l2: 3.81374\n",
      "[75]\tvalid_0's l2: 3.81282\n",
      "[76]\tvalid_0's l2: 3.80938\n",
      "[77]\tvalid_0's l2: 3.80995\n",
      "[78]\tvalid_0's l2: 3.80612\n",
      "[79]\tvalid_0's l2: 3.80464\n",
      "[80]\tvalid_0's l2: 3.80429\n",
      "[81]\tvalid_0's l2: 3.80415\n",
      "[82]\tvalid_0's l2: 3.80449\n",
      "[83]\tvalid_0's l2: 3.80418\n",
      "[84]\tvalid_0's l2: 3.80338\n",
      "[85]\tvalid_0's l2: 3.80097\n",
      "[86]\tvalid_0's l2: 3.80077\n",
      "[87]\tvalid_0's l2: 3.8\n",
      "[88]\tvalid_0's l2: 3.79994\n",
      "[89]\tvalid_0's l2: 3.79931\n",
      "[90]\tvalid_0's l2: 3.79866\n",
      "[91]\tvalid_0's l2: 3.79904\n",
      "[92]\tvalid_0's l2: 3.79873\n",
      "[93]\tvalid_0's l2: 3.79611\n",
      "[94]\tvalid_0's l2: 3.79384\n",
      "[95]\tvalid_0's l2: 3.79309\n",
      "[96]\tvalid_0's l2: 3.79267\n",
      "[97]\tvalid_0's l2: 3.79198\n",
      "[98]\tvalid_0's l2: 3.79315\n",
      "[99]\tvalid_0's l2: 3.79246\n",
      "[100]\tvalid_0's l2: 3.79132\n",
      "[101]\tvalid_0's l2: 3.79091\n",
      "[102]\tvalid_0's l2: 3.79114\n",
      "[103]\tvalid_0's l2: 3.78877\n",
      "[104]\tvalid_0's l2: 3.78835\n",
      "[105]\tvalid_0's l2: 3.7881\n",
      "[106]\tvalid_0's l2: 3.78908\n",
      "[107]\tvalid_0's l2: 3.78842\n",
      "[108]\tvalid_0's l2: 3.78813\n",
      "[109]\tvalid_0's l2: 3.7875\n",
      "[110]\tvalid_0's l2: 3.78816\n",
      "[111]\tvalid_0's l2: 3.78765\n",
      "[112]\tvalid_0's l2: 3.78748\n",
      "[113]\tvalid_0's l2: 3.78776\n",
      "[114]\tvalid_0's l2: 3.78754\n",
      "[115]\tvalid_0's l2: 3.7878\n",
      "[116]\tvalid_0's l2: 3.78726\n",
      "[117]\tvalid_0's l2: 3.78772\n",
      "[118]\tvalid_0's l2: 3.7873\n",
      "[119]\tvalid_0's l2: 3.78674\n",
      "[120]\tvalid_0's l2: 3.78692\n",
      "[121]\tvalid_0's l2: 3.78661\n",
      "[122]\tvalid_0's l2: 3.78688\n",
      "[123]\tvalid_0's l2: 3.78676\n",
      "[124]\tvalid_0's l2: 3.78628\n",
      "[125]\tvalid_0's l2: 3.78685\n",
      "[126]\tvalid_0's l2: 3.78757\n",
      "[127]\tvalid_0's l2: 3.78801\n",
      "[128]\tvalid_0's l2: 3.78838\n",
      "[129]\tvalid_0's l2: 3.7891\n",
      "[130]\tvalid_0's l2: 3.78769\n",
      "[131]\tvalid_0's l2: 3.78754\n",
      "[132]\tvalid_0's l2: 3.78746\n",
      "[133]\tvalid_0's l2: 3.78636\n",
      "[134]\tvalid_0's l2: 3.78702\n",
      "[135]\tvalid_0's l2: 3.78727\n",
      "[136]\tvalid_0's l2: 3.78739\n",
      "[137]\tvalid_0's l2: 3.78736\n",
      "[138]\tvalid_0's l2: 3.78732\n",
      "[139]\tvalid_0's l2: 3.78763\n",
      "[140]\tvalid_0's l2: 3.78753\n",
      "[141]\tvalid_0's l2: 3.78771\n",
      "[142]\tvalid_0's l2: 3.78787\n",
      "[143]\tvalid_0's l2: 3.78836\n",
      "[144]\tvalid_0's l2: 3.78785\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's l2: 3.78628\n",
      "val rmse score is 1.9458363652957718\n",
      "2015-04-27 부터 2015-05-22까지 데이터로 validation rmse 결과: 1.473104495905042\n",
      "mean rmse score over folds is 1.949362778050455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kjb\\data_analysis\\10_estimate_sales_of_walmart_retail_goods\\venv\\lib\\site-packages\\ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold, shuffle=True)\n",
    "splits = folds.split(train_set_X, train_set_y)\n",
    "\n",
    "y_preds = np.zeros(test_set.shape[0])\n",
    "y_oof = np.zeros(train_set_X.shape[0])\n",
    "\n",
    "feature_importances = pd.DataFrame()\n",
    "feature_importances['feature'] = train_set_X.columns\n",
    "mean_score = []\n",
    "\n",
    "print(train_set_X.columns)\n",
    "\n",
    "for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "    print('Fold:',fold_n+1)\n",
    "    \n",
    "    X_train, X_valid = train_set_X.iloc[train_index], train_set_X.iloc[valid_index]\n",
    "    y_train, y_valid = train_set_y.iloc[train_index], train_set_y.iloc[valid_index]\n",
    "    \n",
    "    lgb = LGBMRegressor(\n",
    "        objective = 'regression',\n",
    "        boosting_type = 'gbdt',\n",
    "        num_leaves = 4096,\n",
    "        colsample_bytree = 0.8,\n",
    "        subsample = 0.8,\n",
    "        n_estimators = 400, ## 중요!!!!\n",
    "        learning_rate = 0.1,\n",
    "        n_jobs = -1,\n",
    "        device = 'gpu',\n",
    "        reg_lambda = 0.1\n",
    "    )\n",
    "    lgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], early_stopping_rounds = 20, verbose = True)\n",
    "\n",
    "    feature_importances[f'fold_{fold_n + 1}'] = lgb.feature_importances_\n",
    "    \n",
    "    y_pred_valid = lgb.predict(X_valid, num_iteration=lgb.best_iteration_)\n",
    "    \n",
    "    y_oof[valid_index] = y_pred_valid\n",
    "    \n",
    "    # validation 측정\n",
    "    val_score = np.sqrt(metrics.mean_squared_error(y_pred_valid, y_valid))\n",
    "    print(f'val rmse score is {val_score}')\n",
    "    mean_score.append(val_score)\n",
    "    \n",
    "    all_pred = lgb.predict(var_set_X, num_iteration=lgb.best_iteration_)\n",
    "    all_var_score = np.sqrt(metrics.mean_squared_error(all_pred, var_set_y))\n",
    "    print(f'2015-04-27 부터 2015-05-22까지 데이터로 validation rmse 결과: {all_var_score}')\n",
    "    \n",
    "    \n",
    "    # 예측\n",
    "    y_preds += lgb.predict(test_set, num_iteration=lgb.best_iteration_) / n_fold\n",
    "    \n",
    "    # 메모리 정리\n",
    "    del X_train, X_valid, y_train, y_valid\n",
    "\n",
    "    \n",
    "params = lgb.get_params()\n",
    "eval_results = lgb.evals_result_['valid_0']['l2']\n",
    "\n",
    "print('mean rmse score over folds is',np.mean(mean_score))\n",
    "test['sales'] = y_preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>fold_1</th>\n",
       "      <th>fold_2</th>\n",
       "      <th>fold_3</th>\n",
       "      <th>fold_4</th>\n",
       "      <th>fold_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>16812</td>\n",
       "      <td>26838</td>\n",
       "      <td>21421</td>\n",
       "      <td>15272</td>\n",
       "      <td>17485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_id</td>\n",
       "      <td>17834</td>\n",
       "      <td>24656</td>\n",
       "      <td>20783</td>\n",
       "      <td>15806</td>\n",
       "      <td>17837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dept_id</td>\n",
       "      <td>741</td>\n",
       "      <td>1071</td>\n",
       "      <td>890</td>\n",
       "      <td>696</td>\n",
       "      <td>757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>store_id</td>\n",
       "      <td>13331</td>\n",
       "      <td>20471</td>\n",
       "      <td>16574</td>\n",
       "      <td>11860</td>\n",
       "      <td>13157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>state_id</td>\n",
       "      <td>2657</td>\n",
       "      <td>3990</td>\n",
       "      <td>3287</td>\n",
       "      <td>2408</td>\n",
       "      <td>2582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weekday</td>\n",
       "      <td>12465</td>\n",
       "      <td>19496</td>\n",
       "      <td>16093</td>\n",
       "      <td>10702</td>\n",
       "      <td>12312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>month</td>\n",
       "      <td>2744</td>\n",
       "      <td>3445</td>\n",
       "      <td>3029</td>\n",
       "      <td>2449</td>\n",
       "      <td>2751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>year</td>\n",
       "      <td>7803</td>\n",
       "      <td>11455</td>\n",
       "      <td>9349</td>\n",
       "      <td>7100</td>\n",
       "      <td>7665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>event_name_1</td>\n",
       "      <td>1502</td>\n",
       "      <td>2391</td>\n",
       "      <td>1931</td>\n",
       "      <td>1344</td>\n",
       "      <td>1569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>snap_CA</td>\n",
       "      <td>1259</td>\n",
       "      <td>1769</td>\n",
       "      <td>1617</td>\n",
       "      <td>1297</td>\n",
       "      <td>1324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>snap_TX</td>\n",
       "      <td>2617</td>\n",
       "      <td>4015</td>\n",
       "      <td>3112</td>\n",
       "      <td>2186</td>\n",
       "      <td>2609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>snap_WI</td>\n",
       "      <td>2962</td>\n",
       "      <td>4322</td>\n",
       "      <td>3551</td>\n",
       "      <td>2783</td>\n",
       "      <td>2936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>day</td>\n",
       "      <td>23169</td>\n",
       "      <td>35389</td>\n",
       "      <td>28860</td>\n",
       "      <td>20353</td>\n",
       "      <td>23157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>week</td>\n",
       "      <td>12210</td>\n",
       "      <td>17766</td>\n",
       "      <td>14765</td>\n",
       "      <td>11485</td>\n",
       "      <td>12279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sell_price</td>\n",
       "      <td>12704</td>\n",
       "      <td>17524</td>\n",
       "      <td>14765</td>\n",
       "      <td>11485</td>\n",
       "      <td>12777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>lag_t28</td>\n",
       "      <td>22801</td>\n",
       "      <td>32847</td>\n",
       "      <td>28573</td>\n",
       "      <td>20606</td>\n",
       "      <td>23123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lag_t29</td>\n",
       "      <td>21076</td>\n",
       "      <td>33610</td>\n",
       "      <td>27582</td>\n",
       "      <td>19253</td>\n",
       "      <td>21610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>lag_t30</td>\n",
       "      <td>22471</td>\n",
       "      <td>32500</td>\n",
       "      <td>28111</td>\n",
       "      <td>20061</td>\n",
       "      <td>23232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>lag_t31</td>\n",
       "      <td>22190</td>\n",
       "      <td>31925</td>\n",
       "      <td>28090</td>\n",
       "      <td>20427</td>\n",
       "      <td>22791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rolling_mean_t7</td>\n",
       "      <td>27755</td>\n",
       "      <td>41707</td>\n",
       "      <td>34832</td>\n",
       "      <td>25383</td>\n",
       "      <td>28203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rolling_std_t7</td>\n",
       "      <td>33745</td>\n",
       "      <td>50210</td>\n",
       "      <td>41475</td>\n",
       "      <td>30217</td>\n",
       "      <td>34446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rolling_mean_t28</td>\n",
       "      <td>26714</td>\n",
       "      <td>39844</td>\n",
       "      <td>33582</td>\n",
       "      <td>23930</td>\n",
       "      <td>26997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>rolling_std_t28</td>\n",
       "      <td>19849</td>\n",
       "      <td>32561</td>\n",
       "      <td>25752</td>\n",
       "      <td>17604</td>\n",
       "      <td>20019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rolling_mean_t56</td>\n",
       "      <td>19944</td>\n",
       "      <td>32610</td>\n",
       "      <td>25730</td>\n",
       "      <td>18074</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rolling_std_t56</td>\n",
       "      <td>16216</td>\n",
       "      <td>25403</td>\n",
       "      <td>20035</td>\n",
       "      <td>15010</td>\n",
       "      <td>16376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rolling_mean_t84</td>\n",
       "      <td>19521</td>\n",
       "      <td>31282</td>\n",
       "      <td>24795</td>\n",
       "      <td>17481</td>\n",
       "      <td>19642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rolling_std_t84</td>\n",
       "      <td>13095</td>\n",
       "      <td>21884</td>\n",
       "      <td>16555</td>\n",
       "      <td>11575</td>\n",
       "      <td>13383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rolling_mean_t168</td>\n",
       "      <td>20242</td>\n",
       "      <td>31107</td>\n",
       "      <td>24828</td>\n",
       "      <td>18029</td>\n",
       "      <td>20694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rolling_std_t168</td>\n",
       "      <td>14263</td>\n",
       "      <td>23210</td>\n",
       "      <td>18018</td>\n",
       "      <td>13157</td>\n",
       "      <td>14585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>price_change_t365</td>\n",
       "      <td>7093</td>\n",
       "      <td>10120</td>\n",
       "      <td>8569</td>\n",
       "      <td>6523</td>\n",
       "      <td>7394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>rolling_price_std_t7</td>\n",
       "      <td>1508</td>\n",
       "      <td>2042</td>\n",
       "      <td>1669</td>\n",
       "      <td>1318</td>\n",
       "      <td>1561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>rolling_price_std_t28</td>\n",
       "      <td>4092</td>\n",
       "      <td>5762</td>\n",
       "      <td>5413</td>\n",
       "      <td>3804</td>\n",
       "      <td>4451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>rolling_price_max_t365</td>\n",
       "      <td>18692</td>\n",
       "      <td>26557</td>\n",
       "      <td>22039</td>\n",
       "      <td>17808</td>\n",
       "      <td>19634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>item_id_gb_sell_price</td>\n",
       "      <td>11863</td>\n",
       "      <td>17754</td>\n",
       "      <td>15039</td>\n",
       "      <td>10889</td>\n",
       "      <td>12219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>item_id_gb_lag28</td>\n",
       "      <td>20438</td>\n",
       "      <td>33438</td>\n",
       "      <td>25544</td>\n",
       "      <td>17341</td>\n",
       "      <td>20906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>diff</td>\n",
       "      <td>5212</td>\n",
       "      <td>6604</td>\n",
       "      <td>6182</td>\n",
       "      <td>4734</td>\n",
       "      <td>5317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature  fold_1  fold_2  fold_3  fold_4  fold_5\n",
       "0                       id   16812   26838   21421   15272   17485\n",
       "1                  item_id   17834   24656   20783   15806   17837\n",
       "2                  dept_id     741    1071     890     696     757\n",
       "3                 store_id   13331   20471   16574   11860   13157\n",
       "4                 state_id    2657    3990    3287    2408    2582\n",
       "5                  weekday   12465   19496   16093   10702   12312\n",
       "6                    month    2744    3445    3029    2449    2751\n",
       "7                     year    7803   11455    9349    7100    7665\n",
       "8             event_name_1    1502    2391    1931    1344    1569\n",
       "9                  snap_CA    1259    1769    1617    1297    1324\n",
       "10                 snap_TX    2617    4015    3112    2186    2609\n",
       "11                 snap_WI    2962    4322    3551    2783    2936\n",
       "12                     day   23169   35389   28860   20353   23157\n",
       "13                    week   12210   17766   14765   11485   12279\n",
       "14              sell_price   12704   17524   14765   11485   12777\n",
       "15                 lag_t28   22801   32847   28573   20606   23123\n",
       "16                 lag_t29   21076   33610   27582   19253   21610\n",
       "17                 lag_t30   22471   32500   28111   20061   23232\n",
       "18                 lag_t31   22190   31925   28090   20427   22791\n",
       "19         rolling_mean_t7   27755   41707   34832   25383   28203\n",
       "20          rolling_std_t7   33745   50210   41475   30217   34446\n",
       "21        rolling_mean_t28   26714   39844   33582   23930   26997\n",
       "22         rolling_std_t28   19849   32561   25752   17604   20019\n",
       "23        rolling_mean_t56   19944   32610   25730   18074   20000\n",
       "24         rolling_std_t56   16216   25403   20035   15010   16376\n",
       "25        rolling_mean_t84   19521   31282   24795   17481   19642\n",
       "26         rolling_std_t84   13095   21884   16555   11575   13383\n",
       "27       rolling_mean_t168   20242   31107   24828   18029   20694\n",
       "28        rolling_std_t168   14263   23210   18018   13157   14585\n",
       "29       price_change_t365    7093   10120    8569    6523    7394\n",
       "30    rolling_price_std_t7    1508    2042    1669    1318    1561\n",
       "31   rolling_price_std_t28    4092    5762    5413    3804    4451\n",
       "32  rolling_price_max_t365   18692   26557   22039   17808   19634\n",
       "33   item_id_gb_sell_price   11863   17754   15039   10889   12219\n",
       "34        item_id_gb_lag28   20438   33438   25544   17341   20906\n",
       "35                    diff    5212    6604    6182    4734    5317"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.9116298195516142,\n",
       " 2.008743902930001,\n",
       " 1.9249074828307364,\n",
       " 1.9556963196441517,\n",
       " 1.9458363652957718]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 베이지안 최적화(Bayesian optimization\n",
    ":  초매개변수(Hyper parameter)를 자동으로 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from functools import partial   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_cv(num_leaves, learning_rate, n_estimators, subsample, colsample_bytree, reg_alpha, reg_lambda, x_data=None, y_data=None, n_splits=5, output='score'):\n",
    "    score = 0\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    models = []\n",
    "    for train_index, valid_index in kf.split(x_data):\n",
    "        x_train, y_train = x_data.iloc[train_index], y_data[train_index]\n",
    "        x_valid, y_valid = x_data.iloc[valid_index], y_data[valid_index]\n",
    "        \n",
    "        model = LGBMRegressor(\n",
    "            num_leaves = int(num_leaves), \n",
    "            learning_rate = learning_rate, \n",
    "            n_estimators = int(n_estimators), \n",
    "            subsample = np.clip(subsample, 0, 1), \n",
    "            colsample_bytree = np.clip(colsample_bytree, 0, 1), \n",
    "            reg_alpha = reg_alpha, \n",
    "            reg_lambda = reg_lambda,\n",
    "            device = 'gpu'\n",
    "        )\n",
    "        \n",
    "        model.fit(x_train, y_train)\n",
    "        models.append(model)\n",
    "        \n",
    "        pred = model.predict(x_valid)\n",
    "        true = y_valid\n",
    "        score += metrics.mean_squared_error(true, pred)/n_splits\n",
    "    \n",
    "    if output == 'score':\n",
    "        return score\n",
    "    if output == 'model':\n",
    "        return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | learni... | n_esti... | num_le... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\kjb\\data_analysis\\10_estimate_sales_of_walmart_retail_goods\\venv\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (0.4424817255733826, 0.08152489470734282, 790.0482006660721, 1218.5813550834546, 1.9309431163985868, 48.945610507764144, 0.6437372275043335)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-60deb7d19ea2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4321\u001b[0m                    \u001b[1;31m# 시드 고정\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m )\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mlgbBO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 처음 5회 랜덤 값으로 score 계산 후 30회 최적화\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# 이 예제에서는 7개 하이퍼 파라미터에 대해 30회 조정을 시도했습니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kjb\\data_analysis\\10_estimate_sales_of_walmart_retail_goods\\venv\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_END\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kjb\\data_analysis\\10_estimate_sales_of_walmart_retail_goods\\venv\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kjb\\data_analysis\\10_estimate_sales_of_walmart_retail_goods\\venv\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-f3573f83a9d9>\u001b[0m in \u001b[0;36mlgb_cv\u001b[1;34m(num_leaves, learning_rate, n_estimators, subsample, colsample_bytree, reg_alpha, reg_lambda, x_data, y_data, n_splits, output)\u001b[0m\n\u001b[0;32m     18\u001b[0m         )\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kjb\\data_analysis\\10_estimate_sales_of_walmart_retail_goods\\venv\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    741\u001b[0m                                        \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m                                        \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 743\u001b[1;33m                                        callbacks=callbacks)\n\u001b[0m\u001b[0;32m    744\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kjb\\data_analysis\\10_estimate_sales_of_walmart_retail_goods\\venv\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    598\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kjb\\data_analysis\\10_estimate_sales_of_walmart_retail_goods\\venv\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kjb\\data_analysis\\10_estimate_sales_of_walmart_retail_goods\\venv\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1974\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1975\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1976\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1977\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1978\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델과 관련없는 변수 고정\n",
    "func_fixed = partial(lgb_cv, x_data=train_set_X.reset_index(drop=True), y_data=train_set_y.reset_index(drop=True), n_splits=5, output='score') \n",
    "# 베이지안 최적화 범위 설정\n",
    "lgbBO = BayesianOptimization(\n",
    "    func_fixed, \n",
    "    {\n",
    "        'num_leaves': (64, 4096),        # num_leaves,       범위(16~1024)\n",
    "        'learning_rate': (0.0001, 0.1),  # learning_rate,    범위(0.0001~0.1)\n",
    "        'n_estimators': (16, 1024),      # n_estimators,     범위(16~1024)\n",
    "        'subsample': (0.4, 1),             # subsample,        범위(0~1)\n",
    "        'colsample_bytree': (0.4, 1),      # colsample_bytree, 범위(0~1)\n",
    "        'reg_alpha': (0, 10),            # reg_alpha,        범위(0~10)\n",
    "        'reg_lambda': (0, 50),           # reg_lambda,       범위(0~50)\n",
    "    }, \n",
    "    random_state=4321                    # 시드 고정\n",
    ")\n",
    "lgbBO.maximize(init_points=5, n_iter=30) # 처음 5회 랜덤 값으로 score 계산 후 30회 최적화\n",
    "\n",
    "# 이 예제에서는 7개 하이퍼 파라미터에 대해 30회 조정을 시도했습니다.\n",
    "# 다양한 하이퍼 파라미터, 더 많은 iteration을 시도하여 최상의 모델을 얻어보세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 store 별로 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drop_cols = ['id', 'd', 'target', 'date', 'wm_yr_wk', 'is_event', 'lag_t28', 'lag_t29',\n",
    "       'lag_t30', 'lag_t24', 'lag_t25', 'lag_t26', 'lag_t27']\n",
    "\n",
    "test_sets = []\n",
    "for i in range(10):\n",
    "    store_i = split_store(all_df17_20, i)\n",
    "    test_sets.append(lgb_model(store_i, drop_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    test_sets[0] = pd.concat([test_sets[0], test_sets[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_sets[0].sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 4.4 keras 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "\n",
    "# model.compile(optimizer = \"rmsprop\", loss = root_mean_squared_error, \n",
    "#               metrics =[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential             # Sequential 생성자를 불러옵니다.\n",
    "from keras.layers import Dense, Activation, Dropout      # Dense와 Activation 두 층 인스턴스를 불러옵니다.\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_normal', input_dim=train_set_X[features].shape[1]))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_normal'))\n",
    "# model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))                   # 1차원 출력에 'sigmoid' 함수를 적용하는 Dense 층입니다.\n",
    "model.compile(optimizer='rmsprop',                          # 최적화 함수 = 'rmsprop'\n",
    "              loss= 'mse',                   # 손실 함수 = 'binary_crossentropy'\n",
    "              metrics=[root_mean_squared_error])                         # 평가 지표 = 'accuracy'\n",
    "\n",
    "# 학습시키기 \n",
    "model.fit(train_set_X, train_set_y, epochs=1, batch_size=1000, validation_split = 0.2)           # 생성된 데이터를 32개씩의 배치로 나누어 전체를 총 10회 학습시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result_ = model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "result_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "test['target'] = result_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 예측 및 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kjb\\data_analysis\\10_estimate_sales_of_walmart_retail_goods\\venv\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv('inputs/sample_submission.csv')\n",
    "\n",
    "predictions = test[['id', 'date', 'sales']]\n",
    "predictions['id'] = list(le_id.inverse_transform(predictions['id']))\n",
    "\n",
    "\n",
    "predictions = pd.pivot(predictions, index = 'id', columns = 'date', values = 'sales').reset_index()\n",
    "predictions.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "\n",
    "evaluation_rows = [row for row in sub['id'] if 'evaluation' in row] \n",
    "evaluation = sub[sub['id'].isin(evaluation_rows)]\n",
    "\n",
    "validation = sub[['id']].merge(predictions, on = 'id')\n",
    "final = pd.concat([validation, evaluation])\n",
    "\n",
    "for i in range(1,29):\n",
    "    final['F'+str(i)] *= 1.0315\n",
    "final.to_csv('submissions/submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60980"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>0.873323</td>\n",
       "      <td>0.784295</td>\n",
       "      <td>0.779143</td>\n",
       "      <td>0.783360</td>\n",
       "      <td>0.950387</td>\n",
       "      <td>1.206925</td>\n",
       "      <td>1.239522</td>\n",
       "      <td>0.890044</td>\n",
       "      <td>0.899469</td>\n",
       "      <td>0.877505</td>\n",
       "      <td>0.760785</td>\n",
       "      <td>0.928704</td>\n",
       "      <td>1.158570</td>\n",
       "      <td>0.947115</td>\n",
       "      <td>0.893189</td>\n",
       "      <td>0.763532</td>\n",
       "      <td>0.765772</td>\n",
       "      <td>0.770928</td>\n",
       "      <td>0.904047</td>\n",
       "      <td>1.172698</td>\n",
       "      <td>1.197379</td>\n",
       "      <td>0.857586</td>\n",
       "      <td>0.767958</td>\n",
       "      <td>0.770748</td>\n",
       "      <td>0.806577</td>\n",
       "      <td>0.908495</td>\n",
       "      <td>1.195651</td>\n",
       "      <td>1.230713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>0.194555</td>\n",
       "      <td>0.176493</td>\n",
       "      <td>0.175126</td>\n",
       "      <td>0.187375</td>\n",
       "      <td>0.222587</td>\n",
       "      <td>0.294166</td>\n",
       "      <td>0.329015</td>\n",
       "      <td>0.227524</td>\n",
       "      <td>0.216930</td>\n",
       "      <td>0.211489</td>\n",
       "      <td>0.205290</td>\n",
       "      <td>0.248227</td>\n",
       "      <td>0.316785</td>\n",
       "      <td>0.263612</td>\n",
       "      <td>0.223927</td>\n",
       "      <td>0.209645</td>\n",
       "      <td>0.208626</td>\n",
       "      <td>0.205935</td>\n",
       "      <td>0.240654</td>\n",
       "      <td>0.316128</td>\n",
       "      <td>0.318263</td>\n",
       "      <td>0.227395</td>\n",
       "      <td>0.212678</td>\n",
       "      <td>0.239405</td>\n",
       "      <td>0.236594</td>\n",
       "      <td>0.273997</td>\n",
       "      <td>0.354547</td>\n",
       "      <td>0.359255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>0.543399</td>\n",
       "      <td>0.497084</td>\n",
       "      <td>0.495997</td>\n",
       "      <td>0.498013</td>\n",
       "      <td>0.580580</td>\n",
       "      <td>0.807756</td>\n",
       "      <td>0.808906</td>\n",
       "      <td>0.607966</td>\n",
       "      <td>0.669579</td>\n",
       "      <td>0.659603</td>\n",
       "      <td>0.564589</td>\n",
       "      <td>0.665952</td>\n",
       "      <td>0.882347</td>\n",
       "      <td>0.757665</td>\n",
       "      <td>0.668947</td>\n",
       "      <td>0.630876</td>\n",
       "      <td>0.633323</td>\n",
       "      <td>0.583154</td>\n",
       "      <td>0.663205</td>\n",
       "      <td>0.820275</td>\n",
       "      <td>0.862737</td>\n",
       "      <td>0.640946</td>\n",
       "      <td>0.580865</td>\n",
       "      <td>0.571355</td>\n",
       "      <td>0.532724</td>\n",
       "      <td>0.587334</td>\n",
       "      <td>0.766823</td>\n",
       "      <td>0.768947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>1.685035</td>\n",
       "      <td>1.456727</td>\n",
       "      <td>1.451771</td>\n",
       "      <td>1.479555</td>\n",
       "      <td>1.855729</td>\n",
       "      <td>2.302845</td>\n",
       "      <td>2.426384</td>\n",
       "      <td>1.847484</td>\n",
       "      <td>1.737332</td>\n",
       "      <td>1.600452</td>\n",
       "      <td>1.532305</td>\n",
       "      <td>1.922024</td>\n",
       "      <td>2.372421</td>\n",
       "      <td>1.831755</td>\n",
       "      <td>1.881976</td>\n",
       "      <td>1.570869</td>\n",
       "      <td>1.589190</td>\n",
       "      <td>1.551792</td>\n",
       "      <td>1.744828</td>\n",
       "      <td>2.172816</td>\n",
       "      <td>2.424101</td>\n",
       "      <td>1.851453</td>\n",
       "      <td>1.598248</td>\n",
       "      <td>1.531185</td>\n",
       "      <td>1.484638</td>\n",
       "      <td>1.844668</td>\n",
       "      <td>2.472557</td>\n",
       "      <td>2.483112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>1.123947</td>\n",
       "      <td>1.039583</td>\n",
       "      <td>1.056198</td>\n",
       "      <td>1.021045</td>\n",
       "      <td>1.158401</td>\n",
       "      <td>1.514998</td>\n",
       "      <td>1.630911</td>\n",
       "      <td>1.143672</td>\n",
       "      <td>1.075495</td>\n",
       "      <td>0.974368</td>\n",
       "      <td>0.972741</td>\n",
       "      <td>1.171539</td>\n",
       "      <td>1.505801</td>\n",
       "      <td>1.184925</td>\n",
       "      <td>1.162892</td>\n",
       "      <td>1.019490</td>\n",
       "      <td>1.048211</td>\n",
       "      <td>1.009605</td>\n",
       "      <td>1.197927</td>\n",
       "      <td>1.496557</td>\n",
       "      <td>1.526300</td>\n",
       "      <td>1.071112</td>\n",
       "      <td>0.961041</td>\n",
       "      <td>0.946657</td>\n",
       "      <td>0.970736</td>\n",
       "      <td>1.171604</td>\n",
       "      <td>1.524786</td>\n",
       "      <td>1.609267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id        F1        F2        F3        F4  \\\n",
       "0  HOBBIES_1_001_CA_1_validation  0.873323  0.784295  0.779143  0.783360   \n",
       "1  HOBBIES_1_002_CA_1_validation  0.194555  0.176493  0.175126  0.187375   \n",
       "2  HOBBIES_1_003_CA_1_validation  0.543399  0.497084  0.495997  0.498013   \n",
       "3  HOBBIES_1_004_CA_1_validation  1.685035  1.456727  1.451771  1.479555   \n",
       "4  HOBBIES_1_005_CA_1_validation  1.123947  1.039583  1.056198  1.021045   \n",
       "\n",
       "         F5        F6        F7        F8        F9       F10       F11  \\\n",
       "0  0.950387  1.206925  1.239522  0.890044  0.899469  0.877505  0.760785   \n",
       "1  0.222587  0.294166  0.329015  0.227524  0.216930  0.211489  0.205290   \n",
       "2  0.580580  0.807756  0.808906  0.607966  0.669579  0.659603  0.564589   \n",
       "3  1.855729  2.302845  2.426384  1.847484  1.737332  1.600452  1.532305   \n",
       "4  1.158401  1.514998  1.630911  1.143672  1.075495  0.974368  0.972741   \n",
       "\n",
       "        F12       F13       F14       F15       F16       F17       F18  \\\n",
       "0  0.928704  1.158570  0.947115  0.893189  0.763532  0.765772  0.770928   \n",
       "1  0.248227  0.316785  0.263612  0.223927  0.209645  0.208626  0.205935   \n",
       "2  0.665952  0.882347  0.757665  0.668947  0.630876  0.633323  0.583154   \n",
       "3  1.922024  2.372421  1.831755  1.881976  1.570869  1.589190  1.551792   \n",
       "4  1.171539  1.505801  1.184925  1.162892  1.019490  1.048211  1.009605   \n",
       "\n",
       "        F19       F20       F21       F22       F23       F24       F25  \\\n",
       "0  0.904047  1.172698  1.197379  0.857586  0.767958  0.770748  0.806577   \n",
       "1  0.240654  0.316128  0.318263  0.227395  0.212678  0.239405  0.236594   \n",
       "2  0.663205  0.820275  0.862737  0.640946  0.580865  0.571355  0.532724   \n",
       "3  1.744828  2.172816  2.424101  1.851453  1.598248  1.531185  1.484638   \n",
       "4  1.197927  1.496557  1.526300  1.071112  0.961041  0.946657  0.970736   \n",
       "\n",
       "        F26       F27       F28  \n",
       "0  0.908495  1.195651  1.230713  \n",
       "1  0.273997  0.354547  0.359255  \n",
       "2  0.587334  0.766823  0.768947  \n",
       "3  1.844668  2.472557  2.483112  \n",
       "4  1.171604  1.524786  1.609267  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새롭게 구한 값도 보정하니 정확도가 높아짐\n",
    "# 1.04 를 곱하라고 했는데 1.03 곱하니 더 정확도가 높아짐\n",
    "# 이차회귀식으로 계산 결과, 1.0315 곱하는게 가장 좋음.\n",
    "# tmp = pd.read_csv('submissions/sub_dt_lgb.csv')\n",
    "# for i in range(1,29):\n",
    "#     tmp['F'+str(i)] *= 1.0315\n",
    "# tmp.to_csv('submissions/submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/m5-forecasting-accuracy/submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to M5 Forecasting - Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/20.6M [00:00<?, ?B/s]\n",
      "  0%|          | 8.00k/20.6M [00:00<09:59, 35.9kB/s]\n",
      "  0%|          | 96.0k/20.6M [00:00<07:06, 50.3kB/s]\n",
      "  2%|1         | 360k/20.6M [00:00<04:57, 71.2kB/s] \n",
      "  7%|6         | 1.42M/20.6M [00:00<03:18, 101kB/s]\n",
      " 11%|#         | 2.21M/20.6M [00:00<02:13, 144kB/s]\n",
      " 13%|#2        | 2.62M/20.6M [00:03<02:07, 148kB/s]\n",
      " 31%|###1      | 6.48M/20.6M [00:03<01:09, 211kB/s]\n",
      " 38%|###8      | 7.84M/20.6M [00:03<00:44, 299kB/s]\n",
      " 44%|####4     | 9.12M/20.6M [00:03<00:28, 423kB/s]\n",
      " 50%|#####     | 10.4M/20.6M [00:03<00:18, 595kB/s]\n",
      " 56%|#####6    | 11.5M/20.6M [00:03<00:11, 832kB/s]\n",
      " 62%|######1   | 12.7M/20.6M [00:04<00:07, 1.15MB/s]\n",
      " 67%|######7   | 13.9M/20.6M [00:04<00:04, 1.58MB/s]\n",
      " 73%|#######3  | 15.0M/20.6M [00:04<00:02, 2.14MB/s]\n",
      " 79%|#######8  | 16.2M/20.6M [00:04<00:01, 2.83MB/s]\n",
      " 84%|########4 | 17.3M/20.6M [00:04<00:00, 3.67MB/s]\n",
      " 90%|########9 | 18.4M/20.6M [00:04<00:00, 4.62MB/s]\n",
      " 95%|#########5| 19.6M/20.6M [00:04<00:00, 5.65MB/s]\n",
      "100%|##########| 20.6M/20.6M [00:08<00:00, 2.59MB/s]\n"
     ]
    }
   ],
   "source": [
    "time.sleep(2)\n",
    "os.chdir(\"submissions\")\n",
    "!kaggle competitions submit -c m5-forecasting-accuracy -f submission.csv -m lgb\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 모델 파라미터 및 피처 기록 및 모델 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "write_params_features(features, params, eval_results, mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KJB\\data_analysis\\10_estimate_sales_of_walmart_retail_goods\\mypackage\\utils.py:134: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  fi = pd.concat([fi, tmp])\n",
      "C:\\Users\\KJB\\data_analysis\\10_estimate_sales_of_walmart_retail_goods\\mypackage\\utils.py:135: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  fi = pd.concat([fi, feature])\n"
     ]
    }
   ],
   "source": [
    "save_feature_importance(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1등 노트북이랑 비교해서 카테고리형 피처 빠진거있나 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "324px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
